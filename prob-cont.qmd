# Continuous Probability Distributions {#sec-prob-cont}

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(emoji)
library(knitr)
library(kableExtra)
library(openintro)
```

## Introduction

- A continuous random variable can take on **any** values from *an interval of the real line*.
- Instead of probability functions, a continuous random variable, $X$, has the **probability density function (pdf)** $f(x)$ such that for any real value $a < b$,
$$P(a < X < b) = \int_{a}^b f(x) dx$$
- The **cumulative distribution function (cdf)** of $X$ is defined as
$$F(x) := P(X \le x) = \int_{-\infty}^x f(t)dt$$
- Every probability density function must satisfy <span style="color:blue"> (1) $f(x) \ge 0$ for all $x$; (2) $\int_{-\infty}^{\infty} f(x) dx = 1$ </span>

- `r emoji('sunglasses')` Luckily, we don't deal with integrals in this course.

--------------------------------------------------------------------

<span style="color:blue"> **Density Curve** </span>

- A probability distribution function generates a graph called a **density curve** that shows the *likelihood* of a random variable at all possible values.
- **The area under the density curve between $a$ and $b$:** $P(a < X < b) = \int_{a}^b f(x) dx$.
- **The total area under any density curve is equal to 1:** $\int_{-\infty}^{\infty} f(x) dx = 1$


```{r, echo=FALSE, out.width="50%", fig.align='center'}
#| label: fig-density
#| fig-cap: Density curve for a random variable
# knitr::include_graphics("./images/img-prob/density.png")
par(mar = c(2, 2, 0, 0), mgp = c(0.5, 0.2, 0), mfrow = c(1, 1))
x = seq(0,10,length=1000)
y = dgamma(x, 2, 1/2)
plot(x, y, type = "l", lwd = 3, col = "blue", axes = FALSE, 
     ylab = "f(x)", las = 1, cex.lab = 1.4)
axis(1, at = c(2, 4), labels = c("a", "b"), tick = TRUE)
axis(2, tick = FALSE, labels = FALSE)
abline(h = 0)
abline(v = 0)
x = seq(2, 4, length = 100)
y = dgamma(x, 2, 1/2)
polygon(c(2, x, 4), c(0, y, 0), col = "lightblue")
text(3, dgamma(2, 2, 1/2)/2, "P(a < X < b)", cex = 1.4)
text(6, dgamma(6, 2, 1/2)/3, "Total Area = 1", cex = 1.8)
text(7.5, dgamma(5.6, 2, 1/2), "density curve", cex = 1.8)
```

---------------------------------------------------------------------

<span style="color:blue"> **Commonly Used Continuous Distributions** </span>

- R Shiny app is a [Continuous Distribution](http://sctc.mscs.mu.edu:3838/sample-apps/Calculator/) calculator.
- In this course, we will touch on **normal (Gaussian)**, **student's t**, **chi-square**, **F**
- Some other common distributions include **uniform**, **exponential**, **gamma**, **beta**, **inverse gamma**, **Cauchy**, etc. (MATH 4700)

## Normal (Gaussian) Distribution
-  The normal distribution, $N(\mu, \sigma^2$), has the probability distribution function given by 
$$\small f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}, \quad -\infty < x < \infty$$
    - This distribution has two parameters: mean, $\mu$, and variance, $\sigma^2$ (standard deviation $\sigma$).
    - It is always bell-shaped and symmetric about the mean, $\mu$.
    - When $\mu = 0$ and $\sigma = 1$, $N(0, 1)$ is called **standard normal**.

- Below are examples of normal distribution curves and how they change with different means and standard deviations.

```{r normal_density, echo=FALSE, out.width='35%', fig.align='center'}
#| label: fig-normal-density
#| fig-cap: Normal density curve with mean 100 and standard deviation 15
par(mfrow = c(1, 1))
par(mar = c(1.8, 0, 1.2, 0), mgp = c(0.5, 0.2, 0), las = 1)
mean=100; sd=15
# lb=80; ub=120
x <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(x,mean,sd)
plot(x, hx, type="n", xlab="x", ylab="",
  main=expression(N(100, 15^2)), axes=FALSE)
# i <- x >= lb & x <= ub
lines(x, hx, col = "#003366", lwd = 3)
# polygon(c(lb,x[i],ub), c(0,hx[i],0), col="red")
# area <- pnorm(ub, mean, sd) - pnorm(lb, mean, sd)
# result <- paste("P(",lb,"< IQ <",ub,") =",
#    signif(area, digits=3))
# mtext(result,3)
axis(1, at=seq(40, 160, 20), pos=0, tick = -0.005)
```


```{r normal_densities, echo=FALSE, out.width='75%', fig.align='center'}
#| label: fig-normal-densities
#| fig-cap: Normal density curves with varying means and standard deviations
mean=100; sd=10
x <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(x,mean,sd)
plot(x, hx, type="n", xlab="x", ylab="", xlim = c(-30, 160), bty = "n",
     main="normal densities", yaxt = "n", xaxt = "n")
axis(1, at=seq(-30, 160, 20), pos=0, tick = -0.005)
lines(x, hx, col = "#003366", lwd = 3)
mean=100; sd=15
x <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(x,mean,sd)
lines(x, hx, col = "#FFCC00", lwd = 3)
mean=20; sd=10
x <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(x,mean,sd)
lines(x, hx, col = 2, lwd = 3)
legend("topright", c(expression(N(100, 10^2)), 
                     expression(N(100, 15^2)), 
                     expression(N(20, 10^2))), 
       col = c("#003366", "#FFCC00", 2), lwd = 3, bty = "n")
```

## Standardization and Z-Scores

- **Standardization** allows us to convert $N(\mu, \sigma^2)$ to $N(0, 1)$.
- **Why do we perform standardization?**
  - We want to put data on a *standardized scale*, because it helps us make comparisons more easily!
-  If $x$ is an observation from a distribution with mean $\mu$ and standard deviation $\sigma$, the standardized value of $x$ is its so-called **$z$-score**:
$$z = \frac{x - \mu}{\sigma}$$
- The $z$-score tells us how many standard deviations $x$ falls away from the mean and in which direction. 
  + Observations **larger** than the mean have **positive** $z$-scores. 
  + Observations **smaller** than the mean have **negative** $z$-scores.
  + A $z$-score -1.2 means that $x$ is 1.2 standard deviations to the **left** of or **below** the mean. 
  + A $z$-score 1.8 means that $x$ is 1.8 standard deviations to the **right** of or **above** the mean. 
- <span style="color:blue">  If $X \sim N(\mu, \sigma^2)$, $Z = \frac{X - \mu}{\sigma}$ follows the standard normal distribution $Z \sim N(0, 1)$. </span>

-----------------------------------------------------------------

<span style="color:blue"> **Illustration** </span>

- $X - \mu$ shifts the mean from $\mu$ to 0.

```{r standardization_shift, echo=FALSE, out.width='65%', fig.asp=0.3, fig.align='center'}
#| label: fig-standardization-mean
#| fig-cap: Standardization shifts mean from 3 to 0
mean = 3; sd = 2
par(mar = c(2, 0, 1, 0), mgp = c(1, 0.2, 0), las = 1)
x <- seq(-6, 9, length = 100)
# z <- seq(-3, 13, length = 100)
hx <- dnorm(x, mean, sd)
hz <- dnorm(x, 0, sd)
plot(x, hz, type="n", xlab="x", ylab="", ylim = c(0, dnorm(0, 0, 1)),
  main = "Shift from N(3, 4) to N(0, 4)", axes = FALSE)
lines(x, hz, col = "blue", lwd = 4)
lines(x, hx, col = "#003366", lwd = 4)
axis(1, at = seq(-3, 9, 1), pos=0)
# abline(v = c(0, 3))
segments(x0 = 0, y0 = 0, y1 = dnorm(0, 0, sd), col = "blue", lwd = 2)
segments(x0 = mean, y0 = 0, y1 = dnorm(mean, mean, sd), col = "#003366", lwd = 2)
arrows(x0 = 3, y0 = 0.1, x1 = 0, col = "darkgray", lwd = 2)
```

- $\frac{X - \mu}{\sigma}$ scales the variation from 4 to 1.

```{r standardization_scale, echo=FALSE, out.width='65%', fig.asp=0.3, fig.align='center'}
#| label: fig-standarization-variance
#| fig-cap: Standardization scales variance from 4 to 1
par(mar = c(2, 0, 1, 0), mgp = c(1, 0.2, 0), las = 1)
x <- seq(-6, 9, length = 100)
# z <- seq(-3, 13, length = 100)
hx <- dnorm(x, 0, sd)
hz <- dnorm(x, 0, 1)
plot(x, hz, type="n", xlab="x", ylab="", ylim = c(0, dnorm(0, 0, 1)),
  main = "Scale from N(0, 4) to N(0, 1)", axes = FALSE)
lines(x, hz, col = "red", lwd = 4)
lines(x, hx, col = "blue", lwd = 4)
axis(1, at = seq(-3, 9, 1), pos=0)
segments(x0 = 0, y0 = 0, y1 = dnorm(0, 0, 1), col = "red", lwd = 2)
arrows(x0 = 3, y0 = 0.05, x1 = 2, col = "darkgray", lwd = 2)
arrows(x0 = 0.5, y0 = dnorm(0, 0, 2), x1 = 0.5, y1 = dnorm(0, 0, 1), col = "darkgray", lwd = 2)
```

- A value of $x$ that is 2 standard deviation below the mean, $\mu$, corresponds to $z = -2$.
  - $z = \frac{x  -\mu}{\sigma} \iff x = \mu + z\sigma$. If $z = -2$, $x = \mu - 2\sigma$.

- @fig-distribution-standardized depicts how the values on the x-axis change when standardization is performed.

```{r, echo=FALSE, out.width='90%', fig.align='center'}
#| label: fig-distribution-standardized
#| fig-cap: Standardized Normal Distribution
knitr::include_graphics("./images/img-prob/standardization.png")
```

-----------------------------------------------------------------------

<span style="color:blue"> **SAT and ACT Example** </span>

- Standardization can help us compare the performance of students on the SAT and ACT, which both have nearly normal distributions.
  - The table below lists the parameters for each distribution.

|Measure        | SAT               | ACT         |
|:-------------:|:-----------------:|:-----------:|
| Mean          | 1100              | 21          |  
| SD            | 200               | 6           |

```{r, echo=FALSE, out.width="50%", fig.align='center'}
knitr::include_graphics("./images/img-prob/sat_act.jpeg")
```

- We want to determine whether Anna or Tommy performed better on their respective tests.
  - Anna scored a 1300 on her SAT and Tommy scored a 24 on his ACT.

<span style="color:red"> ***Standardization*** </span>

- $z_{A} = \frac{x_{A} - \mu_{SAT}}{\sigma_{SAT}} = \frac{1300-1100}{200} = 1$; $z_{T} = \frac{x_{T} - \mu_{ACT}}{\sigma_{ACT}} = \frac{24-21}{6} = 0.5$.

```{r sat, echo=FALSE, out.width='70%', fig.align='center'}
#| label: fig-standardization-sat-act
#| fig-cap: Standardization of Anna and Tommy's scores
par(mfrow = c(2, 1),
    las = 1,
    mar = c(2.5, 0, 0.5, 0))
# _____ Curve 1 _____ #
m <- 1100
s <- 200
X <- m + s * seq(-6, 6, 0.01)
Y <- dnorm(X, m, s)
plot(X, Y,
     type = 'l',
     axes = FALSE, xlab = "",
     xlim = m + s * 2.7 * c(-1, 1))
axis(1, at = m + s * (-3:3))
abline(h = 0)
lines(c(m, m),
      dnorm(m, m, s) * c(0.01, 0.99),
      lty = 2,
      col = '#EEEEEE')
lines(c(m, m) + s,
      dnorm(m + s, m, s) * c(0.01, 1.25),
      lty = 2, col = COL[1])
text(m + s,
     dnorm(m + s, m, s) * 1.25,
     'Anna',
     pos = 3,
     col = COL[1])


# _____ Curve 2 _____ #
par(mar = c(2, 0, 1, 0))
m <- 21
s <- 6
X <- m + s * seq(-6, 6, 0.01)
Y <- dnorm(X, m, s)
plot(X, Y, xlab = "",
     type = 'l',
     axes = FALSE,
     xlim = m + s * 2.7 * c(-1, 1))
axis(1, at = m + s * (-3:3))
abline(h = 0)
lines(c(m, m),
      dnorm(m, m, s) * c(0.01, 0.99),
      lty = 2,
      col = '#EEEEEE')
lines(c(m, m) + 3,
      dnorm(m + 3, m, s) * c(0.01, 1.2),
      lty = 2,
      col = COL[1])
text(m + 3,
     dnorm(m + 3, m, s) * 1.05,
     'Tommy',
     pos = 4,
     col = COL[1])
```

- This standardization tells us that Anna scored 1 standard deviation above the mean and Tommy scored 0.5 standard deviations above the mean.
- From this information, we can conclude that Anna performed better on teh SAT than Tommy performed on the ACT.

## Tail Areas and Normal Percentiles

<span style="color:blue"> **Finding Tail Areas $P(X < x)$** </span>

- Finding tail areas allows us to determine the percentage of cases that are above or below a certain score.
- Going back to the SAT and ACT example, this can help us determine the fraction of students have an SAT score below Anna's score of 1300.
  - This is the same as determining what percentile Anna scored at, which is the percentage of cases that had lower scores than Anna.
- Therefore, we are looking for $P(X < 1300 \mid \mu = 1100, \sigma = 200)$ or $P(Z < 1 \mid \mu = 0, \sigma = 1)$.
  - We can calculate this value by using R.

```{r tail, echo=FALSE, out.width='50%', fig.align='center'}
#| label: fig-tail-area
#| fig-cap: Tail area for scores below 1300
par(mfrow = c(1, 1), las = 1, mar = c(2.5, 0, 0, 0), mgp = c(0, 1, 0))
normTail(m = 1100, s = 200, L = 1300, col = 4, cex.axis = 1.3)
```

<span style="color:red"> ***Calculation in R*** </span>

- With **`mean`** and **`sd`** representing the mean and standard deviation of a normal distribution,
  + use **`pnorm(q, mean, sd)`** to compute $P(X \le q)$
  + use **`pnorm(q, mean, sd, lower.tail = FALSE)`** to compute $P(X > q)$

::::{.columns}
:::{.column width="50%"}
```{r, ref.label="fig-tail-area", echo=FALSE, out.width='100%'}
```
:::

:::{.column width="50%"}
```{r}
pnorm(1, mean = 0, sd = 1)
pnorm(1300, mean = 1100, sd = 200)
```

- The shaded area represents the 84.1% of SAT test takers who had z-score below 1.
:::
::::

<span style="color:red"> ***Second ACT and SAT Example*** </span>

:::{.callout-note icon=false}
## What is the probability Shannon SAT scores at least 1190?
- SAT score follows $N(1100, 200^2)$. 
- Shannon is an SAT taker, and nothing else is known about her SAT aptitude. 
:::

- <span style="color:red"> Step 1: State the problem </span>
  +  <span style="color:blue"> We want to compute $P(X \ge 1190)$. </span>

- <span style="color:red"> Step 2: Draw a picture

```{r, echo=FALSE, out.width='40%', fig.align='center'}
#| label: fig-tail-right
#| fig-cap: Tail area for scores greater than 1190
par(mfrow = c(1, 1), las = 1, mar = c(4, 0, 0, 0), mgp = c(1, 1, 0))
normTail(m = 1100, s = 200, U = 1190, col = 4, cex.axis = 1.3)
```


```{r echo=FALSE, out.width='100%', fig.asp=0.2, fig.align='center'}
#| label: fig-tail-subtraction
#| fig-cap: Method to determine right tail areas
AddShadedPlot <- function(x, y, offset,
                          shade.start = -8,
                          shade.until = 8, col = 4) {
  lines(x + offset, y)
  lines(x + offset, rep(0, length(x)))
  these <- which(shade.start <= x & x <= shade.until)
  polygon(c(x[these[1]], x[these], x[rev(these)[1]]) + offset,
          c(0, y[these], 0),
          col = 4)
  lines(x + offset, y)
}
# AddText <- function(x, text) {
#   text(x, 0.549283, text, cex = 2)
# }

X <- seq(-3.2, 3.2, 0.01)
Y <- dnorm(X)
par(mfrow = c(1, 1), las = 1, mar = c(0, 0, 0, 0), mgp = c(0, 0, 0))
plot(X, Y, type = 'l', axes = FALSE, xlim = c(-3.4, 16 + 3.4), xlab = "", ylab = "")
AddShadedPlot(X, Y, 0, 0.45, 8)
AddShadedPlot(X, Y, 8)
AddShadedPlot(X, Y, 16, -8, 0.45)
segments(c(3.5, 3.5), c(0.19, 0.23), c(4.5, 4.5), lwd = 3)
# lines(c(3.72, 4.28), rep(0.549283, 2), lwd = 2)
lines(c(11.5, 12.5), c(0.21, 0.21), lwd = 3)
# text(12, 0.549283,' = ', cex = 2)

```

- <span style="color:red"> Step 3: Find $z$-score </span> 
  + <span style="color:blue"> $z = \frac{1190 - 1100}{200} = 0.45$ and we want to compute $P(X > 1190) = P\left( \frac{X - \mu}{\sigma} > \frac{1190 - 1000}{200} \right) = P(Z > 0.45) = 1 - P(Z \le 0.45)$ </span>
- <span style="color:red"> Step 4: Find the area using `pnorm()` </span>

```{r}
1 - pnorm(0.45)
```

------------------------------------------------------------------------

<span style="color:blue"> **Normal Percentiles in R** </span>

- To get the $100p$-th percentile (or the $p$ quantile $q$ ), given probability $p$,
  + use **`qnorm(p, mean, sd)`** to get a value of $X$, $q$, such that $P(X \le q) = p$ 
  + use **`qnorm(p, mean, sd, lower.tail = FALSE)`** to get $q$ such that $P(X \ge q) = p$
  
<span style="color:red"> ***SAT and ACT Example*** </span>

- What is the 95th percentile for SAT scores?
- <span style="color:red"> Step 1: State the problem </span>
  +  <span style="color:blue"> We want to find $x$ s.t $P(X < x) = 0.95$. </span>
- <span style="color:red"> Step 2: Draw a picture

```{r, echo=FALSE, out.width='40%', fig.align='center'}
#| label: fig-percentile
#| fig-cap: Picture for the 95th percentile of SAT scores
par(mfrow = c(1, 1), las = 1, mar = c(2, 0, 0, 0), mgp = c(1, 1, 0))
normTail(m = 1100, s = 200, L = qnorm(0.95, 1100, 200), col = 4, cex.axis = 1.3)
```

:::{.callout-note}
**We want to find an $x$ value of the normal distribution, which is greater than 95% of all other cases.**
:::

- <span style="color:red"> Step 3: Find $z$-score s.t. $P(Z < z) = 0.95$ using `qnorm()`</span>: 

```{r}
(z_95 <- qnorm(0.95))
```

- <span style="color:red"> Step 4: Find the $x$ of the original scale </span>
  + <span style="color:blue"> $z_{0.95} = \frac{x-\mu}{\sigma}$. So $x = \mu + z_{0.95}\sigma$. </span>
  
```{r}
(x_95 <- 1100 + z_95 * 200)
```
- The 95th percentile for SAT scores is 1429.

```{r}
qnorm(p = 0.95, mean = 1100, sd = 200)
```

## Finding Probabilties

`r emoji('point_right')` **ALWAYS draw and label the normal curve and shade the area of interest.**

- `r emoji('point_right')` **Less than**
  + $\small P(X < x) = P(Z < z)$
  + `pnorm(z, mean = 0, sd = 1)`
  + `pnorm(x, mean = mu, sd = sigma)`
- `r emoji('point_right')` **Greater than**
  + $\small P(X > x) = P(Z > z) = 1 - P(Z \le z)$
  + `1 - pnorm(z)`

:::{.callout-note icon=false}
- Standardization is not a must.
- If we don't standardize, we must specify the mean and SD of the original distribution of $X$, like `pnorm(x, mean = mu, sd = sigma)`.
:::

- `r emoji('point_right')` **Between two numbers**
  + $\small P(a < X < b) = P(z_a < Z < z_b) = P(Z < z_b) - P(Z < z_a)$
  + `pnorm(z_b) - pnorm(z_a)`
- `r emoji('point_right')` **Outside of two numbers** $(a < b)$
$$\small \begin{align} P(X < a \text{ or } X > b) &= P(Z < z_a \text{ or } Z > z_b) \\ &= P(Z < z_a) + P(Z > z_b) \\ &= P(Z < z_a) + 1 - P(Z < z_b) \end{align}$$

  + `pnorm(z_a) + 1 - pnorm(z_b)`
  + `pnorm(z_a) + pnorm(z_b, lower.tail = FALSE)`

:::{.callout-note icon=false}
- Any probability can be computed using the *"less than"* form (*lower* or *left* tail).
- If the calculation involves the "greater than" form, add `lower.tail = FALSE` in `pnorm()`.
:::

## Checking Normality: Normal Quantile Plot

- Many statistical methods assume variables are normally distributed.
- Therefore, testing the appropriateness of the normal assumption is a key step.
- We can check this normality assumption using a **normal quantile plot (normal probability plot)** or a **Quantile-Quantile plot (QQ plot)**.
  + $X$-axis: Quantiles of the *ordered* data if the data were normally distributed.
  + $Y$-axis: *Ordered* data values
- If the data are normally distributed, the points on the QQ plot will lie close to a **straight line**.

-----------------------------------------------------------------

<span style="color:blue"> **QQ plot in R** </span>

```{r qqplot, fig.height=4.5, out.width='60%', echo = -c(1,2,3, 4, 7), fig.align='center'}
#| label: fig-qqplot
#| fig-cap: QQ plots for normal and right-skewed data samples
par(mfcol = c(2, 2), las = 1, mar = c(3.5, 3.5, 2, 1), mgp = c(2, 0.5, 0))
normal_sample <- rnorm(1000)
right_skewed_sample <- rgamma(1000, 2, 1 / 2)
hist(normal_sample, col = 4, main = "Normal data", breaks = 20, border = "white")
qqnorm(normal_sample, main = "Normal data", col = 4)
qqline(normal_sample)
hist(right_skewed_sample, col = 6, main = "Right-skewed data", breaks = 20, border = "white")
qqnorm(right_skewed_sample, main = "Right-skewed data", col = 6)
qqline(right_skewed_sample)
```

## Exercises

1. What percentage of data that follow a standard normal distribution $N(\mu=0, \sigma=1)$ is found in each region? Drawing a normal graph may help.
    (a) $Z < -1.75$
    (b) $-0.7 < Z < 1.3$
    (c) $|Z| > 1$
  
2. The average daily high temperature in June in Chicago is 74$^{\circ}$F with a standard deviation of 4$^{\circ}$F. Suppose that the temperatures in June closely follows a normal distribution.
    (a) What is the probability of observing an 81$^{\circ}$ F temperature or higher in Chigcago during a randomly chosen day in June?
    (b) How cool are the coldest 15\% of the days (days with lowest average high temperature) during June in Chicago?

3. Head lengths of Virginia opossums follow a normal distribution with mean 104 mm and standard deviation 6 mm. 
    (a) Compute the $z$-scores for opossums with head lengths of 97 mm and 108 mm.
    (b) Which observation (97 mm or 108 mm) is more unusual or less likely to happen than another observation? Why?
    
