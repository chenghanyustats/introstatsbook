# Analysis of Variance {#sec-model-anova}

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(openintro)
library(knitr)
library(emoji)
library(car)
library(nortest)
```

## ANOVA Rationale

<span style="color:blue"> **Comparing More Than Two Population Means** </span>

- In many research settings, we want to compare 3 or more population means.

::::{.columns}
:::{.column width="50%"}
- <span style="color:blue"> Are there differences in the mean readings of 4 types of devices used to determine the pH of soil samples? </span>

```{r, echo=FALSE, out.width="78%", fig.align='center'}
knitr::include_graphics("./images/img-model/soil.jpeg")
```
:::

:::{.column width="50%"}
- <span style="color:blue"> Do different treatments (None, Fertilizer, Irrigation, Fertilizer and Irrigation) affect the mean weights of poplar trees?  </span>

```{r, echo=FALSE, out.width="78%", fig.align='center'}
knitr::include_graphics("./images/img-model/poplar.jpeg")
```
:::
::::

------------------------------------------------------------------------

<span style="color:blue"> **One-Way Analysis of Variance** </span>

- A **factor** is a property or characteristic (categorical variable) that allows us to *distinguish the different populations from one another*.  
  + **Type of device** and **treatment of trees** are factors from the examples previously provided.
- One-way ANOVA examines the effect of a *categorical variable* on the *mean of a numerical variable* (response).
  + We use analysis of <span style="color:red"> variance </span> to test the equality of 3 or more population  <span style="color:red"> means</span>. `r emoji('thinking')`
  + The method is **one-way** because we use one single property (categorical variable) for categorizing the populations.

<span style="color:red"> ***Requirements*** </span>

- The populations of each category are **normally** distributed.
- The populations have the **same variance** $\sigma^2$ (two sample pooled $t$-test). 
- The samples are **random samples**.
- The samples are **independent** of each other (not matched or paired in any way).

<span style="color:red"> ***Rationale*** </span>

- Data 1 and Data 2 have the same group sample means $\bar{y}_1$, $\bar{y}_2$ and $\bar{y}_3$ denoted as red dots.
- However, they differ with regards to the variance within each group.

```{r, out.width="70%", fig.asp=0.6, echo=FALSE, fig.align='center'}
#| label: fig-boxplots-var
#| fig-cap: Boxplots illustrating the variance within samples
par(mfrow = c(2, 1), mar = c(2.5, 2.5, 1.5, 0), mgp = c(1.1, 0.5, 0), las = 1)
y1 <- rnorm(50, 6, 0.08)
y2 <- rnorm(50, 5.6, 0.08)
y3 <- rnorm(50, 5.2, 0.08)
small_var_data <- data.frame(y = c(y1, y2, y3), sample = rep(c(1,2,3), each = 50))
boxplot(y ~ sample, small_var_data, ylim = c(2, 9),
        main = "Data 1: Small Variance Within Samples", cex.main = 0.89, 
        col = "lightblue", horizontal = TRUE)
points(x=c(6, 5.6, 5.2), y = c(1, 2,3), col = "red", pch = 16)

y1_l <- rnorm(50, sd = 1.0) + 6
y2_l <- rnorm(50, sd = 1.0) + 5.6
y3_l <- rnorm(50, sd = 1.0) + 5.2
large_var_data <- data.frame(y = c(y1_l, y2_l, y3_l), sample = rep(c(1,2,3), each = 50))
boxplot(y ~ sample, large_var_data, ylim = c(2, 9),
        main = "Data 2: Large Variance Within Samples", cex.main = 0.89, 
        col = "lightblue", horizontal = TRUE)
points(x=c(6, 5.6, 5.2), y = c(1, 2,3), col = "red", pch = 16)
# points(c(5.9, 5.5, 5))
```

:::{.callout-note icon=false}
## For which data do you feel more confident in saying the population means $\mu_1$, $\mu_2$ and $\mu_3$ are not all the same?
:::

---------------------------------------------------------------

<span style="color:blue"> **Variation Between Samples & Variation Within Samples** </span>

- Data 1: Variability between samples is **large** *in comparison to* the variation within samples.
- Data 2: Variation between samples is **small** relatively to the variation within samples.

:::{.callout-note icon=false}
## We are more confident concluding there is a difference in population means when variation **between** samples is *larger* than variation **within** samples.
:::

```{r, out.width="55%", echo=FALSE, fig.align='center'}
#| label: fig-var-within
#| fig-cap: Illustration of small and large variance within samples
knitr::include_graphics("./images/img-model/figure8-1.png")
```

## ANOVA Procedures

- <span style="color:blue"> $\begin{align} &H_0: \mu_1 = \mu_2 = \cdots = \mu_k\\  &H_1: \text{Population means are not all equal} \end{align}$ </span>

<!-- - We use $F$-test.  -->

- Statistician Ronald Fisher found a way to define a variable that follows the $F$ distribution:
$$\frac{\text{variance between samples}}{\text{variance within samples}} \sim F_{df_B,\, df_W}$$
- If the variance *between* samples is larger than the variance *within* samples ($F_{test}$ is much greater than 1), as in Data 1, we reject $H_0$.

:::{.callout-note icon=false}
## Key
- Define variance between samples and variance within samples so that the ratio is $F$ distributed.
:::

------------------------------------------------------------------

<span style="color:blue"> **Variance Within Samples** </span>

- Back to the two-sample pooled $t$-test with equal variance, $\sigma^2$. We have 
$$s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}$$

:::{.callout-note icon=false}
## How about the pooled sample variance for $k$ samples?
:::

- ANOVA assumes the populations have the **same variance** such that $\sigma_1^2 = \sigma_2^2 = \cdots = \sigma_k^2 = \sigma^2$. 
$$\boxed{s_W^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2 + \cdots + (n_k-1)s_k^2}{n_1 + n_2 + \cdots + n_k - k}}$$
where $s_i^2$, $i = 1, \dots ,k$, is the sample variance of group $i$.
- $s_W^2$ represents a *combined* estimate of the common variance, $\sigma^2$. 
  + It measures variability of the observations within the $k$ populations.

-----------------------------------------------------------------

<span style="color:blue"> **Variance Between Samples** </span>

$$\boxed{s^2_{B} = \frac{\sum_{i=1}^k n_i (\bar{y}_{i\cdot} - \bar{y}_{\cdot\cdot})^2}{k-1}}$$ 

- $\bar{y}_{i\cdot}$ is the $i$-th sample mean.
- $\bar{y}_{\cdot\cdot}$ is the *grand* sample mean with all data points in all groups combined.
- $s^2_{B}$ is also an estimate of $\sigma^2$ and measures variability *among* sample means for the $k$ groups.
- If $H_0$ is true $(\mu_1 = \cdots = \mu_k = \mu)$, any variation in the sample means is due to chance and randomness, so it shouldn't be too large.
  + $\bar{y}_{1\cdot}, \cdots, \bar{y}_{k\cdot}$ should be close each other and should be close to $\bar{y}_{\cdot \cdot}$.

-----------------------------------------------------------------

<span style="color:blue"> **ANOVA Table: Sum of Squares** </span>

- **Total Sum of Squares (SST)** measures the total variation around $\bar{y}_{\cdot\cdot}$ in all of the sample data combined (ignoring the groups):
$$\scriptsize{\color{blue}{SST = \sum_{j=1}^{n_i}\sum_{i=1}^{k} \left(y_{ij} - \bar{y}_{\cdot\cdot}\right)^2}}$$ where $y_{ij}$ is the $j$-th data point in the $i$-th group.

- **Sum of Squares Between Samples (SSB)** measures the variation **between** sample means:
$$\scriptsize{ \color{blue}{SSB = \sum_{i=1}^{k}n_i \left(\bar{y}_{i\cdot} - \bar{y}_{\cdot\cdot}\right)^2}}$$

- **Sum of Squares Within Samples (SSW)** measures the variation of any value, $y_{ij}$, about its sample mean, $\bar{y}_{i\cdot}$:
$$\scriptsize{ \color{blue}{SSW = \sum_{i=1}^{k} \sum_{j=1}^{n_i} \left(y_{ij} - \bar{y}_{i\cdot}\right)^2 = \sum_{i=1}^{k} (n_i - 1)s_i^2}}$$

<span style="color:red"> ***Sum of Squares Identity*** </span>

- $SST = SSB + SSW$ 
- $df_{T} = df_{B} + df_{W} \implies N - 1 = (k-1) + (N - k)$
<!-- $\begin{align} &df_{T} = df_{B} + df_{W} \\&n - 1 = (k-1) + (n - k) \end{align}$ -->

- $\text{Mean Square (MS)} = \frac{\text{sum of squares}}{\text{degrees of freedom}}$
- $MSB = \frac{SSB}{k-1} = s^2_{B}$
- $MSW = \frac{SSW}{N-k} = s^2_{W}$
- $F_{test} = \frac{MSB}{MSW}$
- Under $H_0$, $\frac{S^2_{B}}{S_W^2} \sim F_{k-1, \, N-k}$
- Reject $H_0$ if 
  + $F_{test} > F_{\alpha, \, k - 1,\, N-k}$
  + $p$-value $P(F_{k - 1,\, N-k} > F_{test}) < \alpha$

<span style="color:red"> ***ANOVA Table*** </span>

```{r, out.width="100%", echo=FALSE, fig.align='center'}
knitr::include_graphics("./images/img-model/anova_table_k.png")
```

## ANOVA Example

- We hypothesize that a nutrient called "isoflavones" varies among three types of food: (1) cereals and snacks, (2) energy bars and (3) veggie burgers. 

::::{.columns}
:::{.column width="32%"}
```{r, echo=FALSE, out.width = "100%", fig.align = "center"}
knitr::include_graphics("./images/img-model/cereal.jpeg")
```
:::

:::{.column width="2%"}
:::

:::{.column width="32%"}
```{r, echo=FALSE, out.width = "100%", fig.align = "center"}
knitr::include_graphics("./images/img-model/energy_bar.png")
```
:::

:::{.column width="2%"}
:::

:::{.column width="32%"}
```{r, echo=FALSE, out.width = "100%", fig.align = "center"}
knitr::include_graphics("./images/img-model/veggie_burger.jpeg")
```
:::
::::

- A sample of 5 is taken from each type of food and the amount of isoflavones is measured.
- Is there a sufficient evidence to conclude that the mean isoflavone levels vary among these food items at $\alpha = 0.05$?

---------------------------------------------------------------

<span style="color:blue"> **Data** </span>

```{r, echo=FALSE}
load("./data/table08-7.rdata")
data <- `table08-7`
data_anova <- data.frame("y"=c(data[, 1], data[, 2], data[, 3]),
                      "food"=rep(c("cereals", "energy", "veggie"), each = 5))
data_anova[1, 1] <- 3
data[1, 1] <- 3
```

- We prefer a data format like the one shown on the right.

::::{.columns}
:::{.column width="49%"}
```{r ex8-1, echo=TRUE}
data
```

:::{.callout-note icon=false}
## So tell me what is the value of $y_{23}$!
:::
:::

:::{.column width="2%"}
:::

:::{.column width="49%"}
```{r, echo=TRUE}
data_anova
```
:::
::::

<br>

```{r boxplot-ex81, out.width="80%", echo=FALSE, fig.align='center'}
#| label: fig-boxplot-isoflavone
#| fig-cap: Boxplot of the Isoflavone Content in 3 Types of Food
par(mfrow = c(1, 1))
boxplot(data, axes = FALSE, ylab = "",
        main = "Boxplot of Isoflavones", horizontal = FALSE)
axis(2)
axis(1, las = 1, at = 1:3, 
     labels = c("Cereals", "Energy Bars", "Veggie Burger"))
```

---------------------------------------------------------------

<span style="color:blue"> **Test Assumptions** </span>

- Assumptions:
  + $\sigma_1 = \sigma_2 = \sigma_3$ (I tested it).
  + Data are generated from a normal distribution for each type of food (QQ plots confirm this).


```{r normality-ex81, message = FALSE, out.width = "100%", fig.asp=0.35,echo=FALSE}
#| label: fig-qqplots
#| fig-cap: QQ plots for each type of food
par(mgp = c(2, 1, 0))
par(mar = c(3.5, 3.5, 1.5, 0))
qqPlot(y ~ food, data = data_anova, layout=c(1, 3))
# ad.test(data_ex78[data_ex78$additive == 1, 1])
# ad.test(data_ex78[data_ex78$additive == 2, 1])
# ad.test(data_ex78[data_ex78$additive == 3, 1])
```

<span style="color:blue"> **ANOVA Testing** </span>

- <span style="color:blue"> $\begin{align}&H_0: \mu_1 = \mu_2 = \mu_3\\&H_1: \mu_is \text{ not all equal} \end{align}$ </span>

```{r, out.width="100%", echo=FALSE, fig.align='center'}
knitr::include_graphics("./images/img-model/anova_table_k.png")
```


- We can do all the calculations and generate an ANOVA table using just one line of code, as shown below. 


```{r anova-ex81, echo=3}
options(digits = 6)
# summary(aov(y ~ source, data = df_ex81)) ## method 1
anova(lm(y ~ food, data = data_anova))
```



