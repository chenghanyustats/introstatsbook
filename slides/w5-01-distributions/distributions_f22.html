<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>MATH 4720/MSSC 5720 Introduction to Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr.¬†Cheng-Han Yu   Department of Mathematical and Statistical Sciences   Marquette University" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: left, inverse, middle, title-slide

.title[
# MATH 4720/MSSC 5720 Introduction to Statistics
]
.subtitle[
## Probability Distributions ‚ñ∂Ô∏è
]
.author[
### Dr.¬†Cheng-Han Yu <br> Department of Mathematical and Statistical Sciences <br> Marquette University
]
.date[
### September 26 2022
]

---

&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      var: "{\\mathrm{Var}}",
      cov: "{\\mathrm{Cov}}",
      bsbeta: "{\\boldsymbol{\\beta}}",
      bsalpha: "{\\boldsymbol{\\alpha}}",
      bsep: "{\\boldsymbol{\\epsilon}}"
    }
  }
});
&lt;/script&gt;





&lt;!-- layout: true --&gt;

&lt;!-- &lt;style&gt; --&gt;
&lt;!-- p.caption { --&gt;
&lt;!--   font-size: 0.6em; --&gt;
&lt;!-- } --&gt;
&lt;!-- &lt;/style&gt; --&gt;

&lt;!-- &lt;div class="my-footer"&gt; --&gt;
&lt;!-- &lt;span&gt; --&gt;
&lt;!-- &lt;a href="https://d2l.mu.edu/d2l/home/431031" target="_blank"&gt;D2L Website&lt;/a&gt; --&gt;
&lt;!-- &lt;/span&gt; --&gt;
&lt;!-- &lt;/div&gt; --&gt;

&lt;!-- &lt;style type="text/css"&gt; --&gt;
&lt;!-- .caption { --&gt;
&lt;!--     font-size: x-small; --&gt;
&lt;!--     text-align: center; --&gt;
&lt;!-- } --&gt;
&lt;!-- &lt;/style&gt; --&gt;


---







background-image: url(https://upload.wikimedia.org/wikipedia/commons/1/1c/6sided_dice_%28cropped%29.jpg)
background-position: 50% 50%
background-size: cover
class: center, middle, inverse
# Random Variables


---
## Random Variables
- Recap: A **variable** in a data set is a characteristic that varies from one to another.
  + A variable can be either categorical or numerical.
  + Numerical variables can be either **discrete** or **continuous**.
  
--

- A **random variable**, usually written as `\(X\)` &lt;sup&gt;1&lt;/sup&gt;, is a variable whose possible values are **numerical** outcomes determined by **chance** or **randomness** of a procedure or experiment.
  + &lt;span style="color:blue"&gt; Toss a coin 2 times. `\(X\)` = # of heads. &lt;/span&gt; 
  + &lt;span style="color:blue"&gt; `\(X\)` = # of accidents in W. Wisconsin Ave. per day.&lt;/span&gt;

  &lt;!-- + `\(X\)` = time (in minutes) until next accident in W. Wisconsin Ave. --&gt;

- A random variable has a **probability distribution** associated with it, accounting for its randomness. 

.footnote[
[1] Usually in statistics, a capital `\(X\)` represents a random variable and a small `\(x\)` represents a realized value of `\(X\)`.
]


---
## Discrete and Continuous Random Variables
- A **discrete** random variable takes on a **finite** or **countable** number of values.
- A **continuous** random variable has **infinitely** many values, and the collection of values is **uncountable**.
- &lt;span style="color:blue"&gt; The number of relationships you've ever had is **discrete** variable because we can count the number and it is finite.&lt;/span&gt;
  + If we can further determine the probability that the number is 0, 1, 2, or any possible number, it is a **discrete random variable**.
- &lt;span style="color:blue"&gt; Height is **continuous** because it can be any number within a range. &lt;/span&gt; 
  + If we have a way to quantify the probability that the height is from any value `\(a\)` to any value `\(b\)`, it is a **continuous random variable**.








---
class: center, middle, inverse

&lt;!-- # Welcome Aboard! --&gt;

# Probability Distributions
## Discrete Distributions
## Continuous Distributions

---
## A Statistician Should Know
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/common_dist.png" alt="https://github.com/rasmusab/distribution_diagrams" width="50%" /&gt;
&lt;p class="caption"&gt;https://github.com/rasmusab/distribution_diagrams&lt;/p&gt;
&lt;/div&gt;


---
class: center, middle
## What We Learn Here
### Binomial Distribution
### Poisson Distribution
### Normal Distribution




---
exclude: true
## Discrete and Continuous Random Variables
- A **discrete** random variable takes on a **finite** or **countable** number of values.
- A **continuous** random variable has **infinitely** many values, and the collection of values is **uncountable**.
- &lt;span style="color:blue"&gt; The number of relationships you ever had is **discrete** variable because we can count the number and it is finite.&lt;/span&gt; If we can further determine the probability that the number is 0, 1, 2, or any possible number, it is a **discrete random variable**.
- &lt;span style="color:blue"&gt; Height is **continuous** because it can be any number within a range. &lt;/span&gt; If we have a way to quantify the probability that the height is from any value `\(a\)` to any value `\(b\)`, it is a **continuous random variable**.

---
background-image: url(./img/Poisson.jpg)
background-position: 50% 50%
background-size: cover
class: center, middle, inverse
# Discrete Probability Distributions

---

## Discrete Probability Distribution

- The **probability (mass) function** of a discrete random variable (rv) `\(X\)` is a function `\(P(X = x)\)` (or `\(p(x)\)`) that assigns a probability for **every** possible number `\(x\)`. 
- The **probability distribution** for a discrete r.v. `\(X\)` *displays* its **probability function**.
- The display can be a *table*, *graph*, or *mathematical formula* of `\(P(X = x)\)`. 

--

&lt;span style="color:blue"&gt; **Example:** ü™ôü™ô Toss a fair coin twice independently and `\(X\)` is the number of heads. &lt;/span&gt;
- The probability distribution of `\(X\)` as a table is 

&lt;table&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; x &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; P(X = x) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.25 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.25 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


--

.alert[
üëâ `\(\{X = x\}\)` is an event corresponding to an event of some experiment.
]

--

.question[
What is the event that `\(\{X = 0\}\)` corresponds to?
]

--

.question[
How do we get `\(P(X = 0)\)`, `\(P(X=1)\)` and `\(P(X=2)\)` ?
]



---
## Discrete Probability Distribution as a Graph 
&lt;!-- - Probability Histogram --&gt;
&lt;img src="distributions_f22_files/figure-html/discrete_prob_dist_graph-1.png" width="40%" style="display: block; margin: auto;" /&gt;
- `\(0 \le P(X = x) \le 1\)` for every value `\(x\)` of `\(X\)`.
  + &lt;span style="color:blue"&gt; `\(x = 0, 1, 2\)` &lt;/span&gt;
  
--

- `\(\sum_{x}P(X=x) = 1\)`, where `\(x\)` assumes all possible values.
  + &lt;span style="color:blue"&gt; `\(P(X=0) + P(X = 1) + P(X = 2) = 1\)` &lt;/span&gt;
  
--

- The probabilities for a discrete r.v. are **additive** because `\(\{X = a\}\)` and `\(\{X = b\}\)` are *disjoint* for any possible values `\(a \ne b\)`.
  + &lt;span style="color:blue"&gt; `\(P(X = 1 \text{ or } 2) = P(\{X = 1\} \cup \{X = 2\}) = P(X = 1) + P(X = 2)\)`. &lt;/span&gt;





---
## Mean of a Discrete Random Variable
- Suppose `\(X\)` takes values `\(x_1, \dots, x_k\)` with probabilities `\(P(X = x_1), \dots, P(X = x_k)\)`.
- The **mean** or **expected value** of `\(X\)` is the sum of each outcome multiplied by its corresponding probability:
`$$E(X) := x_1 \times P(X = x_1) + \dots + x_k \times P(X = x_k) = \sum_{i=1}^kx_iP(X=x_i)$$`
- The Greek letter `\(\mu\)` may be used in place of the notation `\(E(X)\)`.


--
.alert[
üëâ The mean of a discrete random variable `\(X\)` is the **weighted average** of possible values `\(x\)` *weighted by their corresponding probability*.
]


--

.question[
What is the mean of `\(X\)` (the number of heads) in the previous example?
]


---
## Variance of a Discrete Random Variable
- Suppose `\(X\)` takes values `\(x_1, \dots , x_k\)` with probabilities `\(P(X = x_1), \dots, P(X = x_k)\)` and expected value `\(\mu = E(X)\)`.
- The variance of `\(X\)`, denoted by `\(\var(X)\)` or `\(\sigma^2\)`, is `$$\small \var(X) := (x_1 - \mu)^2 \times P(X = x_1) + \dots + (x_k - \mu)^2 \times P(X = x_k) = \sum_{i=1}^k(x_i - \mu)^2P(X=x_i)$$`
- The standard deviation of `\(X\)`, `\(\sigma\)`, is the square root of the variance.



--
.alert[
üëâ The variance of a discrete random variable `\(X\)` is the *weighted sum of squared deviation* from the mean weighted by probability values.
]

--
.question[
What is the variance of `\(X\)` (the number of heads) in the previous example?
]


---
class: center, middle, inverse
# Binomial Distribution

---
## Binomial Experiment and Random Variable
- A **binomial experiment** is the one having the following properties:
  1. üëâ The experiment consists of a **fixed** number of **identical** trials `\(n\)`.
  2. üëâ Each trial results in one of **exactly two** outcomes (*success* (S) and *failure* (F)).
  3. üëâ Trials are **independent**, meaning that the outcome of any trial does not affect the outcome of any other trial.
  4. üëâ The probability of success is **constant** for all trials.
- If `\(X\)` is defined as  &lt;span style="color:blue"&gt; the number of successes observed in `\(n\)` trials &lt;/span&gt;, `\(X\)` is a binomial random variable.

--

.alert[
- The word *success* just means one of the two outcomes, and *does not necessarily mean something good. *
- üò≤ Can define *Drug abuse* as success and *No drug abuse* as failure.
]



---
## Binomial Distribution
- The probability function `\(P(X = x)\)` of a binomial r.v. `\(X\)` can be *fully* determined by 
  + the number of trials `\(n\)`
  + probability of success `\(\pi\)`
- Different `\((n, \pi)\)` pairs generate different binomial probability distributions.
- `\(X\)` is said to follow a binomial distribution with **parameters** `\(n\)` and `\(\pi\)`, written as `\(\color{blue}{X \sim binomial(n, \pi)}\)`.
- The binomial probability function is 
$$ \color{blue}{P(X = x \mid n, \pi) = \frac{n!}{x!(n-x)!}\pi^x(1-\pi)^{n-x}, \quad x = 0, 1, 2, \dots, n}$$ with mean `\(\mu = E(X) = n\pi\)` and variance `\(\sigma^2 = \var(X) = n\pi(1-\pi)\)`.


--

.question[
Tossing a fair coin two times independently. Let `\(X =\)` # of heads. Is `\(X\)` a binomial r.v.?
]




---
## Binomial Distribution Example
.pull-left-wide[
Assume that 20% of all drivers have a blood alcohol level above the legal limit. For a random sample of 15 vehicles, compute the probability that:
  1. Exactly 6 of the 15 drivers will *exceed* the legal limit.
  
  2. Of the 15 drivers, 6 or more will *exceed* the legal limit.
]


.pull-right-narrow[
&lt;img src="./img/alcohol.jpeg" width="60%" style="display: block; margin: auto;" /&gt;
]


--

- Suppose it is a binomial experiment with `\(n = 15\)` and `\(\pi = 0.2\)`. 
- Let `\(X\)` be the number of drivers exceeding limit. 
- `\(X \sim binomial(15, 0.2)\)`.

$$ \color{blue}{P(X = x \mid n=15, \pi=0.2) = \frac{15!}{x!(15-x)!}(0.2)^x(1-0.2)^{15-x}, \quad x = 0, 1, 2, \dots, n}$$


---
## Binomial Distribution Example `\(X \sim binomial(15, 0.2)\)`

&lt;img src="distributions_f22_files/figure-html/binomial_plot_noshow-1.png" width="80%" style="display: block; margin: auto;" /&gt;



---
## Binomial Distribution Example
.pull-left-wide[
Assume that 20% of all drivers have a blood alcohol level above the legal limit. For a random sample of 15 vehicles, compute the probability that:
  1. Exactly 6 of the 15 drivers will *exceed* the legal limit.
  2. Of the 15 drivers, 6 or more will *exceed* the legal limit.
]


.pull-right-narrow[
&lt;img src="./img/alcohol.jpeg" width="60%" style="display: block; margin: auto;" /&gt;
]


--

  1. `\(\small P(X = 6) = \frac{n!}{x!(n-x)!}\pi^x(1-\pi)^{n-x} = \frac{15!}{6!(15-6)!}(0.2)^6(1-0.2)^{15-6} = 0.043\)`
  
--

  2. `\(\small P(X \ge 6) = p(6) + \dots + p(15) = 1 - P(X \le 5) = 1 - (p(0) + p(1) + \dots + p(5)) = 0.0611\)`
  


--

.tip[
Never do this by hand. We compute them using R!
]






---
## Binomial Example Computation in R
&lt;!-- - R Shiny app is at [Binomial Calculator](http://sctc.mscs.mu.edu:3838/sample-apps/Calculator/) --&gt;
- With `size` the number of trials and `prob` the probability of success,
  + **`dbinom(x, size, prob)`** to compute `\(P(X = x)\)`
  + **`pbinom(q, size, prob)`** to compute `\(P(X \le q)\)`
  + **`pbinom(q, size, prob, lower.tail = FALSE)`** to compute `\(P(X &gt; q)\)`
  
.pull-left[

```r
## 1. P(X = 6)
dbinom(x = 6, size = 15, prob = 0.2) 
```

```
## [1] 0.04299
```

```r
## 2. P(X &gt;= 6) = 1 - P(X &lt;= 5)
1 - pbinom(q = 5, size = 15, prob = 0.2) 
```

```
## [1] 0.06105
```
]

.pull-right[

```r
## 2. P(X &gt;= 6) = P(X &gt; 5)
pbinom(q = 5, size = 15, prob = 0.2, 
       lower.tail = FALSE)  
```

```
## [1] 0.06105
```
]


---
## Binomial(15, 0.2)

```r
plot(x = 0:15, y = dbinom(0:15, size = 15, prob = 0.2), 
     type = 'h', xlab = "x", ylab = "P(X = x)", 
     lwd = 5, main = "Binomial(15, 0.2)")
```

&lt;img src="distributions_f22_files/figure-html/binomial_plot-1.png" width="67%" style="display: block; margin: auto;" /&gt;



---
class: center, middle, inverse
# Poisson Distribution


---
## Poisson Random Variables
- If we like to count **the number of occurrences of some event over a unit of time or space (region)** and its associated probability, we could consider the **Poisson distribution**.
  + Number of COVID patients arriving at ICU in one hour
  + Number of Marquette students logging onto D2L in one day
  + Number of dandelions per square meter in Marquette campus

--

- Let `\(X\)` be a Poisson r.v. Then `\(\color{blue}{X \sim Poisson(\lambda)}\)`, where `\(\lambda\)` is the parameter representing the **mean** number of occurrences of the event in the interval.
`$$\color{blue}{P(X = x \mid \lambda) = \frac{\lambda^x e^{-\lambda}}{x!}, \quad x = 0, 1, 2, \dots}$$` with both mean and variance being equal to `\(\lambda\)`.



---
## Assumptions and Properties of Poisson Variables
- üëâ **Events occur one at a time**; two or more events do not occur at the same time or in the same space or spot.
- üëâ The occurrence of an event in a given period of time or region of space is **independent** of the occurrence of the event in a **nonoverlapping** time period or region of space.
- üëâ `\(\lambda\)` is **constant** of any period or region.




--

.question[
Can you find the difference between binomial and Poisson distributions?
]


--
- The Poisson distribution
  + is determined by one single parameter `\(\lambda\)`
  + has possible values `\(x = 0, 1, 2, \dots\)` with no upper limit (countable), while a binomial variable has possible values `\(0, 1, 2, \dots, n\)` (finite)


---
## Poisson Distribution Example 
.pull-left-wide[
Last year there were 4200 births at the University of Wisconsin Hospital. Assume `\(X\)` be the number of births in a given day at the center, and `\(X \sim Poisson(\lambda)\)`. Find
  1. `\(\lambda\)`, the mean number of births **per day**.
  2. the probability that on a randomly selected day, there are exactly 10 births.
  3. `\(P(X &gt; 10)\)`? 
]

.pull-right-narrow[
&lt;img src="./img/baby.jpeg" width="100%" style="display: block; margin: auto;" /&gt;
]

--

1. `\(\small \lambda = \frac{\text{Number of birth in a year}}{\text{Number of days}} = \frac{4200}{365} = 11.5\)`

--

2. `\(\small P(X = 10 \mid \lambda = 11.5) = \frac{\lambda^x e^{-\lambda}}{x!} = \frac{11.5^{10} e^{-11.5}}{10!} = 0.113\)`

--

3. `\(\small P(X &gt; 10) = p(11) + p(12) + \dots + p(20) + \dots\)` (No end!)
`\(\small P(X &gt; 10) = 1 - P(X \le 10) = 1 - (p(1) + p(2) + \dots + p(10))\)`.


---
## Poisson Example Compuatation in R
&lt;!-- - R Shiny app is at [Poisson Calculator](http://sctc.mscs.mu.edu:3838/sample-apps/Calculator/) --&gt;
&lt;!-- P(X &lt;= 10) = 0.392 --&gt;
- With `lambda` the mean of Poisson distribution, 
  + **`dpois(x, lambda)`** to compute `\(P(X = x)\)`
  + **`ppois(q, lambda)`** to compute `\(P(X \le q)\)`
  + **`ppois(q, lambda, lower.tail = FALSE)`** to compute `\(P(X &gt; q)\)`

.pull-left[

```r
(lam &lt;- 4200 / 365)
```

```
## [1] 11.51
```

```r
## P(X = 10)
dpois(x = 10, lambda = lam)  
```

```
## [1] 0.1128
```
]

.pull-right[

```r
## P(X &gt; 10) = 1 - P(X &lt;= 10)
1 - ppois(q = 10, lambda = lam)  
```

```
## [1] 0.599
```

```r
## P(X &gt; 10)
ppois(q = 10, lambda = lam, 
      lower.tail = FALSE) 
```

```
## [1] 0.599
```
]


---
## Poisson(11.5)
- `\(X\)` has no upper limit. The graph is *truncated* at `\(x = 24\)`. 

```r
plot(0:24, dpois(0:24, lambda = lam), type = 'h', lwd = 5, 
     ylab = "P(X = x)", xlab = "x", main = "Poisson(11.5)")
```

&lt;img src="distributions_f22_files/figure-html/poisson_plot-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---
exclude:true
## Poisson as Approximation to Binomial
- When `\(n \ge 100\)`, `\(\pi \le 0.01\)` and `\(n\pi \le 20\)`, `\(binomial(n, \pi) \approx Poisson(\mu = n\pi)\)`.

&lt;img src="distributions_f22_files/figure-html/poisson_approx-1.png" width="95%" style="display: block; margin: auto;" /&gt;


---
background-image: url(./img/Gauss.jpg)
background-position: 50% 50%
background-size: cover
class: center, middle, inverse
# Continuous Probability Distributions

---
## Continuous Probability Distributions
- A continuous r.v. can take on **any** values from *an interval of the real line*.
- Instead of probability functions, a continuous r.v. `\(X\)` has the **probability density function (pdf)** `\(f(x)\)` such that for any real value `\(a &lt; b\)`,
`$$P(a &lt; X &lt; b) = \int_{a}^b f(x) dx$$`
- The **cumulative distribution function (cdf)** of `\(X\)` is defined as
`$$F(x) := P(X \le x) = \int_{-\infty}^x f(t)dt$$`
--

- Every pdf must satisfy &lt;span style="color:blue"&gt; (1) `\(f(x) \ge 0\)` for all `\(x\)`; (2) `\(\int_{-\infty}^{\infty} f(x) dx = 1\)` &lt;/span&gt;

--

üòé Luckily we don't deal with integrals in this course.


---
## Density Curve
- A pdf generates a graph called the **density curve** that shows the *likelihood* of a random variable at all possible values.
- `\(P(a &lt; X &lt; b) = \int_{a}^b f(x) dx\)`: **The area under the density curve between `\(a\)` and `\(b\)`.**
- `\(\int_{-\infty}^{\infty} f(x) dx = 1\)`: **The total area under any density curve is equal to 1.**

&lt;img src="distributions_f22_files/figure-html/unnamed-chunk-7-1.png" width="50%" style="display: block; margin: auto;" /&gt;


---
## Commonly Used Continuous Distributions
- R Shiny app is at [Continuous Distribution](http://sctc.mscs.mu.edu:3838/sample-apps/Calculator/)
- In this course, we will touch **normal (Gaussian)**, **student's t**, **chi-square**, **F**
- Some other common distributions include **uniform**, **exponential**, **gamma**, **beta**, **inverse gamma**, **Cauchy**, etc. (MATH 4700)


---
## Normal (Gaussian) Distribution
-  The normal distribution, `\(N(\mu, \sigma^2\)`), has the pdf given by
`$$\small f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}, \quad -\infty &lt; x &lt; \infty$$`
  + Two parameters mean `\(\mu\)` and variance `\(\sigma^2\)` (standard deviation `\(\sigma\)`)
  + Always bell shaped, and symmetric about the mean `\(\mu\)`
  + When `\(\mu = 0\)` and `\(\sigma = 1\)`, `\(N(0, 1)\)` is called **standard normal**.

&lt;img src="distributions_f22_files/figure-html/normal_density-1.png" width="35%" style="display: block; margin: auto;" /&gt;

---
## Normal Density Curves
&lt;img src="distributions_f22_files/figure-html/normal_densities-1.png" width="75%" style="display: block; margin: auto;" /&gt;



---
exclude:true
## The Empirical Rule
- Approximately 68% of the observations fall within `\(\sigma\)` of the mean `\(\mu\)`.
- Approximately 95% of the observations fall within `\(2\sigma\)` of the mean `\(\mu\)`.
- Approximately 99.7% of the observations fall within `\(3\sigma\)` of the mean `\(\mu\)`.
&lt;img src="distributions_f22_files/figure-html/689599-1.png" width="60%" style="display: block; margin: auto;" /&gt;






---
## Standardization and Z-Scores 
- **Standardization**: Convert `\(N(\mu, \sigma^2)\)` to `\(N(0, 1)\)`.
- **Why standardization**: Put data onto a *standardized scale*, making comparisons easier!
.question[
|Measure         | SAT               | ACT         |
|:-------------:|:-----------------:|:------------:|
| Mean          | 1100              | 21          |  
| SD            | 200               | 6           |

- The distribution of SAT and ACT scores are both nearly normal. 
- Suppose Anna scored 1300 on her SAT and Tommy scored 24 on his ACT. Who performed better?
]

&lt;img src="./img/sat_act.jpeg" width="50%" style="display: block; margin: auto;" /&gt;



---
## Standardization and Z-Scores
-  If `\(x\)` is an observation from a distribution with mean `\(\mu\)` and standard deviation `\(\sigma\)`, the standardized value of `\(x\)` is so-called ** `\(z\)`-score **:
`$$z = \frac{x - \mu}{\sigma}$$`
- A `\(z\)`-score tells us how many standard deviations `\(x\)` falls away from the mean, and in which direction.
  + Observations **larger (smaller)** than the mean have **positive (negative)** `\(z\)`-scores.
  + A `\(z\)`-score -1.2 means that `\(x\)` is 1.2 standard deviations to the **left** of (**below**) the mean.
  + A `\(z\)`-score 1.8 means that `\(x\)` is 1.8 standard deviations to the **right** of (**above**) the mean.
- &lt;span style="color:blue"&gt;  If `\(X \sim N(\mu, \sigma^2)\)`, `\(Z = \frac{X - \mu}{\sigma}\)` follows the standard normal distribution, i.e., `\(Z \sim N(0, 1)\)`. &lt;/span&gt;




---
## Standardization Illustration
- `\(X - \mu\)` shifts the mean from `\(\mu\)` to 0

&lt;img src="distributions_f22_files/figure-html/standardization_shift-1.png" width="65%" style="display: block; margin: auto;" /&gt;

--

- `\(\frac{X - \mu}{\sigma}\)` scales the variation from 4 to 1

&lt;img src="distributions_f22_files/figure-html/standardization_scale-1.png" width="65%" style="display: block; margin: auto;" /&gt;

---
## Standardization Illustration
- A value of `\(x\)` that is 2 standard deviation below `\(\mu\)` corresponds to `\(z = -2\)`.
- `\(z = \frac{x  -\mu}{\sigma} \iff x = \mu + z\sigma\)`. If `\(z = -2\)`, `\(x = \mu - 2\sigma\)`.
&lt;img src="distributions_f22_files/figure-html/z_score-1.png" width="70%" style="display: block; margin: auto;" /&gt;




---
## SAT and ACT Example
- `\(z_{A} = \frac{x_{A} - \mu_{SAT}}{\sigma_{SAT}} = \frac{1300-1100}{200} = 1\)`; `\(z_{T} = \frac{x_{T} - \mu_{ACT}}{\sigma_{ACT}} = \frac{24-21}{6} = 0.5\)`.
&lt;img src="distributions_f22_files/figure-html/sat-1.png" width="70%" style="display: block; margin: auto;" /&gt;




---
exclude:true
## Example of normal distribution
- The length of human pregnancies from conception to birth varies according to a normal distribution with mean 266 days and standard deviation 16 days. 
  1. Let `\(X\)` be the length (in days) of a random pregnancy. What is the distribution of `\(X\)`?
  2. A pregnancy was 250 days long, what is its `\(z\)`-score?
  3. A `\(z\)`-score is 1.5, what is the corresponding pregnancy length?
  1. &lt;span style="color:blue"&gt; `\(X \sim N(266, 16^2).\)` &lt;/span&gt;
  2. &lt;span style="color:blue"&gt; `\(x = 250\)`, therefore `\(z = \frac{x - \mu}{\sigma} = \frac{250 - 266}{16}\)` = -1. &lt;/span&gt;
  3. &lt;span style="color:blue"&gt; Since `\(x = \mu + z \cdot \sigma\)`, `\(x = 266 + 1.5 \cdot 16 = 290.\)`&lt;/span&gt;


---
## Finding Tail Areas `\(P(X &lt; x)\)`
.question[
What fraction of students have an SAT score below Anna's score of 1300?
]
- This is the same as the percentile Anna is at, which is the percentage of cases that have lower scores than Anna.
- Need `\(P(X &lt; 1300 \mid \mu = 1100, \sigma = 200)\)` or `\(P(Z &lt; 1 \mid \mu = 0, \sigma = 1)\)`.

&lt;img src="distributions_f22_files/figure-html/tail-1.png" width="50%" style="display: block; margin: auto;" /&gt;



---
exclude:true
## Finding Tail Areas `\(P(Z &lt; z)\)`
- Normal table (Table C.1 in OI and A-2 in BIO)
&lt;img src="./img/normal_table.png" width="50%" style="display: block; margin: auto;" /&gt;



---
## Finding Tail Areas `\(P(X &lt; x)\)` in R

- With **`mean`** and **`sd`** representing the mean and standard deviation of a normal distribution
  + **`pnorm(q, mean, sd)`** to compute `\(P(X \le q)\)`
  + **`pnorm(q, mean, sd, lower.tail = FALSE)`** to compute `\(P(X &gt; q)\)`

--

.pull-left[
&lt;img src="distributions_f22_files/figure-html/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[

```r
pnorm(1, mean = 0, sd = 1)
```

```
## [1] 0.8413
```

```r
pnorm(1300, mean = 1100, sd = 200)
```

```
## [1] 0.8413
```
- The shaded area represents the proportion 84.1% of SAT test takers who had z-score below 1.
]


---
exclude:true
## Finding Tail Areas `\(P(X &lt; x)\)` in R
.pull-left[
&lt;img src="distributions_f22_files/figure-html/unnamed-chunk-12-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[

```r
pnorm(1, mean = 0, sd = 1)
```

```
## [1] 0.8413
```

```r
pnorm(1300, mean = 1100, sd = 200)
```

```
## [1] 0.8413
```
]

- The shaded area represents the proportion 84.1% of SAT test takers who had z-score below 1.


---
## SAT Example Cont'd
- SAT score follows `\(N(1100, 200^2)\)`. Shannon is a SAT taker, and nothing is known about Shannon's SAT aptitude. What is the probability Shannon SAT scores at least 1190?
- &lt;span style="color:red"&gt; Step 1: State the problem &lt;/span&gt;
  +  &lt;span style="color:blue"&gt; We like to compute `\(P(X \ge 1190)\)`. &lt;/span&gt;
- &lt;span style="color:red"&gt; Step 2: Draw a picture
&lt;img src="distributions_f22_files/figure-html/unnamed-chunk-14-1.png" width="50%" style="display: block; margin: auto;" /&gt;

---
## SAT Example Cont'd
&lt;img src="distributions_f22_files/figure-html/unnamed-chunk-15-1.png" width="100%" style="display: block; margin: auto;" /&gt;

- &lt;span style="color:red"&gt; Step 3: Find `\(z\)`-score &lt;/span&gt;: 
  + &lt;span style="color:blue"&gt; `\(z = \frac{1190 - 1100}{200} = 0.45\)` and we like to compute `\(P(X &gt; 1190) = P\left( \frac{X - \mu}{\sigma} &gt; \frac{1190 - 1000}{200} \right) = P(Z &gt; 0.45) = 1 - P(Z \le 0.45)\)` &lt;/span&gt;
- &lt;span style="color:red"&gt; Step 4: Find the area using `pnorm()` &lt;/span&gt;

```r
1 - pnorm(0.45)
```

```
## [1] 0.3264
```

---
## Normal Percentiles in R
- To get the `\(100p\)`-th percentile (or the `\(p\)` quantile `\(q\)` ), given probability `\(p\)`, we use
  + **`qnorm(p, mean, sd)`** to get a value of `\(X\)`, `\(q\)`, such that `\(P(X \le q) = p\)` 
  + **`qnorm(p, mean, sd, lower.tail = FALSE)`** to get `\(q\)` such that `\(P(X \ge q) = p\)`


---
## SAT Example
- What is the 95th percentile for SAT scores?
- &lt;span style="color:red"&gt; Step 1: State the problem &lt;/span&gt;
  +  &lt;span style="color:blue"&gt; We like to find `\(x\)` s.t `\(P(X &lt; x) = 0.95\)`. &lt;/span&gt;
- &lt;span style="color:red"&gt; Step 2: Draw a picture
&lt;img src="distributions_f22_files/figure-html/unnamed-chunk-17-1.png" width="40%" style="display: block; margin: auto;" /&gt;

.alert[
**Find a `\(x\)` value of the normal distribution, not an area (probability), which is 0.95.**
]

---
## SAT Example Cont'd
- &lt;span style="color:red"&gt; Step 3: Find `\(z\)`-score s.t. `\(P(Z &lt; z) = 0.95\)` using `qnorm()`&lt;/span&gt;: 

```r
(z_95 &lt;- qnorm(0.95))
```

```
## [1] 1.645
```

- &lt;span style="color:red"&gt; Step 4: Find the `\(x\)` of the original scale &lt;/span&gt;
  + &lt;span style="color:blue"&gt; `\(z_{0.95} = \frac{x-\mu}{\sigma}\)`. So `\(x = \mu + z_{0.95}\sigma\)`. &lt;/span&gt;

```r
(x_95 &lt;- 1100 + z_95 * 200)
```

```
## [1] 1429
```
- The 95th percentile for SAT scores is 1429.

--

```r
qnorm(p = 0.95, mean = 1100, sd = 200)
```

```
## [1] 1429
```

---
## Finding Probabilties
üëâ **ALWAYS draw and label the normal curve and shade the area of interest.**

- üëâ **Less than**
  + `\(\small P(X &lt; x) = P(Z &lt; z)\)`
  + `pnorm(z, mean = 0, sd = 1)`
  + `pnorm(x, mean = mu, sd = sigma)`
- üëâ **Greater than**
  + `\(\small P(X &gt; x) = P(Z &gt; z) = 1 - P(Z \le z)\)`
  + `1 - pnorm(z)`

.alert[
- üëâ Standardization is not a must. 
- üëâ We have to specify the mean and SD of the original distribution of `\(X\)`, like `pnorm(x, mean = mu, sd = sigma)`.
]

---
## Finding Probabilties

- üëâ **Between two numbers**
  + `\(\small P(a &lt; X &lt; b) = P(z_a &lt; Z &lt; z_b) = P(Z &lt; z_b) - P(Z &lt; z_a)\)`
  + `pnorm(z_b) - pnorm(z_a)`
- üëâ **Outside of two numbers** `\((a &lt; b)\)`
`$$\small \begin{align} P(X &lt; a \text{ or } X &gt; b) &amp;= P(Z &lt; z_a \text{ or } Z &gt; z_b) \\ &amp;= P(Z &lt; z_a) + P(Z &gt; z_b) \\ &amp;= P(Z &lt; z_a) + 1 - P(Z &lt; z_b) \end{align}$$`
  + `pnorm(z_a) + 1 - pnorm(z_b)`
  + `pnorm(z_a) + pnorm(z_b, lower.tail = FALSE)`


.alert[
- üëâ Any probability can be computed using the *"less than"* form (*lower* or *left* tail).
- üëâ If the calculation involves the "greater than" form, add `lower.tail = FALSE` in `pnorm()`.
]


---
## Checking Normality: Normal Quantile Plot
- Many statistical methods assume variables are normally distributed.
- Testing the appropriateness of the normal assumption is a key step.
- A **normal quantile plot (normal probability plot)** or a **Quantile-Quantile plot (QQ plot)** helps us check normality assumption.
  + `\(X\)`-axis: Quantiles of the *ordered* data if the data were normally distributed.
  + `\(Y\)`-axis: *Ordered* data values
- If the data are like normally distributed, the points on the QQ plot will lie close to a **straight line**.




---
## QQ plot in R

```r
qqnorm(normal_sample, main = "Normal data", col = 4)
qqline(normal_sample)
qqnorm(right_skewed_sample, main = "Right-skewed data", col = 6)
qqline(right_skewed_sample)
```

&lt;img src="distributions_f22_files/figure-html/qqplot-1.png" width="60%" style="display: block; margin: auto;" /&gt;



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9.5",
"highlightLines": true,
"highlightStyle": "tomorrow-night-bright",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
