# Bayesian Inference {#sec-infer-bayes}

{{< include macros.qmd >}}

```{r}
#| echo: false
source("./_common.R")
```

The inference methods we have learned so far assume that unknown (population) parameters to be estimated or tested are constants. They are fixed and their values do not change. In other words, the parameters are not random variables, and the uncertainty that arises when estimating them is entirely due to sampling variation, not the variability of the parameters themselves. Additionally, when dealing with uncertainty, we use relative frequency to describe probabilities. Lots of times the answer to our questions relies on repetitions of experiments or trials. These methods adopt the so-called **frequentist** philosophy. The frequentist approach, also known as the classical approach, has dominated the statistics community since the early 20th century. This dominance followed the development of a comprehensive inference framework by several great statisticians, such as Ronald Fisher, Jerzy Neyman, and Egon Pearson. This framework, which includes confidence intervals, hypothesis testing, p-values, and statistical significance, is taught in every introductory statistics course.



In fact, there is another way of thinking about statistical inference: the **Bayesian** philosophy. The Bayesian approach did not emerge after the frequentist approach; rather, it has historical roots that trace back to Bayes' theorem (Bayes' rule), named after Thomas Bayes. People in the late 18th or early 19th century already used the Bayesian philosophy to tackle problems. For instance, Pierre-Simon Laplace used the Bayesian theorem to calculate the probability that the sun would rise the next day. However, the Bayesian approach lost popularity later on because as problems became more complex, solving them within the Bayesian framework became very tedious and time-consuming, especially given the lack of powerful computing resources at the time. With the advancement of computing power starting in the late 20th century, more statisticians and scientists began to embrace the Bayesian approach.

It is important to understand the frequentist and Bayesian philosophies, particularly their differences, advantages, and disadvantages. Depending on the research question and available resources, one method may be more suitable than the other. Alternatively, it may be beneficial to combine these two paradigms to leverage the advantages of both. Currently, introductory statistics courses focus heavily on the frequentist approach. Given the ease of computation and the increasing use of Bayesian methods in scientific research, it is time to introduce more Bayesian thinking to STAT 101 students, not just one lecture of Bayes theorem.


## Bayesian Thinking

Before we dive into Bayesian statistics, let's take a quiz to determine whether you currently lean more towards a Bayesian or frequentist mindset. This quiz is adapted from [Bayes Rules](https://www.bayesrulesbook.com/), a great new book on Bayesian statistics. I encourage you to spend some time on this if you would like to delve deeper.


1. [When flipping a fair coin, we say that "the probability of flipping Heads is 0.5." How do you interpret this probability?]{.green} *(a = 1 pt, b = 3 pts, c = 2 pts)*

    a. If I flip this coin over and over, roughly 50% will be Heads.
    b. Heads and Tails are equally plausible.
    c. Both a. and b. make sense.
  

2. [An election is coming up and a pollster claims that candidate Yu has a 0.9 probability of winning. How do you interpret this probability?]{.green} *(a = 1 pt, b = 3 pts, c = 1 pt)*

    a. If we observe the election over and over, candidate Yu will win roughly 90% of the time. 
    b. Candidate Yu is much more likely to win than to lose.
    c. The pollster’s calculation is wrong. Candidate Yu will either win or lose, thus their probability of winning can only be 0 or 1.


3. [Two claims.]{.green} *(a = 3 pts, b = 1 pt)*

    [(1) Ben claims he can predict the coin flip outcome. To test his claim, you flip a fair coin 8 times and he correctly predicts all.]{.green} 
    
    [(2) Emma claims she can distinguish natural and artificial sweeteners. To test her claim, you give her 8 samples and she correctly identifies each.]{.green} 
    
    [In light of these experiments, what do you conclude?]{.green}

    a. You're more confident in Emma's claim than Ben's claim.
    b. The evidence supporting Ben's claim is just as strong as the evidence supporting Emma's claim.


4. [Suppose that during a doctor’s visit, you tested positive for COVID. If you only get to ask the doctor one question, which would it be?]{.green} *(a = 3 pts, b = 1 pt)*

    a. What's the chance that I actually have COVID?
    b. If in fact I don't have COVID, what's the chance that I would've gotten this positive test result?


Time tally up your quiz score. Are you frequentist or Bayesian? Totals from 4–5 indicate that your current thinking is fairly frequentist, whereas totals from 9–12 indicate alignment with the Bayesian philosophy. In between these extremes, totals from 6–8 indicate that you see strengths in both philosophies.


:::: {.columns}

::: {.column width="50%"}
- Totals **4-5**: your thinking is **frequentist**

```{r}
#| echo: false
#| out-width: 80%
#| fig-cap: Young Fisher from Wiki
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/a/aa/Youngronaldfisher2.JPG")
```

:::


::: {.column width="50%"}
- Totals **9-12**: your thinking is **Bayesian**
```{r}
#| echo: false
#| fig-cap: Thomas Bayes from Wiki
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif")
```

:::

::::

- Totals **6-8**: you see strengths in both philosophies

You are a frequentist or Bayesian? Are those confidence interval or hypothesis testing thing all Greek to you? Maybe it is because 


## The Meaning of Probability: **Relative Frequency** vs. **Relative Plausibility** 

The *frequentist* interprets probability as the [*long-run* relative frequency of a *repeatable* experiment]{.green}. We've seen this interpretation before in @sec-prob-define. We know that using relative frequencies as probability has several issues:

- `r emo::ji('confused')` How large of a number is large enough? 

- `r emo::ji('confused')` Meaning of "under similar conditions"

- `r emo::ji('confused')` The relative frequency is reliable under identical conditions?

- `r emo::ji('point_right')`  We only obtain an approximation instead of exact value.

- `r emo::ji('joy')`  How do you compute the probability that Chicago Cubs wins the World Series next year? 

```{r}
knitr::include_graphics("https://media.giphy.com/media/EKURBxKKkw0uY/giphy.gif")
```

In statistical inference, our research questions or events of interest are often not repeatable or very difficult to replicate. For example, what is the probability that Donald Trump will win the 2024 presidential election? What is the probability that the Milwaukee Bucks will win the 2025 NBA championship? What would the mean income level for males be if every man was required to serve in the military for two years? Still many political scientists, sport analysts, or economists are answering those questions, right?! To rationalize their arguments, and to better answer these types of research questions, we must interpret probability in a different way.

----------------------------------------------------------------------

In the *Bayesian* philosophy, a probability measures the [**relative plausibility**]{.green} of an event.

:::: {.columns}

::: {.column width="50%"}

For the statement "_candidate A has a 0.9 probability of winning_", a frequentist might say the conclusion is wrong or weirdly say in long-run *hypothetical* repetitions of the election, candidate A would win roughly 90% of the time. A Bayesian would say based on analysis the candidate A is 9 times more likely to win than to lose.

Back to our Quiz 1. For the statement "the probability of flipping Heads is 0.5", a frequentist would conclude that if we flip the coin over and over, roughly 1/2 of these flips will be Heads. A Bayesian would conclude that Heads and Tails are equally likely.

:::


::: {.column width="50%"}
:::{.small}
```{r}
#| out-width: "100%"
#| fig-cap: "Source: https://x.com/nytgraphics/status/796195155158171648"
knitr::include_graphics("./images/img-infer/winning.jpeg")
```
:::
:::
::::


## Prior Information and Empirical Evidence

> How can we live if we don’t change? 
> - Beyoncé. Lyric from “Satellites.”

Everybody changes their mind. You likely even changed your mind in the last minute. For example, suppose there’s a new Italian restaurant in your town. It has a 5-star online rating and you love Italian food! Thus, prior to ever stepping foot in the restaurant, you anticipate that it will be quite delicious. On your first visit, you collect some edible data: your pasta dish arrives a soggy mess. Weighing the stellar online rating against your own terrible meal (which might have just been a fluke), you update your knowledge: this is a 3-star not 5-star restaurant. Willing to give the restaurant another chance, you make a second trip. On this visit, you’re pleased with your Alfredo and increase the restaurant’s rating to 4 stars. You continue to visit the restaurant, collecting edible data and updating your knowledge each time.

```{r}
#| fig-cap: "Fig 1.1 of Bayes Rules. The figures not being sourced come from this book too."
#| fig-cap-location: bottom
#| label: fig-restaurant
knitr::include_graphics("./images/img-infer/restaurant_diagram.png")
```

- We use **data** and **prior beliefs** to update our knowledge (**posterior**), and repeating.

- We continuously update our knowledge about the world as we accumulate lived experiences, or *collect data*.


@fig-bayes shows Bayesian Knowledge-building Process. If you're an environmental scientist, yours might be an analysis of the human role in climate change. You don't walk into such an inquiry without context – you carry a degree of incoming or prior information based on previous research and experience. Naturally, it's in light of this information that you interpret new data, weighing both in developing your updated or posterior information.


```{r}
#| fig-cap-location: bottom
#| label: fig-bayes
#| out-width: 50%
knitr::include_graphics("./images/img-infer/bayes_diagram.png")
```


Frequentist relies on (limited) data only. In Question 3, in a frequentist analysis, "8 out of 8" is "8 out of 8" no matter if it's in the context of Ben's coins or Emma's sweeteners. 

- *Equally confident* conclusions that Ben can predict coin flips and Emma can distinguish between natural and artificial sweeteners.

```{r}
#| out-width: "30%"
#| fig-cap-location: bottom
knitr::include_graphics("./images/img-infer/freq_diagram.png")
```

- But do you really believe Ben's claim 100\%? `r emo::ji('thinking')` `r emo::ji('confused')`


- In fact, we judge their claim before evidence are collected, don't we? `r emo::ji('thinking')`

- You probably think Ben overstates his ability but Emma's claim sounds relatively reasonable, right?


<!-- ### The Bayesian Balancing -->

- Frequentist throws out all prior knowledge in favor of a mere 8 data points.

- Bayesian analyses *balance* and *weight* our prior experience/knowledge/belief and new data/evidence to judge a claim or make a conclusion.


```{r}
#| out-width: "56%"
#| fig-cap-location: bottom
knitr::include_graphics("./images/img-infer/bayes-balance-1.png")
```

:::: {.columns}

::: {.column width="80%"}
- [*We are not stubborn!*]{.green} If Ben had correctly predicted the outcome of *1 million* coin flips, the strength of this data would far surpass that of our prior judgement, leading to a posterior conclusion that perhaps Ben is psychic!
:::


::: {.column width="20%"}
```{r}
#| out-width: "60%"
knitr::include_graphics("./images/img-infer/psychic.jpeg")
```
:::
::::



## Asking Different Questions

:::: {.columns}

::: {.column width="80%"}


In Question 4,

- Bayesians answer (a) *what's the chance that I actually have COVID?*
- Frequentists answer (b) *if in fact I do not have COVID, what's the chance that I would’ve gotten this positive test result?*
:::


::: {.column width="20%"}

```{r}
knitr::include_graphics("./images/img-infer/covid.jpeg")
```
:::
::::

+---------------+---------------+----------------------+-------------+
|               | Test Positive | Test Negative        | Total       |
+===============+===============+======================+=============+
| COVID         | 3             | 1                    | 4           |
+---------------+---------------+----------------------+-------------+
| No COVID      | 9             | 87                   |  96         |
+---------------+---------------+----------------------+-------------+
| Total         | 12            | 88                   | 100         |
+---------------+---------------+----------------------+-------------+


- $H_0$: Do not have COVID vs. $H_1$: Have COVID

- A frequestist assesses *the uncertainty of the observed data in light of an assumed hypothesis* $P(Data \mid H_0) = 9/96$

- A Bayesian assesses *the uncertainty of the hypothesis in light of the observed data* $P(H_0 \mid Data) = 9/12$


A Bayesian analysis would ask: Given my positive test result, what’s the chance that I actually have the disease? Since only 3 of the 12 people that tested positive have the disease (Table 1.1), there’s only a 25% chance that you have the disease. Thus, when we take into account the disease’s rarity and the relatively high false positive rate, it’s relatively unlikely that you actually have the disease. What a relief. 

Since disease status isn’t repeatable, the probability you have the disease is either 1 or 0 – you have it or you don’t. To the contrary, medical testing (and data collection in general) is repeatable. You can get tested for the disease over and over and over. Thus, a frequentist analysis would ask: If I don’t actually have the disease, what’s the chance that I would’ve tested positive? Since only 9 of the 96 people without the disease tested positive, there’s a roughly 10% (9/96) chance that you would’ve tested positive even if you didn’t have the disease.



## Bayesian Model

Fake News

:::: {.columns}

::: {.column width="80%"}

- Tell if an incoming article is fake. The usage of an ! might seem odd for a real article. The exclamation point data is more consistent with fake news.

```{r}
# Load packages
library(bayesrules)
library(tidyverse)
library(janitor)

# Import article data
data(fake_news)
# glimpse(fake_news[, c("type", "title_has_excl")])
```


- [**Prior info**:]{.green} 40% of the articles are fake

```{r}
fake_news |>  
  tabyl(type) |>  
  adorn_totals("row")
```
::::


::: {.column width="20%"}
```{r}
knitr::include_graphics("./images/img-infer/fake_news.jpeg")
```
:::
::::

- [**Data come in**:]{.green} Check several fake and real articles, and found `!` is more consistent with fake news.

```{r}
# Tabulate exclamation usage and article type
fake_news |>  
  tabyl(title_has_excl, type) |> 
  adorn_totals("row")
```



--------------------------------------------------------------------------------

### Bayesian Updating Rule

```{r}
#| out-width: "60%"
#| fig-cap-location: bottom
knitr::include_graphics("./images/img-infer/fake_news_diagram.png")
```

- $F$: *an article is fake*.

- The **prior probability model**

+--------------------------+---------------+----------------------+-------------+
| Event                    | $F$           | $F^c$                | Total       |
+==========================+===============+======================+=============+
| Probability $P(\cdot)$   | 0.4           | 0.6                  | 1           |
+--------------------------+---------------+----------------------+-------------+

```{r}
fake_news |> 
  tabyl(title_has_excl, type) |> 
  adorn_totals("row")
```

- $D$: *an article title has exclamation mark*.

- Conditional probability: $P(D \mid F) = 16/60 = 0.27$; $P(D \mid F^c) = 2/90 = 0.02$.

- [ *Opposite position*]{.green}: 
    + Know the incoming article used `!` (observed data)
    + Don't know whether or not the article is fake (what we want to decide).

- Compare $P(D \mid F)$ and $P(D \mid F^c)$ to ascertain the relative **likelihoods** of *observed data* $D$ under different scenarios of the *uncertain* article status.

Since exclamation point usage is so much more likely among fake news than real news, this data provides some evidence that the article is fake To help distinguish this application of conditional probability calculations from that when D is uncertain and F is known, we’ll utilize the following likelihood function notation.


--------------------------------------------------------------------------------

### Likelihood Function

::: {.midi}
- **Likelihood function** $L(\cdot\mid D)$:


$$L(F \mid D) = P(D \mid F) \text{ and } L(F^c \mid D) = P(D \mid F^c)$$
:::

::: {.midi}
- When $F$ is known, the *conditional probability* function $P(\cdot \mid F)$ compares the probabilities of an unknown event $D$, $D^c$, occurring with $F$: 
$$P(D \mid F) \text{  vs. } P(D^c \mid F)$$
:::

::: {.midi}
- When $D$ is known, the *likelihood function* $L(\cdot \mid D) = P(D \mid \cdot)$ evaluates the *relative compatibility* of data $D$ with $F$ or $F^c$: 
$$L(F \mid D) \text{  vs. } L(F^c \mid D)$$
:::


::: {.small}
+-------------------------------+---------------+----------------------+-------------+
| Event                         | $F$           | $F^c$                | Total       |
+===============================+===============+======================+=============+
| Probability $P(\cdot)$        | 0.4           | 0.6                  | 1           |
+-------------------------------+---------------+----------------------+-------------+
| Likelihood  $L(\cdot \mid D)$ | 0.27          | 0.02                 | 0.29        |
+-------------------------------+---------------+----------------------+-------------+
:::

- [_The likelihood function is not a probability function!_]{.green}





--------------------------------------------------------------------------------

### Bayes' Rule

$$\begin{align*} P(F \mid D) &= \frac{P(F \cap D)}{P(D)}\\ &= \frac{L(F \mid D)P(F)}{P(D)}\end{align*}$$


$$\text{posterior = } \frac{\text{likelihood} \cdot \text{prior }}{ \text{normalizing constant}} $$

- The normalizing constant $P(D)$ is known as **marginal likelihood** or **evidence**.

--------------------------------------------------------------------------------

### Posterior

- Started with a prior understanding that there's a 40% chance that the incoming article would be fake.

- Yet upon observing the use of an exclamation point in the title 

::: {.center}

> *“The president has a funny secret!”*

:::

a feature that's more common to fake news.

- Our posterior understanding evolved quite a bit – the chance that the article is fake jumped to 89%.


+-------------------------------------+---------------+----------------------+-------------+
| Event                               | $F$           | $F^c$                | Total       |
+=====================================+===============+======================+=============+
| Prior prob  $P(\cdot)$              | 0.4           | 0.6                  | 1           |
+-------------------------------------+---------------+----------------------+-------------+
| Posterior prob $P(\cdot \mid D)$    | 0.89          | 0.11                 | 1           |
+-------------------------------------+---------------+----------------------+-------------+


## Bayesian Inference for Random Variables

For any random variables parameter $\theta$ and data ${\bf Y} = (Y_1, \dots, Y_n)$, 

- $\pi(\theta)$: the prior pmf/pdf of $\theta$

- $L(\theta \mid y_1,\dots, y_n)$: the likelihood of $\theta$ given observed data $\by = \{y_i \}_{i = 1}^n$. 

- The posterior distribution of $\theta$ given $\by$ is

$$\pi(\theta \mid \by) = \frac{L(\theta \mid \by)\pi(\theta)}{p(\by)}$$ where $$p(\by) = \begin{cases} \int_{\Theta} L(\theta \mid \by)\pi(\theta) ~ d\theta & \text{if } \theta \text{ is continuous }\\ 
\sum_{\theta \in \Theta} L(\theta \mid \by)\pi(\theta) & \text{if } \theta \text{ is discrete }
\end{cases}$$

--------------------------------------------------------------------------------

### Proportionality

$$\pi(\theta \mid \by) = \frac{L(\theta \mid \by)\pi(\theta)}{p(\by)} \propto_{\theta} L(\theta \mid \by)\pi(\theta)$$


$$\text{posterior } \propto \text{ likelihood } \cdot \text{ prior } $$

--------------------------------------------------------------------------------

### Motivation Example
:::: {.columns}

::: {.column width="70%"}


- Michelle has decided to run for governor of Wisconsin.

<!-- - You've conducted 30 different polls throughout the election season. -->

- According to *previous* 30 polls, 
  + Michelle's support is centered round 45%
  + she polled at around 35% in the dreariest days and around 55% in the best days

- With this prior information, we'd like to estimate/update Michelle's support by *conducting a new poll*.
:::


::: {.column width="30%"}

```{r}
knitr::include_graphics("./images/img-infer/vote.jpeg")
```
:::
::::


Key: Describe prior and data information using probabilistic models.


- The parameter to be estimated is $\theta$, the Michelle's support, which is between 0 and 1.



#### Prior Distribution

- A popular probability distribution for probability is **beta distribution**, $\text{beta}(\alpha, \beta)$, where $\alpha > 0$ and $\beta > 0$ are shape parameters.

$$\pi(\theta \mid \alpha, \beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1-\theta)^{\beta-1}$$

```{r}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/f/f3/Beta_distribution_pdf.svg")
```


- $\theta \sim \text{beta}(\alpha, \beta)$

- In the prior model, $\alpha$ and $\beta$ are **hyperparameters** to be chosen to reflect our prior information.

> Michelle's support is centered round 45%, and she polled at around 35% in the dreariest days and around 55% in the best days.

- Choose $\alpha$ and $\beta$ so that the *prior mean is about 0.45* and *the range is from 0.35 to 0.55*.


- $\E(\theta) = \frac{\alpha}{\alpha + \beta}$

- $\var(\theta) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$


```{r}
par(mar = c(3, 3, 2, 0), mgp = c(2, 0.6, 0))
x <- seq(0, 1, by = 0.0001)
plot(x, dbeta(x, 45, 55), type = "l", lwd = 3, col = 2, las = 1,
     xlab = expression(theta), ylab = expression(pi(theta)))
title(main = "Prior Distribtuion: beta(45, 55)")
```


#### Likelihood

> You plan to conduct a new poll of $n = 50$ Cheeseheads and record $Y$, the number that support Michelle.

::: {.question}
What distribution can be used for modeling likelihood connecting the data $y$ and the parameter we are interested, $\theta$?
:::

- If voters answer the poll *independently*, and the probability that any polled voter supports Michelle is $\theta$, we could consider 

$$Y \mid \theta \sim \text{binomial}(n=50, \theta)$$

- The poll result is $y = 30$, the likelihood is

$$L(\theta \mid y = 30) = {50 \choose 30}\theta^{30}(1-\theta)^{20}, \quad \theta \in (0, 1)$$

```{r}
par(mar = c(3, 3, 2, 0), mgp = c(2, 0.6, 0))
x <- seq(0, 1, by = 0.0001)
y <- choose(50, 30) * x ^ 30 * (1 - x) ^ 20
plot(x, y, type = "l", lwd = 3, col = 4, las = 1,
     xlab = expression(theta), ylab = expression(paste("L(", theta, " | ", y, ")")))
title(main = "Likelihood function")
```

#### Bayesian Model

$$\begin{align}Y \mid \theta &\sim \text{binomial}(n=50, \theta)\\ \theta &\sim \text{beta}(45, 55)
\end{align}$$

Goal: Obtain the posterior distribution $\pi(\theta \mid y)$.

$$
\begin{align} \pi(\theta \mid y) &\propto_{\theta} L(\theta \mid y)\pi(\theta) \\
&= {50 \choose 30}\theta^{30}(1-\theta)^{20} \times \frac{\Gamma(100)}{\Gamma(45)\Gamma(55)}\theta^{44}(1-\theta)^{54}\\
&\propto_{\theta} \theta^{74}(1-\theta)^{74}\\
&= \frac{\Gamma(150)}{\Gamma(75)\Gamma(75)} \theta^{74}(1-\theta)^{74} \\
&= \text{beta}(75, 75)\end{align}
$$

using the fact that $\int_{\mathcal{X}} f(x) dx = 1$ for any pdf $f(x)$.


#### Posterior Distribution

```{r}
plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50)
```


<!-- #### Take-home Message -->

<!-- - The parameter is a random variable in the Bayesian world. -->

<!-- - It is fixed and constant in the frequentist world. -->





## Further Reading and References

- [Bayes Rules](https://www.bayesrulesbook.com/)

- [All About that Bayes: Probability, Statistics, and the Quest to Quantify Uncertainty](https://www.youtube.com/watch?v=eDMGDhyDxuY) by Dr. Kristin Lennox


- [The Equation of Knowledge](https://www.amazon.com/Equation-Knowledge-Unified-Philosophy-Science/dp/0367428156) by Dr. Le Nguyen Hoang
