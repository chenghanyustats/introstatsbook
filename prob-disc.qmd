# Discrete Probability Distributions {#sec-prob-disc}

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(emoji)
library(knitr)
library(kableExtra)
library(openintro)
```


## Discrete Probability Distribution

- The **probability (mass) function** of a discrete random variable (rv) $X$ is a function $P(X = x)$ (or $p(x)$) that assigns a probability for **every** possible number $x$. 
- The **probability distribution** for a discrete r.v. $X$ *displays* its **probability function**.
- The display can be a *table*, *graph*, or *mathematical formula* of $P(X = x)$. 

<span style="color:blue"> **Example:**ðŸª™ðŸª™ Toss a fair coin twice independently and $X$ is the number of heads. </span>

- The probability distribution of $X$ as a table is 

```{r discrete_prob_dist_table, echo=FALSE, fig.align='center'}
prob_function <- cbind("x" = c(0, 1, 2), "P(X = x)" = c(0.25, 0.5, 0.25))
# kable(prob_function, format = "pipe")
# kable(print(as.data.frame(prob_function), row.names = FALSE))
prob_function_horizontal <- rbind("x" = c("0", "1", "2"), "P(X = x)" = c(0.25, 0.5, 0.25))
# print(as.data.frame(t(prob_function)), row.names = FALSE)
# print(unname(as.data.frame(prob_function_horizontal)))
kable(prob_function_horizontal)
```

:::{.callout-tip icon=false}

## `r emoji('point_right')` $\{X = x\}$ is an event corresponding to an event of some experiment.

:::

:::{.callout-note icon=false}

## What is the event that $\{X = 0\}$ corresponds to?

:::

:::{.callout-note icon=false}

## How do we get $P(X = 0)$, $P(X=1)$ and $P(X=2)$ ?

:::

## Discrete Probability Distribution as a Graph 
<!-- - Probability Histogram -->
```{r discrete_prob_dist_graph, echo=FALSE, out.width="40%", fig.asp=0.5, fig.align='center'}
par(mar = c(4, 4, 0, 0))
plot(c("0", "1", "2"), c(0.25, 0.5, 0.25), type = "h", ylim = c(0, 0.75),
     lwd = 5, col = "#003366", ylab = "P(X = x)", xlab = "x", las = 1, axes = F)
points(c("0", "1", "2"), c(0.25, 0.5, 0.25), pch = 16, cex = 2, col = "#FFCC00")
axis(1, 0:2, c("0", "1", "2"), col.axis = "black")
axis(2, seq(0, 0.75, by = 0.25), col.axis = "black", las = 2)
```
- $0 \le P(X = x) \le 1$ for every value $x$ of $X$.

  + <span style="color:blue"> $x = 0, 1, 2$ </span>
  


- $\sum_{x}P(X=x) = 1$, where $x$ assumes all possible values.

  + <span style="color:blue"> $P(X=0) + P(X = 1) + P(X = 2) = 1$ </span>
  


- The probabilities for a discrete r.v. are **additive** because $\{X = a\}$ and $\{X = b\}$ are *disjoint* for any possible values $a \ne b$.

  + <span style="color:blue"> $P(X = 1 \text{ or } 2) = P(\{X = 1\} \cup \{X = 2\}) = P(X = 1) + P(X = 2)$. </span>

## Mean of a Discrete Random Variable
- Suppose $X$ takes values $x_1, \dots, x_k$ with probabilities $P(X = x_1), \dots, P(X = x_k)$.
- The **mean** or **expected value** of $X$ is the sum of each outcome multiplied by its corresponding probability:
$$E(X) := x_1 \times P(X = x_1) + \dots + x_k \times P(X = x_k) = \sum_{i=1}^kx_iP(X=x_i)$$
- The Greek letter $\mu$ may be used in place of the notation $E(X)$.

:::{.callout-tip icon=false}

## `r emoji('point_right')` The mean of a discrete random variable $X$ is the **weighted average** of possible values $x$ *weighted by their corresponding probability*.

:::

:::{.callout-note icon=false}

## What is the mean of $X$ (the number of heads) in the previous example?

:::

## Variance of a Discrete Random Variable
- Suppose $X$ takes values $x_1, \dots , x_k$ with probabilities $P(X = x_1), \dots, P(X = x_k)$ and expected value $\mu = E(X)$.
- The variance of $X$, denoted by $Var(X)$ or $\sigma^2$, is $$\small Var(X) := (x_1 - \mu)^2 \times P(X = x_1) + \dots + (x_k - \mu)^2 \times P(X = x_k) = \sum_{i=1}^k(x_i - \mu)^2P(X=x_i)$$
- The standard deviation of $X$, $\sigma$, is the square root of the variance.

:::{.callout-tip icon=false}

## `r emoji('point_right')` The variance of a discrete random variable $X$ is the *weighted sum of squared deviation* from the mean weighted by probability values.

:::

:::{.callout-note icon=false}

## What is the variance of $X$ (the number of heads) in the previous example?

:::

## Binomial Experiment and Random Variable
- A **binomial experiment** is the one having the following properties:

  1. `r emoji('point_right')` The experiment consists of a **fixed** number of **identical** trials $n$.
  
  2. `r emoji('point_right')` Each trial results in one of **exactly two** outcomes (*success* (S) and *failure* (F)).
  
  3. `r emoji('point_right')` Trials are **independent**, meaning that the outcome of any trial does not affect the outcome of any other trial.
  
  4. `r emoji('point_right')` The probability of success is **constant** for all trials.
  
- If $X$ is defined as  <span style="color:blue"> the number of successes observed in $n$ trials </span>, $X$ is a binomial random variable.

:::{.callout-note icon=false}
- The word *success* just means one of the two outcomes, and *does not necessarily mean something good. *
- `r emoji('astonished')` We can define *Drug abuse* as success and *No drug abuse* as failure.
:::


## Binomial Distribution
- The probability function $P(X = x)$ of a binomial r.v. $X$ can be *fully* determined by 

  + the number of trials $n$
  
  + probability of success $\pi$
  
- Different $(n, \pi)$ pairs generate different binomial probability distributions.
- $X$ is said to follow a binomial distribution with **parameters** $n$ and $\pi$, written as $\color{blue}{X \sim binomial(n, \pi)}$.
- The binomial probability function is 
$$ \color{blue}{P(X = x \mid n, \pi) = \frac{n!}{x!(n-x)!}\pi^x(1-\pi)^{n-x}, \quad x = 0, 1, 2, \dots, n}$$ with mean $\mu = E(X) = n\pi$ and variance $\sigma^2 = Var(X) = n\pi(1-\pi)$.

:::{.callout-note icon=false}
## If we toss a fair coin two times independently and let $X =$ # of heads, is $X$ a binomial r.v.?
:::

## Binomial Distribution Example
:::{layout-ncol=2}
- Assume that 20% of all drivers have a blood alcohol level above the legal limit. For a random sample of 15 vehicles, compute the probability that:

  1. Exactly 6 of the 15 drivers will *exceed* the legal limit.
  
  2. Of the 15 drivers, 6 or more will *exceed* the legal limit.
  
```{r, echo=FALSE, out.width="30%", fig.align='center'}
knitr::include_graphics("./images/img-prob/alcohol.jpeg")
```
:::
  - Suppose it is a binomial experiment with $n = 15$ and $\pi = 0.2$. 
  - Let $X$ be the number of drivers exceeding limit. 
  - $X \sim binomial(15, 0.2)$.
  
$$ \color{blue}{P(X = x \mid n=15, \pi=0.2) = \frac{15!}{x!(15-x)!}(0.2)^x(1-0.2)^{15-x}, \quad x = 0, 1, 2, \dots, n}$$


  1. $\small P(X = 6) = \frac{n!}{x!(n-x)!}\pi^x(1-\pi)^{n-x} = \frac{15!}{6!(15-6)!}(0.2)^6(1-0.2)^{15-6} = 0.043$
  


  2. $\small P(X \ge 6) = p(6) + \dots + p(15) = 1 - P(X \le 5) = 1 - (p(0) + p(1) + \dots + p(5)) = 0.0611$
  
:::{.callout-tip}
Never do this by hand. We can compute them using R!
:::

## Binomial Distribution Example $X \sim binomial(15, 0.2)$


```{r binomial_plot_noshow, echo = FALSE, out.width="80%", fig.align='center'}
par(mar = c(4, 4, 2, 0), mgp = c(2.7, 1, 0), las = 1)
plot(x = 0:15, y = dbinom(0:15, size = 15, prob = 0.2), type = 'h', xlab = "x", 
     ylab = "P(X = x)", lwd = 5, main = "Binomial(15, 0.2)")
```


## Binomial Example Computation in R
<!-- - R Shiny app is at [Binomial Calculator](http://sctc.mscs.mu.edu:3838/sample-apps/Calculator/) -->
- With `size` the number of trials and `prob` the probability of success,

  + **`dbinom(x, size, prob)`** to compute $P(X = x)$
  
  + **`pbinom(q, size, prob)`** to compute $P(X \le q)$
  
  + **`pbinom(q, size, prob, lower.tail = FALSE)`** to compute $P(X > q)$
  
:::{layout-ncol=2}
```{r binomial_r_1}
## 1. P(X = 6)
dbinom(x = 6, size = 15, prob = 0.2) 
## 2. P(X >= 6) = 1 - P(X <= 5)
1 - pbinom(q = 5, size = 15, prob = 0.2) 
```



```{r binomial_r_2}
## 2. P(X >= 6) = P(X > 5)
pbinom(q = 5, size = 15, prob = 0.2, 
       lower.tail = FALSE)  
```
:::

## Binomial(15, 0.2)
```{r binomial_plot, echo = -1, out.width="67%", fig.align='center'}
par(mar = c(4, 4, 2, 0), mgp = c(2.7, 1, 0), las = 1)
plot(x = 0:15, y = dbinom(0:15, size = 15, prob = 0.2), 
     type = 'h', xlab = "x", ylab = "P(X = x)", 
     lwd = 5, main = "Binomial(15, 0.2)")
```

## Poisson Random Variables
- If we like to count **the number of occurrences of some event over a unit of time or space (region)** and its associated probability, we could consider the **Poisson distribution**.

  + Number of COVID patients arriving at ICU in one hour
  
  + Number of Marquette students logging onto D2L in one day
  
  + Number of dandelions per square meter in Marquette campus



- Let $X$ be a Poisson r.v. Then $\color{blue}{X \sim Poisson(\lambda)}$, where $\lambda$ is the parameter representing the **mean** number of occurrences of the event in the interval.
$$\color{blue}{P(X = x \mid \lambda) = \frac{\lambda^x e^{-\lambda}}{x!}, \quad x = 0, 1, 2, \dots}$$ with both mean and variance being equal to $\lambda$.




## Assumptions and Properties of Poisson Variables

- `r emoji('point_right')` **Events occur one at a time**; two or more events do not occur at the same time or in the same space or spot.
- `r emoji('point_right')` The occurrence of an event in a given period of time or region of space is **independent** of the occurrence of the event in a **nonoverlapping** time period or region of space.
- `r emoji('point_right')` $\lambda$ is **constant** of any period or region.

:::{.callout-note icon=false}
## Can you find the difference between Binomial and Poisson distributions?
:::

- The Poisson distribution

  + is determined by one single parameter $\lambda$
  
  + has possible values $x = 0, 1, 2, \dots$ with no upper limit (countable), while a binomial variable has possible values $0, 1, 2, \dots, n$ (finite)



## Poisson Distribution Example 
:::{layout-ncol=2}
- Last year there were 4200 births at the University of Wisconsin Hospital. Assume $X$ be the number of births in a given day at the center, and $X \sim Poisson(\lambda)$. Find
  1. $\lambda$, the mean number of births **per day**.
  2. the probability that on a randomly selected day, there are exactly 10 births.
  3. $P(X > 10)$? 

```{r, echo=FALSE, out.width="45%", fig.align='center'}
knitr::include_graphics("./images/img-prob/baby.jpeg")
```
:::

1. $\small \lambda = \frac{\text{Number of birth in a year}}{\text{Number of days}} = \frac{4200}{365} = 11.5$


2. $\small P(X = 10 \mid \lambda = 11.5) = \frac{\lambda^x e^{-\lambda}}{x!} = \frac{11.5^{10} e^{-11.5}}{10!} = 0.113$



3. $\small P(X > 10) = p(11) + p(12) + \dots + p(20) + \dots$ (No end!)
$\small P(X > 10) = 1 - P(X \le 10) = 1 - (p(1) + p(2) + \dots + p(10))$.



## Poisson Example Compuatation in R
<!-- - R Shiny app is at [Poisson Calculator](http://sctc.mscs.mu.edu:3838/sample-apps/Calculator/) -->
<!-- P(X <= 10) = 0.392 -->
- With `lambda` the mean of Poisson distribution, 

  + **`dpois(x, lambda)`** to compute $P(X = x)$
  
  + **`ppois(q, lambda)`** to compute $P(X \le q)$
  
  + **`ppois(q, lambda, lower.tail = FALSE)`** to compute $P(X > q)$
  
:::{layout-ncol=2}
```{r poisson_r_1}
(lam <- 4200 / 365)
## P(X = 10)
dpois(x = 10, lambda = lam)  
```


```{r poisson_r_2}
## P(X > 10) = 1 - P(X <= 10)
1 - ppois(q = 10, lambda = lam)  
## P(X > 10)
ppois(q = 10, lambda = lam, 
      lower.tail = FALSE) 
```
:::

## Poisson(11.5)
- $X$ has no upper limit. The graph is *truncated* at $x = 24$. 
```{r poisson_plot, out.width="60%", fig.align='center'}
plot(0:24, dpois(0:24, lambda = lam), type = 'h', lwd = 5, 
     ylab = "P(X = x)", xlab = "x", main = "Poisson(11.5)")
```



