# Inference About Proportions {#sec-infer-prop}

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(openintro)
library(knitr)
library(emoji)
library(kableExtra)
set.seed(1234)
```

## Introduction

<span style="color:blue"> **One Categorical Variable with Two Categories** </span>

- Let $X$ be the categorical variable Gender with 2 categories, Male and Female.

::::{.columns}
:::{.column width="49%"}
| Subject     | Male | Female |
|:--------:|:--------:|:--------:|
| 1 | x |   |  
| 2 |   | x |
| $\vdots$  | $\vdots$ | $\vdots$  |
| $n$ | x |   |

<center>
**One-way frequency/count table**
</center>

| $X$     | Count |
|:--------:|:--------:|
| Male   | $y$    |  
| Female | $n-y$ |
:::

:::{.column width="2%"}
:::

:::{.column width="49%"}
```{r, echo=FALSE, out.width="100%", fig.align='center'}
knitr::include_graphics("./images/img-infer/class.jpeg")
```

- The number of males can be viewed as a random variable because the *count, $y$, varies from sample to sample*.

:::{.callout-note icon=false}
## What probability distribution might be appropriate for the count, $Y$?
:::
:::
::::

----------------------------------------------------------------

<span style="color:blue"> **Probability Distribution for Count Data: Two Levels** </span>

- $binomial(n, \pi)$ could be a good option for count data with 2 categories.
  + Fixed number of trials. <span style="color:blue"> (Fixed $n$ subjects) </span>
  + Each trial results in one of two outcomes. <span style="color:blue"> (Either $M$ or $F$) </span>
  + Trials are independent. <span style="color:blue"> (If the subjects are randomly sampled) </span>
- If the proportion of being in category, $M$, is $\pi$, the count, $Y$, has $$P(Y = y \mid n, \pi) = \frac{n!}{y!(n-y)!}\pi^{y}(1-\pi)^{n-y}$$
- Goal: **Estimate or test the population proportion, $\pi$, of the category**, $M$.

## Inference for a Single Proportion

<span style="color:blue"> **Hypothesis Testing for $\pi$ (Exact Binom Test)** </span>

<span style="color:red"> Step 0: Method Assumptions </span>

- <span style="color:blue"> $n\pi_0 \ge 5$ and $n(1-\pi_0) \ge 5$  </span>
  + The larger, the better

<span style="color:red"> Step 1: Set the Null and Alternative Hypothesis </span>

- <span style="color:blue"> $\begin{align} &H_0: \pi = \pi_0 \\ &H_1: \pi > \pi_0 \text{ or } \pi < \pi_0 \text{ or } \pi \ne \pi_0 \end{align}$ </span>

<span style="color:red"> Step 2: Set the Significance Level, $\alpha$ </span>

<span style="color:red"> Step 3: Calculate the Test Statistic </span>

-  <span style="color:blue"> Under $H_0$, $z_{test} = \dfrac{\hat{\pi} - \pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}$  where $\hat{\pi} = \frac{y}{n} =$ sample proportion </span>

:::{.callout-note}
- The sampling distribution of $\hat{\pi}$ is approximately normal with mean, $\pi$, and standard error, $\sqrt{\frac{\pi(1-\pi)}{n}}$, if $y_i$ are independent and the assumptions are satisfied.
:::

<span style="color:red"> Step 4-c: Find the Critical Value $z_{\alpha}$ (one-tailed) or $z_{\alpha/2}$ (two-tailed) </span>

<span style="color:red"> Step 5-c: Draw a Conclusion Using Critical Value Method </span>

- <span style="color:blue"> $H_1: \pi > \pi_0$: Reject $H_0$ in favor of $H_1$ if $z > z_{\alpha}$ </span>
- <span style="color:blue"> $H_1: \pi < \pi_0$: Reject $H_0$ in favor of $H_1$ if $z < -z_{\alpha}$ </span>
- <span style="color:blue"> $H_1: \pi \ne \pi_0$: Reject $H_0$ in favor of $H_1$ if $|z| > z_{\alpha/2}$ </span>

<span style="color:red"> Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim </span>

--------------------------------------------------------------------------

<span style="color:blue"> **Confidence Interval for $\pi$** </span>

- Assumptions:
  - $n\hat{\pi} \ge 5$ and $n(1-\hat{\pi}) \ge 5$
- The $100(1 - \alpha)\%$ confidence interval for $\pi$ is
$$\hat{\pi} \pm z_{\alpha/2}\sqrt{\frac{\pi(1-\pi)}{n}}$$ where $\hat{\pi} = y/n$.
- $\pi$ is unknown, so we use the estimate, $\hat{\pi}$, instead: $$\hat{\pi} \pm z_{\alpha/2}\sqrt{\frac{\hat{\pi}(1-\hat{\pi})}{n}}$$

:::{.callout-note}
- No hypothesized value, $\pi_0$, is involved in the confidence interval.
:::

---------------------------------------------------------------------

<span style="color:blue"> **Example: Exit Poll** </span>

- Suppose we collect data on 1,000 voters in an election with only two candidates, **R** and **D**.

::::{.columns}
:::{.column width="49%"}
|Voter | R | D |
|:-----:|:-----:|:-----:|
|1  | x |   |
|2  |   |  x |
| $\vdots$  | $\vdots$ | $\vdots$  |
|1000| x |   |
:::

:::{.column width="2%"}
:::

:::{.column width="49%"}
```{r, echo=FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("./images/img-infer/vote.jpeg")
```
:::
::::

- Based on the data, we want to predict who won the election.
- Let $Y$ be the number of voters that voted for **R**.
- Assume the count, $Y$, is sampled from $binomial(n = 1000, \pi)$.
  + $\pi = P(\text{a voter voted for R}) =$ (population) proportion of all voters that for R
    - This is the **unknown** parameter to be estimated or tested.
- Predict whether or not **R won the election**.

:::{.callout-note icon=false}
## What are $H_0$ and $H_1$?
- <span style="color:blue"> $\begin{align} &H_0: \pi \le 1/2 \\ &H_1: \pi > 1/2 \text{ (more than half voted for R)} \end{align}$ </span>
:::




<span style="color:red"> ***Hypothesis Testing*** </span>

- In an exit poll of 1,000 voters, 520 voted for **R**, one of the two candidates.

<span style="color:red"> Step 0 </span>

- <span style="color:blue"> $n\pi_0 = 1000(1/2) = 500 \ge 5$ and $n(1-\pi_0) \ge 5$ </span>

<span style="color:red"> Step 1 </span>

- <span style="color:blue"> $\begin{align} &H_0: \pi \le 1/2 \\ &H_1: \pi > 1/2 \end{align}$ </span>

<span style="color:red"> Step 2 </span>

- <span style="color:blue"> $\alpha = 0.05$ </span>

<span style="color:red"> Step 3 </span>

- <span style="color:blue"> $z_{test} = \frac{\hat{\pi} - \pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}} =  \frac{\frac{520}{1000} - 0.5}{\sqrt{\frac{0.5(1-0.5)}{1000}}} = 1.26$ </span>

<span style="color:red"> Step 4-c </span>

- <span style="color:blue"> $z_{\alpha} = z_{0.05} = 1.645$ </span>

<span style="color:red"> Step 5-c </span> 

- <span style="color:blue">  Reject $H_0$ in favor of $H_1$ if $z_{test} > z_{\alpha}$. </span>
- <span style="color:blue"> Since $z_{test} < z_{\alpha}$, we do not reject $H_0$.  </span>

<span style="color:red"> Step 6 </span> 

- <span style="color:blue">  We do not have sufficient evidence to conclude that R won.  </span>

- We make the same conclusion using the $p$-value method. 

$$ p\text{-value} = P(Z > 1.26) = 0.1 > 0.05$$

<span style="color:red"> ***Confidence Interval*** </span>

- Assumptions: 
  + $n\hat{\pi} = 1000(0.52) = 520 \ge 5$ and $n(1-\hat{\pi}) = 480 \ge 5$.
- Estimate the proportion of all voters that voted for **R** using a 95% confidence interval.

$$\hat{\pi} \pm z_{\alpha/2}\sqrt{\frac{\hat{\pi}(1-\hat{\pi})}{n}} = 0.52 \pm z_{0.025}\sqrt{\frac{0.52(1-0.52)}{1000}} = (0.49, 0.55).$$

- Below is a demonstration of how to perform a binomial test in R.

```{r, echo=TRUE}
# Use alternative = "two.sided" to get CI
# binom.test()
prop.test(x = 520, n = 1000, p = 0.5, alternative = "greater", correct = FALSE)
```

## Inference for Two Proportions

::::{.columns}
:::{.column width="53%"}

|Group 1 | Group 2
|:-----:|:-----:
| $n_1$ trials  | $n_2$ trials 
| $Y_1$ number of successes | $Y_2$ number of successes 
| $Y_1 \sim binomial(n_1, \pi_1)$ | $Y_2 \sim binomial(n_2, \pi_2)$ 

- $\pi_1$: Population proportion of success of Group 1
- $\pi_2$: Population proportion of success of Group 2
:::

:::{.column width="2%"}
:::

:::{.column width="45%"}
- Is the male presidential approval rate, $\pi_1$, higher than the female approval rate, $\pi_2$?

```{r, echo=FALSE, out.width="90%", fig.align='center'}
knitr::include_graphics("./images/img-infer/trump_rate.png")
``` 
:::
::::

------------------------------------------------------------------------

<span style="color:blue"> **Hypothesis Testing for $\pi_1$ and $\pi_2$** </span>

<span style="color:red"> Step 0: Check Method Assumptions </span>

-  <span style="color:blue"> $n_1\hat{\pi}_1 \ge 5$, $n_1(1-\hat{\pi}_1) \ge 5$ and $n_2\hat{\pi}_2 \ge 5$, $n_2(1-\hat{\pi}_2) \ge 5$ </span>

<span style="color:red"> Step 1: Set the Null and Alternative Hypothesis </span>
  
- <span style="color:blue"> $\begin{align}  &H_0: \pi_1 = \pi_2 \\ &H_1: \pi_1 > \pi_2 \text{ or } \pi_1 < \pi_2 \text{ or } \pi_1 \ne \pi_2 \end{align}$ </span>

<span style="color:red"> Step 2: Set the Significance Level, $\alpha$ </span>

<span style="color:red"> Step 3: Calculate the Test Statistic </span>
 
-  <span style="color:blue"> $z_{test} = \dfrac{\hat{\pi}_1 - \hat{\pi}_2}{\sqrt{\bar{\pi}(1-\bar{\pi})(\frac{1}{n_1} + \frac{1}{n_2}})}$, $\bar{\pi} = \frac{y_1+y_2}{n_1+n_2}$ is the **pooled** sample proportion estimating $\pi$ </span>

<span style="color:red"> Step 4-c: Find the Critical Value $z_{\alpha}$ (one-tailed) or $z_{\alpha/2}$ (two-tailed) </span>

<span style="color:red"> Step 5-c: Draw a Conclusion Using Critical Value Method </span>
  
- <span style="color:blue">  Reject $H_0$ in favor of $H_1$ if </span>
  + <span style="color:blue"> $H_1: \pi_1 > \pi_2$: Reject $H_0$ in favor of $H_1$ if $z > z_{\alpha}$ </span>
  + <span style="color:blue"> $H_1: \pi_1 < \pi_2$: Reject $H_0$ in favor of $H_1$ if $z < -z_{\alpha}$ </span>
  + <span style="color:blue"> $H_1: \pi_1 \ne \pi_2$: Reject $H_0$ in favor of $H_1$ if $|z| > z_{\alpha/2}$ </span>

<span style="color:red"> Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim </span>

-------------------------------------------------------------------

<span style="color:blue"> **Confidence Interval for $\pi_1 - \pi_2$**

- The $100(1 - \alpha)\%$ confidence interval for $\pi_1 - \pi_2$ is $$\hat{\pi}_1 - \hat{\pi}_2 \pm z_{\alpha/2}\sqrt{\frac{\hat{\pi}_1(1-\hat{\pi}_1)}{n_1}+\frac{\hat{\pi}_2(1-\hat{\pi}_2)}{n_2}}$$
- Requirements: 
  - $n_1\hat{\pi}_1 \ge 5$, $n_1(1-\hat{\pi}_1) \ge 5$ and $n_2\hat{\pi}_2 \ge 5$, $n_2(1-\hat{\pi}_2) \ge 5$

------------------------------------------------------------------

<span style="color:blue"> **Example: Effectiveness of Learning** </span>

::::{.columns}
:::{.column width="70%"}
- Suppose we do a study on 300 students to compare the effectiveness of learning statistics in online vs. in-person programs.
- Randomly assign
  + 125 students to the online program
  + the remaining 175 to the in-person program
:::

:::{.column width="30%"}
```{r, echo=FALSE, out.width="100%", fig.align='center'}
knitr::include_graphics("./images/img-infer/online_learning.jpeg")
```
:::
::::

|Exam Results | Online Instruction | In-Person Instruction |
|:-----:|:-----:|:-----:|
|Pass  | 94   | 113 |
|Fail  | 31   | 62  |
|Total | 125  | 175 |

:::{.callout-note icon=false}
## Is there sufficient evidence to conclude that the online program is more effective than the traditional in-person program at $\alpha=0.05$?
:::

<span style="color:red"> ***Hypothesis Testing*** </span>

<span style="color:red"> Step 0 </span>

- <span style="color:blue"> $\hat{\pi}_1 = 94/125 = 0.75$ and $\hat{\pi}_2 = 113/175 = 0.65$. </span>
- <span style="color:blue"> $n_1\hat{\pi}_1 = 94 > 5$, $n_1(1-\hat{\pi}_1) = 31 > 5$, and $n_2\hat{\pi}_2 = 113 > 5$, $n_2(1-\hat{\pi}_2) = 62 > 5$ </span>

<span style="color:red"> Step 1 </span>

- <span style="color:blue"> $H_0: \pi_1 = \pi_2$ vs. $H_1: \pi_1 > \pi_2$ </span>  
- $\pi_1$ $(\pi_2)$ is the population proportion of students passing the exam in the online (in-person) program.

<span style="color:red"> Step 2 </span>

- <span style="color:blue"> $\alpha = 0.05$ </span>

<span style="color:red"> Step 3 </span>

- <span style="color:blue"> $\bar{\pi} = \frac{94+113}{125+175} = 0.69$ </span>
- <span style="color:blue"> $z_{test} = \dfrac{\hat{\pi}_1 - \hat{\pi}_2}{\sqrt{\bar{\pi}(1-\bar{\pi})(\frac{1}{n_1} + \frac{1}{n_2}})} = \frac{0.75 - 0.65}{\sqrt{0.69(1-0.69)(\frac{1}{125} + \frac{1}{175})}} = 1.96$ </span>

<span style="color:red"> Step 4-c </span>

- <span style="color:blue"> $z_{\alpha} = z_{0.05} = 1.645$ </span>

<span style="color:red"> Step 5-c </span>

- <span style="color:blue">  Reject $H_0$ in favor of $H_1$ if $z_{test} > z_{\alpha}$. </span>
- <span style="color:blue"> Since $z_{test} > z_{\alpha}$, we reject $H_0$.  </span>

<span style="color:red"> Step 6 </span>

- <span style="color:blue">  We have sufficient evidence to conclude that the online program is more effective. </span>

<span style="color:red"> ***Confidence Interval*** </span>

- We want to know how effective the online program is. 
- Estimate $\pi_1 - \pi_2$ using a $95\%$ confidence interval.
$$\hat{\pi}_1 - \hat{\pi}_2 \pm z_{\alpha/2}\sqrt{\frac{\hat{\pi}_1(1-\hat{\pi}_1)}{n_1}+\frac{\hat{\pi}_2(1-\hat{\pi}_2)}{n_2}}$$
- $z_{0.05/2} = 1.96$
- The 95% confidence interval is 
$$0.75 - 0.65 \pm 1.96\sqrt{\frac{(0.75)(1-0.75)}{125} + \frac{(0.65)(1-0.65)}{175}}\\
 = (0.002, 0.210)$$
- Because 0 is not included in this interval, we reach the same conclusion as the hypothesis testing.

<span style="color:red"> ***Implementation in R*** </span>

- Below is a demonstration of how to make inferences about two proportions in R.

```{r, echo=TRUE}
# Use alternative = "two.sided" to get CI
prop.test(x = c(94, 113), n = c(125, 175), alternative = "greater", correct = FALSE)
prop_ci <- prop.test(x = c(94, 113), n = c(125, 175), alternative = "two.sided", correct = FALSE)
prop_ci$conf.int
```

## Exercises

1. Lipitor (atorvastatin) is a drug used to control cholesterol. In clinical trials of Lipitor, 98 subjects were treated with Lipitor and 245 subjects were given a placebo. Among those treated with Lipitor, 6 developed infections. Among those given a placebo, 24 developed infections. Use a 0.05 significance level to test the claim that the rate of inflections was the same for those treated with Lipitor and those given a placebo.
    (a) Test the claim using the critical-value and p-value methods.
    (b) Test the claim by constructing a confidence interval.

