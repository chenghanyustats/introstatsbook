[
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Introduction to Statistics",
    "section": "Welcome",
    "text": "Welcome\nThis is the website for my introductory statistics book. This book serves as a main reference book for my MATH 4720 Statistical Methods and MATH 4740 Biostatistical Methods at Marquette University.1 Some topics can also be discussed in an introductory data science course. Youâ€™ll learn basic probability and statistical concepts as well as data analysis techniques such as linear regression using R computing software.2 The book balances the following aspects of statistics:\n\nmathematical derivation and statistical computation\ndistribution-based and simulation-based inferences\nmethodology and applications\nclassical/frequentist and Bayesian approaches\n\nThe course materials are borrowed from several existing statistics books and notes, especially from the following books:\n\nOpenIntro Statsitics (OS) (data focused)\nIntroduction to Modern Statistics (IMS) (simulation-based and computation focused)\nAn Introduction to Statistical Methods & Data Analysis, 7th edition (SMD) (distribution-based and mathematics focused)3"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Introduction to Statistics",
    "section": "License",
    "text": "License\nThis website is (and will always be) free to use, and is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 License. If youâ€™d like to give back, please consider reporting a typo or leaving a pull request at github.com/chenghanyustats/introstatsbook."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Statistics and Data",
    "section": "",
    "text": "What is Statistics? What is Data Science? What are data?"
  },
  {
    "objectID": "intro-stats.html#what-is-statistics",
    "href": "intro-stats.html#what-is-statistics",
    "title": "1Â  Science of Data and Data Science",
    "section": "\n1.1 What is Statistics?",
    "text": "1.1 What is Statistics?\n\nStatistics can be defined in a variety of ways, and there doesnâ€™t seem to be one definition that describes it best.\nFor our purposes, statistics can be generally divided into two overarching categories.\n\nStatistics as a set of numeric records\nStatistics as a discipline\n\n\n\n Statistics as a Set of Numeric Records \n\nIn ordinary conversations, the word statistics is used as a term to indicate a set or collection of numeric records.\nFor example, FigureÂ 1.1 below shows Michael Jordanâ€™s career statistics from his time in the NBA.\n\n\n\n\n\nFigureÂ 1.1: Example of statistics as a set of numeric records (Source: https://www.nba.com/stats/player/893/career)\n\n\n\n\n\nHowever, this is just one way of defining statistics.\n\n\n Statistics as a Discipline \n\nAs previously stated, other definitions of statistics exist including the one shown in FigureÂ 1.2.\n\n\n\n\n\nFigureÂ 1.2: Statistics Shirt (Source: shorturl.at/vEMNS)\n\n\n\n\n\nThis definition emphasizes the idea that with the same data, different statistical methods may produce different results and lead to different conclusions.\nWiki lists a more formal definition of statistics in FigureÂ 1.3 below.\n\n\n\n\n\nFigureÂ 1.3: More formal definition of statistics (Source:https://en.wikipedia.org/wiki/Statistics)\n\n\n\n\n\n\nStatistics can also be described as a Science of Data that uses statistical thinking, methods and models.\n\n\nðŸ¤” But wait, if statistics is a science of data, then what is DATA SCIENCEâ“"
  },
  {
    "objectID": "intro-stats.html#difference-between-statistics-and-data-science",
    "href": "intro-stats.html#difference-between-statistics-and-data-science",
    "title": "1Â  Science of Data and Data Science",
    "section": "\n1.2 Difference between Statistics and Data Science",
    "text": "1.2 Difference between Statistics and Data Science\n\n Data Science \n\nBecause of their shared attributes, many find it hard to differentiate between statistics and data science.\nThe tweets below poke fun at the lack of clarity surrounding the definition of data science/data scientists (FigureÂ 1.4).\n\n\n\n\n\nFigureÂ 1.4: Tweets about what Data Science is\n\n\n\nA more formal definition of data science can be found on Investopedia.\nThis site defines Data Science as a field of applied mathematics and statistics that provides useful information based on large amounts of complex data or big data.\nAlthough this definition is helpful for understanding data science, Dan Ariely, a famous behavioral economist at Duke, joked about their use of the term big data in his tweet below (FigureÂ 1.5).\n\n\n\nFigureÂ 1.5: Professor Ariely on Big Data\n\n\n\nMore information can be gathered about the differences between these two fields from looking at the courses offered in the Statistics Department at UC Santa Cruz.\nFrom FigureÂ 1.6 below, one can see that statistics primarily focuses on data analysis, methods and models.\n\n\n\n\n\nFigureÂ 1.6: Courses offered by the Department of Statistics at UC Santa Cruz (Source: https://courses.soe.ucsc.edu/)\n\n\n\n\n\nThis statistics department, in particular, doesnâ€™t talk a lot about data collection, organization, data presentation or data visualization.\nAlthough statistics does not focus on these concepts, they are encompassed within the field of data science.\nThe data science process includes the collection, organization, analysis, interpretation and presentation of data (FigureÂ 1.7).\n\n\n\n\n\nFigureÂ 1.7: The data science process created at Harvard by Joe Blitzstein and Hanspeter Pfister\n\n\n\n\n\nIn typical statistics departments, there isnâ€™t much instruction or research done on data collection, cleaning, storage, database management, and data visualization.\nBecause statistics continues to focus on data analysis and modeling, Data Science now addresses these other processes that statistics passes over."
  },
  {
    "objectID": "intro-stats.html#what-will-we-learn-in-this-course",
    "href": "intro-stats.html#what-will-we-learn-in-this-course",
    "title": "1Â  Science of Data and Data Science",
    "section": "\n1.3 What Will We Learn In this Course?",
    "text": "1.3 What Will We Learn In this Course?\n\nBelow, the main topics of this course, as well as brief descriptions, are listed in the order in which they will be covered. .\n\n\n\n\n\n\n\n\n\n\nWe will spend most of our time talking about probability and the statistical inference methods that are circled on the list above.\nThis course will also include a focus on the statistical methods for analyzing data.\nIn summary, we will learn useful information\n\nabout the population we are interested in\nfrom our sample data\n\nthrough statistical inferential methods, including estimation and testing\n\n\n\n\n\n\n\n\nFigureÂ 1.8: Illustration of obtaining sample data from a population"
  },
  {
    "objectID": "intro-data.html#data",
    "href": "intro-data.html#data",
    "title": "2Â  Data",
    "section": "\n2.1 Data",
    "text": "2.1 Data\n What is Data? \n\nBecause statistics is a science of data, we first need to understand what data is.\n\nData can be described as a set of objects on which we observe or measure one or more characteristics.\n\n\nObjects are individuals, observations, subjects or cases in statistical studies.\nA characteristic or attribute is also called a variable because it varies from one object to another.\n\n\nWe usually store a data set in a matrix form that has rows and columns.\n\nEach row corresponds to a unique case or observational unit.\nEach column represents a characteristic or variable.\n\n\nThis structure allows new cases to be added as rows or new variables to be added as columns.\n\n\n Example \n\n\nFigureÂ 2.1 below is a data set of Marquette basketball players stored in matrix form.\nThe objects are individuals or players in the data and each have their own associated row.\nEach player has several characteristics or attributes shown in the columns associated with them.\n\nThese include jersey number, class, position, height, weight, hometown and high school.\nThese characteristics can also be referred to as variables because they vary from one player to another.\n\n\n\n\n\n\n\nFigureÂ 2.1: Data set of 2019 Marquette menâ€™s basketball players"
  },
  {
    "objectID": "intro-data.html#population-and-sample",
    "href": "intro-data.html#population-and-sample",
    "title": "2Â  Data",
    "section": "\n2.2 Population and Sample",
    "text": "2.2 Population and Sample\n Target Population \n\nThe first step in conducting a study is to identify questions to be investigated.\nA clear research question is helpful in identifying\n\nwhat cases should be studied (row)\nwhat variables are important (column)\n\n\nOnce the research question is determined, it is important to identify the target population to be investigated.\nThe target population is the complete collection of data weâ€™d like to make inference about.\n\n GPA Example \n\n\n\n\nResearch Question: What is the average GPA of currently enrolled Marquette undergraduate students?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Target Population: All Marquette undergraduate students that are currently enrolled.\nBecause all Marquette undergrads that are currently enrolled are the complete collection of data weâ€™d like to make inference about, each currently enrolled Marquette undergrad is an object.\nAverage GPA is the variable or population property we would like to make an inference about.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nStudents who are not currently enrolled or students that have already graduated are not our interest, so they shouldnâ€™t be a part of target population.\n\n\n\n Heart Disease Example \n\n\n\nDoes a new drug reduce mortality in patients with severe heart disease?\n\n\n\n\n\n\n\n\n\n\n\n Target Population: All people with severe heart disease. \nMortality is the variable or population property we would like to make an inference about.\n\n\n\n\n Sample Data \n\nIn some cases itâ€™s possible to collect data of all the cases we are interested in.\nHowever, most of the time it is either expensive or too time consuming to collect data for every case in a population.\nWhat if we tried to collect data on the average GPA of all students in Illinois? The U.S.? The world? ðŸ˜± ðŸ˜± ðŸ˜±\n\n\n\n\nThe solution to this problem is sampling.\nA sample is a subset of cases selected from a population.\nWe are not able to collect the average GPA of every member of the population, but we can collect a sample from that population which has fewer objects (FigureÂ 13.1).\nWe can then compute the average GPA of the sample data.\n\n\n\n\n\n\n\n\nFigureÂ 2.2: Sampling from the population reduces the number of objects from which to collect data.\n\n\n\n\n\n\n\nOur hope is that the average GPA of the sample is close to the average GPA of the population, which is our main interest.\nFor the sampleâ€™s average GPA to be close to populationâ€™s average GPA, we want the sample to look like the population such that they share similar attributes including GPA.\n\n\n Good Sample vs.Â Bad Sample \n\n\n\n\n\n\nIs this 4720/5720 class a sample of the target population Marquette students?\n\n\n\n\n\n\n\n\n\n\nFigureÂ 2.3: Majors of students in this 4740/5740 class\n\n\n\n\n\n\n\n\n\n\nIs this 4720/5720 class a â€œgoodâ€ sample of the target population?\n\n\n\n\n\n\n\nThe sample is convenient to be collected, but as FigureÂ 2.3 shows, it is NOT representative of the population.\nBecause this class is primarily composed of STEM majors, it may not share the attributes necessary with the target population for the two to share a similar average GPA.\nTherefore, we call this a biased sample.\n\nThe average GPA of the class may differ greatly from the average GPA of all MU undergrads.\n\n\n\n\n\n\n\nFigureÂ 2.4: Sampling from a class of mostly STEM students is not representative of the entire population.\n\n\n\n\n\n\n\nAs shown in FigureÂ 2.5, the average GPA differs based on studentsâ€™ majors.\nBecause this class consists of mostly STEM majors, it is likely that the average GPA of its students is not the same as the average GPA of all MU undergraduates.\n\nFigureÂ 2.4 depicts that sampling needs to be done appropriately to ensure the sample is representative of the population.\n\n\n\n\n\n\n\n\nFigureÂ 2.5: UC Berkeley average GPAs by major\n\n\n\n\n\n\n\n How do we collect and why do we need a representative sample? \n\nWe always seek to randomly select a sample from a population.\nRandom sampling usually give us a representative sample, as long as the sample size, or the number of objects in the sample, is not too small.\nIt is important to collect samples this way, because many statistical methods are based on the randomness assumption."
  },
  {
    "objectID": "intro-data.html#data-collection",
    "href": "intro-data.html#data-collection",
    "title": "2Â  Data",
    "section": "\n2.3 Data Collection",
    "text": "2.3 Data Collection\n Two Types of Studies to Collect Sample Data \n\nThere are two types of studies that are used to collect data: observational studies and experimental studies.\nAn observational study is a study in which those collecting the data observe and measure characteristics/variables, but do NOT attempt to modify or intervene with the subjects being studied.\n\n Example: Sample from 1ï¸âƒ£ the heart disease and 2ï¸âƒ£ heart disease-free populations and record the fat content of the diets for the two groups. \n\n\nIn an experimental study, some treatment(s) is applied and then those collecting data proceed to observe its responses or effects on the individuals (experimental units).\n\n Example: Assign volunteers to one of several diets with different levels of dietary fat (treatments) and compare the treatments with respect to the incidence of heart disease after a period of time. \n\n\n\n\n\n\n\n\n\nObservational or Experimental?\n\n\n\n\nRandomly select 40 males and 40 females to see the difference in blood pressure levels between male and female.\nTest the effects of a new drug by randomly dividing patients into 3 groups (high dosage, low dosage, placebo).\n\n\n\n Limitation of Observational Studies: Confounding Variables \n\nA confounder is a variable NOT included in a study that affects the variables in the study.\nFor example, a person observes past data that shows that increases in ice cream sales are associated with increases in drownings and concludes that eating ice cream causes drownings. ðŸ˜±ðŸ˜•â‰ï¸\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the confounder that is not in the data but affects ice cream sales and the number of drownings?\n\n\n\n\nTemperature\n\n\n\n\nAs temperature increases, ice cream sales increase and the number of drownings also rises because more people go swimming (FigureÂ 2.6).\n\n Causal Relationships \n\nMaking causal conclusions based on experimental data is often more reasonable than making the same causal conclusions based on observational data.\nObservational studies are generally only sufficient to show associations, not causality.\n\n\n\n\n\nFigureÂ 2.6: Temperature acting as a confounder\n\n\n\n\n\n Types of Random Samples \n\nAs previously mentioned, many statistical methods are based on the randomness assumption.\nTherefore, itâ€™s important to understand what a random sample is and how to collect it.\nIn a random sample, each member of a population is equally likely to be selected.\n\n Simple Random Sample \n\nFor a simple random sample (SRS), every possible sample of sample size \\(n\\) has the same chance to be chosen.\n\nExample: If I were to sample 100 students from all 10,000 Marquette students, I would randomly assign each student a number (from 1 to 10,000) and then randomly select 100 numbers.\n\n\n\n\n\n\n\nFigureÂ 2.7: Simple Random Sample\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 2.8: Simple random sample from a population of 15 (https://research-methodology.net/sampling-in-primary-data-collection/random-sampling/)\n\n\n\n\n\n\n Stratified Random Sample \n\nFor stratified sampling, subdivide the population into different subgroups (strata) that share the same characteristics, then draw a simple random sample from each subgroup.\n\nHomogeneous within strata; Non-homogeneous between strata (FigureÂ 2.9)\n\n\n\n\n\nFigureÂ 2.9: Stratified Sampling\n\n\n\n\n\n\nExample: Divide Marquette students into groups by colleges, then perform a SRS for each group (FigureÂ 2.10).\n\n\n\n\n\nFigureÂ 2.10: Stratified sampling of Marquette Students\n\n\n\n\n Cluster Sampling \n\nFor cluster sampling, divide the population into clusters, then randomly select some of those clusters, and then choose all the members from those selected clusters.\n\nHomogeneous between clusters; Non-homogeneous within clusters (FigureÂ 2.11)\n\n\n\n\n\nFigureÂ 2.11: Cluster Sampling\n\n\n\n\n\n\nExample: Study 4720 studentsâ€™ drinking habits by dividing the students into 9 groups, and then randomly selecting 3 and interviewing all of the students in each of those clusters (FigureÂ 2.12).\n\n\n\n\n\nFigureÂ 2.12: Cluster sampling of Marquette students"
  },
  {
    "objectID": "intro-data.html#data-type",
    "href": "intro-data.html#data-type",
    "title": "2Â  Data",
    "section": "\n2.4 Data Type",
    "text": "2.4 Data Type\n\n\n\n\nFigureÂ 2.13: Types of Data\n\n\n\n\n Categorical vs.Â Numerical Variables \n\nA categorical variable provides non-numerical information which can be placed in one (and only one) category from two or more categories.\n\nGender (Male ðŸ‘¨, Female ðŸ‘©, Trans ðŸ³ï¸â€ðŸŒˆ) \nClass (Freshman, Sophomore, Junior, Senior, Graduate) \nCountry (USA ðŸ‡ºðŸ‡¸, Canada ðŸ‡¨ðŸ‡¦, UK ðŸ‡¬ðŸ‡§, Germany ðŸ‡©ðŸ‡ª, Japan ðŸ‡¯ðŸ‡µ, Korea ðŸ‡°ðŸ‡·) \n\n\nA numerical variable is recorded in a numerical value representing counts or measurements.\n\n GPA \n The number of relationships youâ€™ve had \n Height \n\n\n\n Numerical Variables \n\nNumerical variables can be discrete or continuous.\nA discrete variable takes on values of a finite or countable number.\nA continuous variable takes on values anywhere over a particular range without gaps or jumps.\n\n GPA is continuous because it can be any value between 0 and 4. \n The number of relationships youâ€™ve had is discrete because you can count the number and it is finite.\n Height is continuous because it can be any number within a range. \n\n\n\n Categorical Variables \n\nCategorical variables are usually recorded as numbers.\nGender (Male = 0, Female = 1, Trans = 2) \nClass (Freshman = 1, Sophomore = 2, Junior = 3, Senior = 4, Graduate = 5) \nCountry (USA = 100, Canada = 101, UK = 200, Germany = 201, Japan = 300, Korea = 301) \nUnited Airlines boarding groups\n\nThe numbers represent categories only; differences between them are meaningless.\n\nCanada - USA = 101 - 100 = 1?\nGraduate - Sophomore = 5 - 2 = 3 = Junior?\n\n\nWe need to learn the level of measurements to know which arithmetic operations are meaningful.\n\n\n Levels of Measurements \n Nominal and Ordinal for Categorical Variables \n\n\nNominal: The data can NOT be ordered in a meaningful or natural way.\n\n\nGender (Male = 0, Female = 1, Trans = 2)  is nominal because Male, Female and Trans cannot be ordered.\n\nCountry (USA = 100, Canada = 101, UK = 200, Germany = 201, Japan = 300, Korea = 301)  is nominal.\n\n\n\nOrdinal: The data can be arranged in some meaningful order, but differences between data values can NOT be determined or are meaningless.\n\n\nClass (Freshman = 1, Sophomore = 2, Junior = 3, Senior = 4, Graduate = 5)  is ordinal because Sophomore is one class higher than Freshman.\n\n\n\n Interval and Ratio for Numerical Variables \n\n\nInterval: The data have meaningful differences between any two values but the data do NOT have a natural zero or starting point. The data can do \\(\\color{red} +\\) and \\(\\color{red} -\\), but canâ€™t reasonably do \\(\\color{red} \\times\\) and \\(\\color{red} \\div\\).\n\n\nTemperature is interval because \\(80^{\\circ}\\)F is 40 degrees higher than \\(40^{\\circ}\\)F \\((80-40=40)\\), but \\(0^{\\circ}\\) does not mean NO heat and \\(80^{\\circ}\\)F is NOT twice as hot as \\(40^{\\circ}\\)F.\n\n\n\nRatio: The data have both meaningful differences and ratios, and there is a natural zero starting point that indicates none of the quantity. The data can do \\(\\color{red} +\\), \\(\\color{red} -\\), \\(\\color{red} \\times\\) and \\(\\color{red} \\div\\).\n\n\nDistance is ratio because \\(80\\) miles is twice as far as \\(40\\) miles \\((80/40 = 2)\\), and \\(0\\) mile means no distance.\n\n\n\n\n Converting Numerical to Categorical \n\nYouâ€™ve already seen an example of this with the class grading scale (FigureÂ 2.14).\n\n\n\n\n\n\nGrade\n\n\nPercentage\n\n\n\n\n\nA\n\n\n[94, 100]\n\n\n\n\nA-\n\n\n[90, 94)\n\n\n\n\nB+\n\n\n[87, 90)\n\n\n\n\nB\n\n\n[83, 87)\n\n\n\n\nB-\n\n\n[80, 83)\n\n\n\n\nC+\n\n\n[77, 80)\n\n\n\n\nC\n\n\n[73, 77)\n\n\n\n\nC-\n\n\n[70, 73)\n\n\n\n\nD+\n\n\n[65, 70)\n\n\n\n\nD\n\n\n[60, 65)\n\n\n\n\nF\n\n\n[0, 60)\n\n\n\n\nFigureÂ 2.14: Grading scale for this class\n\n\n\n\n Practice \n\n\n\n\n\n\nYour turn!\n\n\n\nIdentify the data type of each variable in the Marquette menâ€™s basketball player data\n\n\n\n\n\n\nFigureÂ 2.15: 2019 Marquette menâ€™s basketball player data set"
  },
  {
    "objectID": "intro-data.html#exercises",
    "href": "intro-data.html#exercises",
    "title": "2Â  Data",
    "section": "\n2.5 Exercises",
    "text": "2.5 Exercises\n\n\nData Type: Identify each of the following as numerical or categorical data.\n\nThe names of the companies that manufacture paper towels\nThe colors of cars\nThe heights of football players\n\n\n\nLevel of Measurements: Identify the level of measurement used in each of the following.\n\nThe weights of people in a sample of people living in Milwaukee.\nA physicianâ€™s descriptions of â€œabstains from smoking, light smoker, moderate smoker, heavy smoker.â€\nFlower classifications of â€œrose, tulip, daisy.â€\nSuzy measures time in days, with 0 corresponding to her birth date. The day before her birth is -1, the day after her birth is +1, and so on. Suzy has converted the dates of major historical events to her numbering system. What is the level of measurement of these numbers?\n\n\n\nDiscrete vs Continuous: Determine whether the data are discrete or continuous.\n\nThe length of stay (in days) for each COVID patient in Wisconsin.\nSeveral subjects are randomly selected and their heights are recorded.\nFrom a data set, we see that a male had an arm circumference of 31.28 cm.\nA sample of married couples is randomly selected and the number of animals in each family is recorded.\n\n\n\nSampling Method: Identify which of these types of sampling is used: random, stratified, or cluster.\n\nDr.Â Yu surveys his statistics class by identifying groups of males and females, then randomly selecting 7 students from each of those two groups.\nDr.Â Yu conducts a survey by randomly selecting 5 different sports teams at Marquette and surveying all of the student-athletes on those teams.\n427 subjects were randomly assigned to (1) meditation or (2) no mediation group to study the effectiveness of this mindfulness activity on lowering blood pressure.\n\n\n\nStudy Type: Determine whether the study is an experiment or an observational study, then identify a major problem with this study.\n\nIn a survey conducted by USA Today, 998 Internet users chose to respond to the question:â€œHow often do you seek medical advice online?â€ 42% of the respondents said â€œfrequently.â€\nThe Physiciansâ€™ Health Study involved 21,045 female physicians. Based on random selections, 11,224 of them were treated with aspirin and other other 9,821 were given placebos. The study was stopped early because it became clear that aspirin did not reduce the risk of myocardial infarctions by a substantial amount."
  },
  {
    "objectID": "intro-r.html#lets-get-equipped-with-our-tools",
    "href": "intro-r.html#lets-get-equipped-with-our-tools",
    "title": "3Â  Tool foR Data",
    "section": "\n3.1 Letâ€™s get equipped with our tools!",
    "text": "3.1 Letâ€™s get equipped with our tools!\n Integrated Development Environment \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR and Python are programming languages.\n\nPosit Cloud offers two integrated development environments (IDE).\n\nRStudio\nJupyterLab/Jupyter Notebook\n\n\nThese IDEs are software for efficiently writing computer programs.\n\n R and Posit \n\n\n\n\n\n\n\n\n\n\n\n\nR: free open-source programming language ðŸ“ˆ\nR is mainly for doing data science with strength in statistical modeling, computing and data visualization\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosit: interface for R, Python, etc. called an IDE (integrated development environment), e.g.Â â€œI write R code in the RStudio IDEâ€.\nPosit is not a requirement for programming with R, but itâ€™s commonly used by R developers, statisticians and data scientists.\n\n\n\n\n The R User Interface \n\nRStudio IDE includes\n\na viewable environment, a file browser, data viewer and a plotting pane. ðŸ‘\nalso features integrated help, syntax highlighting, context-aware tab completion and more! ðŸ˜„\n\n\n\n\n\n\nR\n\n\n\n\n\nFigureÂ 3.1: R Console\n\n\n\n\n\n\nRStudio\n\n\n\n\n\nFigureÂ 3.2: RStudio Console\n\n\n\n\n\n\n\n â˜ï¸ Posit Cloud - Statistics w/o hardware hassles \n\nðŸ˜Ž You can implement R/Python programs without installing R/Python and the IDE on your laptop!\nðŸ˜Ž Posit Cloud lets you do, share and learn data science online for free!\n\n\n\nðŸ˜ž Getting everything ready locally: Lots of friction\n\nDownload and install R/Python\nDownload and install IDE\nInstall wanted R/Python packages:\n\ntidymodels\ntidyverse\nNumPy\nâ€¦\n\n\nLoad these packages\nDownload and install tools like Git\n\n\nðŸ¤“ Posit Cloud: Much less friction\n\n\n\n\n\n\n\n\n\nGo to https://posit.cloud/\nLog in\n\n\n>hello R!\n\n\n\n\n Install Posit Cloud \n\n\n\n\n\n\nLab Time!\n\n\n\n\n\nStep 1: In the Posit website https://posit.co/, choose Products > Posit Cloud as shown below.\n\n\n\n\n\n\n\nFigureÂ 3.3: Posit website\n\n\n\n\n\n\n\n\n\n\nLab Time!\n\n\n\n\n\nStep 2: Click GET STARTED.\n\nStep 3: Free1 > Sign Up. Please sign up with GitHub if you have one or use your Marquette email address.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n New Projects \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo create a new project, click New Project in the top right corner as shown above.\n\n\n Workspaces \n\nWhen you create an account on Posit Cloud, you get a workspace of your own.\nYou can add a new workspace (click + New Space in sidebar) and control its permissions.\n\n\n\n\n\n\n\n\n\n\n First R Code in Posit Cloud! \n\n\n\n\n\n\nLab Time!\n\n\n\n\nIn the bar, click the desired workspace.\nClick New Project > New RStudio Project to get into the IDE.\nClick Untitled Project and give your project a nice name, math-4720 for example.\nIn the Console pane, write your first R code: a string \"Hello WoRld!\" or math 2 + 4.\nChange the editor theme: Tools > Global Options > Appearance\n\n\n\n\n\n\n\n\nFigureÂ 3.4: How to change the editor theme\n\n\n\n\n\n More Tips \n\nFor more help, read the Posit Cloud guide.\n\n\n\n\n\nFigureÂ 3.5: Posit Cloud Guide"
  },
  {
    "objectID": "intro-r.html#working-in-posit-cloud",
    "href": "intro-r.html#working-in-posit-cloud",
    "title": "3Â  Tool foR Data",
    "section": "\n3.2 Working in Posit Cloud",
    "text": "3.2 Working in Posit Cloud\n Panes \n\n\n\n\nFigureÂ 3.6: RStudio Panes\n\n\n\n\n\n Source Pane \n R Script \n\nAn R script is a .R file that contains R code.\nTo create an R script, go to File > New > R Script, or click the green-plus icon on the top left corner and select R Script.\n\n\n\n\n\nFigureÂ 3.7: Creating an R script\n\n\n\n\n Python Script \n\nA Python script is a .py file that contains Python code.\nTo create a Python script, go to File > New > Python Script, or click the green-plus icon on the topleft corner and select Python Script.\n\n\n\n\n\nFigureÂ 3.8: Creating a Python script\n\n\n\n\n Run Code \n\n\n Run : run the current line or selection of code.\n\n\nctrl + enter (Win) or cmd + enter (Mac)\n\n\n\n Icon to the right of Run : re-run the previous code.\n\n\nalt + ctrl + p (Win) or option + cmd + p (Mac)\n\n\n\n Source : run all the code in the R script.\n\n\nshift + ctrl + s (Win) or shift + cmd + s (Mac)\n\n\n\n Source with Echo : run all the code in the R script with the code printed in the console.\n\n\nshift + ctrl + enter (Win) or shift + cmd + enter (Mac)\n\n\n\n\n\n\n\nFigureÂ 3.9: Running R Code\n\n\n\n\n Run Python Code \n\nRunning Python code may require you to update some packages. Please say YES!\n\nWhen you run the Python code in the R console, the console will switch from R to Python.\nType quit in the Python console to switch back to the R console.\n\n\n\n\n\n\n\n\n\n\n Environment Tab \n\nThe (global) environment is where we are currently working.\nAnything created or imported into the current R/Python session is stored in our environment and shown in the Environment tab.\nAfter we run the R script from FigureÂ 3.7, the following objects are stored in the environment:\n\nData set mtcars\n\nObject x storing integer values 1 to 10.\nObject y storing three numeric values 3, 5, 9.\n\n\n\n\n\n\n\nFigureÂ 3.10: Environment Pane\n\n\n\n\n\nAfter we run the Python script from FigureÂ 3.8, the following object is stored in the environment:\n\nObject b storing a string Hello World!\n\n\n\n\n\n\n\n\n\n\n\n\n\n History Tab \n\nThe History tab keeps a record of all previous commands.\n\n\nSave icon: save all history to a file\n\nTo Console: send the selected commands to the console.\n\nTo Source : inserted the selected commands into the current script.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the console pane, use â¬†ï¸ to show the previous commands.\n\n\n\n R Packages ðŸ“¦ \n\nWhen we start an R session, only built-in packages like base, stats, graphics, etc. are available.\nInstalling packages is an easy way to get access to other data and functions.\n\n\n!\n\n\n Installing R Packages \n\n\n\nTo install a package, such as the ggplot2 package, we use the command\n\n\ninstall.packages(\"ggplot2\")\n\n\nA different option in the right-bottom pane is Packages > Install.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Loading R Packages ðŸ“¦ \n\n\n\nTo use any function or data in ggplot2, we write ggplot2:: followed by the name of the function or data.\n\n\nggplot2::ggplot(ggplot2::mpg, \n                ggplot2::aes(\n                    x = displ, \n                    y = hwy, \n                    colour = class)\n                ) + \n    ggplot2::geom_point()\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat happens when you run the code shown below?\n\nggplot(mpg, aes(x = displ, \n                y = hwy, \n                colour = class)) + \n    geom_point()\n\n\n\n\n\n\n\nWe can load the package into our R session using library().\n\nWith library(ggplot2), R knows the function and data are from the ggplot2 package.\n\n\nlibrary(ggplot2)\nggplot(mpg, aes(x = displ, \n                y = hwy, \n                colour = class)) + \n    geom_point()\n\n\n\n\n Help \n\nWhat if you donâ€™t know how a function works or what a data set is about â“\n\nðŸ‘‰ Simply type ? followed by the data name or function name to get more information.\n\n\n\n\n?mean\n?mtcars\n\n\n\n\n\n\n\nWhat does the function mean() do? What is the size of mpg?\n\n\n\n\n\n\n\nA document will show up in the Help tab, teaching you how to use the function or explaining the data set.\n\nAn example is shown for the mpg data set in FigureÂ 3.11 below.\n\n\n\n\n\n\n\nFigureÂ 3.11: Document explaining the mpg data set in the Help tab\n\n\n\n\n\n\n\n\n\n\n\nYou can do it!\n\n\n\n\nWhat is the size of mtcars data?\nType mtcars and hit enter in the console to see the data set.\nDiscuss the data type of each variable.\nType mtcars[, 1] and hit enter in the console and discuss what you see."
  },
  {
    "objectID": "intro-r.html#install-r-and-r-studio-locally-to-your-computer",
    "href": "intro-r.html#install-r-and-r-studio-locally-to-your-computer",
    "title": "3Â  Tool foR Data",
    "section": "\n3.3 Install R and R Studio Locally to Your Computer",
    "text": "3.3 Install R and R Studio Locally to Your Computer\n Install R \n Step 1 \n\nGo to https://cloud.r-project.org.\nClick Download R for [your operating system].\n\n\n\nFigureÂ 3.12: Downloading R\n\n\n Step 2 \n\nIf you are a Mac user, you should see the page shown below in FigureÂ 3.13.\nYou are recommended to download and install the latest version of R (now R-4.2.1) if your OS version allows to do so.\nOtherwise, choose a previous version, such as R-3.6.3.\n\n\n\nFigureÂ 3.13: Downloading R for Mac\n\n\n\nIf you are a Windows user, after clicking Download R for Windows, please choose base version and then click Download R-4.2.1 for Windows.\n\n Step 3 \n\nOnce you successfully install R, when you open R, you should be able to see the following R terminal or console:\n\n\n\n\nWindows\n\n\n\nFigureÂ 3.14: Windows R Console\n\n\n\n\n\n\nMac\n\n\n\nFigureÂ 3.15: Mac R Console\n\n\n\n\n Welcome to the R World! \n\nNow you are ready to use R for statistical computation.\nYou can use R like a calculator.\n\nAfter typing your formula, simply hit enter and you get the answer!\n\n\n\n\n1 + 2\n\n[1] 3\n\n30 * 42 / 3\n\n[1] 420\n\nlog(5) - exp(3) * sqrt(7)\n\n[1] -51.5319\n\n\n\n Install RStudio \n Step 1 \n\nIn the RStudio website, please choose Products > RStudio as shown in FigureÂ 3.16.\n\n\n\nFigureÂ 3.16: R Studio Website\n\n\n Step 2 \n\nChoose RStudio Desktop and click DOWNLOAD RSTUDIO DESKTOP for the free version.\n\n\n\n\n\nFigureÂ 3.17: Downloading RStudio Desktop\n\n\n\n\n Step 3 \n\nClick DOWNLOAD RSTUDIO FOR [YOUR SYSTEM] (FigureÂ 3.18).\nFollow the standard installation steps and you should get the software.\nMake sure that R is installed successfully on your computer before you download and install RStudio.\n\n\n\n\n\n\n\nNote\n\n\n\nThe latest version of RStudio is 2022.07.1+554.\n\n\n\n\n\n\nFigureÂ 3.18: Latest version of RStudio\n\n\n\n\n\n RStudio Screen \n\nWhen you open RStudio, you should see something similar to FigureÂ 3.19 below.\nIf you do, congratulations!\nYou can now do any statistical computation in R using RStudio locally on your computer.\n\n\n\n\n\nFigureÂ 3.19: R Studio Screen"
  },
  {
    "objectID": "intro-r.html#operators",
    "href": "intro-r.html#operators",
    "title": "3Â  Tool foR Data",
    "section": "\n3.4 Operators",
    "text": "3.4 Operators\n R is a Calculator \n Arithmetic Operators \n\n\n\n\nFigureÂ 3.20: Table of arithmetic operators\n\n\n\n\n Examples \n\n2 + 3 * 5 + 4\n\n[1] 21\n\n2 + 3 * (5 + 4)\n\n[1] 29\n\n\n\nWe have to do the operation in the parentheses first, as the PEMDAS rule describes in FigureÂ 3.21 below.\n\n\n\n\n\nFigureÂ 3.21: Order of operations\n\n\n\n\n\n R Does Comparisons \n Logical Operators \n\n\n\n\nFigureÂ 3.22: Table of logical operators\n\n\n\n\n Examples \n\n\n\n5 <= 5\n\n[1] TRUE\n\n5 <= 4\n\n[1] FALSE\n\n# Is 5 is NOT equal to 5? FALSE\n5 != 5\n\n[1] FALSE\n\n\n\n\n\n\n## Is TRUE not equal to FALSE?\nTRUE != FALSE\n\n[1] TRUE\n\n## Is not TRUE equal to FALSE?\n!TRUE == FALSE\n\n[1] TRUE\n\n## TRUE if either one is TRUE or both are TRUE\nTRUE | FALSE\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\n\nWhat does TRUE & FALSE return?\n\n\n\n\n\n\n\n Built-in Functions \n\nR has lots of built-in functions, especially for mathematics, probability and statistics.\n\n\n\n\n\nFigureÂ 3.23: R Built-in functions\n\n\n\n\n Examples \n\n\n\nsqrt(144)\n\n[1] 12\n\nexp(1)  ## Euler's number\n\n[1] 2.718282\n\nsin(pi/2)\n\n[1] 1\n\nabs(-7)\n\n[1] 7\n\n\n\n\n\n\nfactorial(5)\n\n[1] 120\n\n## without specifying base value\n## it is a natural log with base e\nlog(100)\n\n[1] 4.60517\n\n## log function and we specify base = 2\nlog(100, base = 10)\n\n[1] 2\n\n\n\n\n\n Commenting \n\n\n\n\n\n\nYouâ€™ve seen comments a lot! How do we write a comment in R?\n\n\n\n\n\n\n\nUse # to add a comment so that the text after # is not read as an R command.\nWriting (good) comments is highly recommended.\nComments help readers, and more importantly yourself, understand what the code is doing.\nThey should explain the why, not the what.\n\n\n\n\n\n\n\nhttps://www.reddit.com/r/ProgrammerHumor /comments/8w54mx/code_comments_be_like/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Objects and Funtions in R \n\n Everything that exists is an object.  Everything that happens is a function call. \nâ€“ John Chambers, the creator of the S programming language.\n\n\nWe have made lots of things happen!\nEven arithmetic and logical operators are functions!\n\n\n`+`(x = 2, y = 3)\n\n[1] 5\n\n`&`(TRUE, FALSE)\n\n[1] FALSE\n\n\n\n Creating Variables \n\nA variable stores a value that can be changed according to our need.\nUse the <- operator to assign a value to the variable. (Highly recommendedðŸ‘)\n\n\nx <- 5  ## we create an object, value 5, and call it x, which is a variable.\nx  ## type the variable name to see the value stored in the object x\n\n[1] 5\n\n\n\n\n(x <- x + 6)  # We can reassign any value to the variable we created\n\n[1] 11\n\nx == 5  # We can perform any operations on variables\n\n[1] FALSE\n\nlog(x) # Variables can also be used in any built-in functions\n\n[1] 2.397895\n\n\n\n\n\n\n\n\n\n\n\n Bad Naming \n\nâŒ Unless you have a very good reason, donâ€™t create a variable whose name is the same as any R built-in constant or function!\nðŸ˜Ÿ It causes lots of confusion when your code is long and when others read it.\n\n\n## THIS IS BAD CODING! DON'T DO THIS!\npi  ## pi is a built-in constant\n\n[1] 3.141593\n\n(pi <- 20)\n\n[1] 20\n\nabs ## abs is a built-in function\n\nfunction (x)  .Primitive(\"abs\")\n\n(abs <- abs(pi))\n\n[1] 20"
  },
  {
    "objectID": "intro-r.html#object-types",
    "href": "intro-r.html#object-types",
    "title": "3Â  Tool foR Data",
    "section": "\n3.5 Object Types",
    "text": "3.5 Object Types\n Types of Variables \n\nUse typeof() to check which type a variable belongs to.\nCommon types include character, double, integer and logical.\nTo check if itâ€™s of a specific type, use is.character(), is.double(), is.integer(), is.logical().\n\n\n\n\ntypeof(5)\n\n[1] \"double\"\n\ntypeof(5L)\n\n[1] \"integer\"\n\ntypeof(\"I_love_stats!\")\n\n[1] \"character\"\n\n\n\n\n\n\ntypeof(1 > 3)\n\n[1] \"logical\"\n\nis.double(5L)\n\n[1] FALSE\n\n\n\n\n Variable Types in R and in Statistics \n\nType character and logical correspond to categorical variables.\n\nType logical is a special type of categorical variables that has only two categories (binary).\n\nWe usually call it a binary variable.\n\n\n\n\nType double and integer correspond to numerical variables. (an exception later)\n\nType double is for continuous variables\nType integer is for discrete variables."
  },
  {
    "objectID": "intro-r.html#r-data-structures",
    "href": "intro-r.html#r-data-structures",
    "title": "3Â  Tool foR Data",
    "section": "\n3.6 R Data Structures",
    "text": "3.6 R Data Structures\n (Atomic) Vector \n\nTo create a vector, use c(), which is short for concatenate or combine.\n\nAll elements of a vector must be of the same type.\n\n\n\n\n(dbl_vec <- c(1, 2.5, 4.5)) \n\n[1] 1.0 2.5 4.5\n\n(int_vec <- c(1L, 6L, 10L))\n\n[1]  1  6 10\n\n## TRUE and FALSE can be written as T and F\n(log_vec <- c(TRUE, FALSE, F))  \n\n[1]  TRUE FALSE FALSE\n\n(chr_vec <- c(\"pretty\", \"girl\"))\n\n[1] \"pretty\" \"girl\"  \n\n\n\n\n\n\n## check how many elements in a vector\nlength(dbl_vec) \n\n[1] 3\n\n## check a compact description of \n## any R data structure\nstr(dbl_vec) \n\n num [1:3] 1 2.5 4.5\n\n\n\n\n Operations on Vectors \n\nWe can do the same operations on vectors that we do on a scalar variable (vector of length 1).\n\n\n\n\n# Create two vectors\nv1 <- c(3, 8)\nv2 <- c(4, 100) \n\n## All operations happen element-wisely\n# Vector addition\nv1 + v2\n\n[1]   7 108\n\n# Vector subtraction\nv1 - v2\n\n[1]  -1 -92\n\n\n\n\n\n\n# Vector multiplication\nv1 * v2\n\n[1]  12 800\n\n# Vector division\nv1 / v2\n\n[1] 0.75 0.08\n\nsqrt(v2)\n\n[1]  2 10\n\n\n\n\n Recycling of Vectors \n\nIf we apply arithmetic operations to two vectors of unequal length, the elements of the shorter vector will be recycled to complete the operations.  \n\n\n\nv1 <- c(3, 8, 4, 5)\n# The following 2 operations are the same\nv1 * 2\n\n[1]  6 16  8 10\n\nv1 * c(2, 2, 2, 2)\n\n[1]  6 16  8 10\n\nv3 <- c(4, 11)\nv1 + v3  ## v3 becomes c(4, 11, 4, 11) when doing the operation\n\n[1]  7 19  8 16\n\n\n Subsetting Vectors \n\nTo extract element(s) in a vector, use a pair of brackets [] with element indexing.\nThe indexing starts with 1.\n\n\n\n\nv1\n\n[1] 3 8 4 5\n\nv2\n\n[1]   4 100\n\n## The first element\nv1[1] \n\n[1] 3\n\n## The second element\nv2[2]  \n\n[1] 100\n\n\n\n\n\n\nv1[c(1, 3)]\n\n[1] 3 4\n\n## extract all except a few elements\n## put a negative sign before the vector of \n## indices\nv1[-c(2, 3)] \n\n[1] 3 5\n\n\n\n\n\n Factor \n\nA vector of type factor can be ordered in a meaningful way.\n\nCreate a factor by factor().\nIt is a type of integer, not character. ðŸ˜² ðŸ™„\n\n\nfac <- factor(c(\"med\", \"high\", \"low\"))\ntypeof(fac)\n\n[1] \"integer\"\n\nlevels(fac) ## Each level represents an integer, ordered from the vector alphabetically.\n\n[1] \"high\" \"low\"  \"med\" \n\nstr(fac)  ## The integers show the level each element in vector fac belongs to.\n\n Factor w/ 3 levels \"high\",\"low\",\"med\": 3 1 2\n\norder_fac <- factor(c(\"med\", \"high\", \"low\"), levels = c(\"low\", \"med\", \"high\"))\nstr(order_fac)\n\n Factor w/ 3 levels \"low\",\"med\",\"high\": 2 3 1\n\n\n\n List (Generic Vectors) \n\nLists are different from vectors.\n\nElements can be of any type, including lists.\n\n\nConstruct a list by using list() instead of c().\n\n\n\n\n## a list of 3 elements of different types\nx_lst <- list(idx = 1:3, \n              \"a\", \n              c(TRUE, FALSE))\nx_lst\n\n$idx\n[1] 1 2 3\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1]  TRUE FALSE\n\n\n\n\n\n\nstr(x_lst)\n\nList of 3\n $ idx: int [1:3] 1 2 3\n $    : chr \"a\"\n $    : logi [1:2] TRUE FALSE\n\nnames(x_lst)\n\n[1] \"idx\" \"\"    \"\"   \n\nlength(x_lst)\n\n[1] 3\n\n\n\n\n Subsetting a List \n\nx_lst <- list(idx = 1:3, \n              \"a\", \n              c(TRUE, FALSE))\n\n\n\n\nReturn an  element  of a list\n\n\n## subset by name (a vector)\nx_lst$idx  \n\n[1] 1 2 3\n\n## subset by indexing (a vector)\nx_lst[[1]]  \n\n[1] 1 2 3\n\ntypeof(x_lst$idx)\n\n[1] \"integer\"\n\n\n\n\n\n\nReturn a  sub-list  of a list\n\n\n## subset by name (still a list)\nx_lst[\"idx\"]  \n\n$idx\n[1] 1 2 3\n\n## subset by indexing (still a list)\nx_lst[1]  \n\n$idx\n[1] 1 2 3\n\ntypeof(x_lst[\"idx\"])\n\n[1] \"list\"\n\n\n\n\n\n\n\n\n\nFigureÂ 3.24: Condiment analogy for subsetting lists\n\n\n\n\n\n\nIf list x is a train carrying objects, then x[[5]] is the object in car 5; x[4:6] is a train of cars 4-6.\nâ€” @RLangTip, https://twitter.com/RLangTip/status/268375867468681216\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 3.25: Train analogy for subsetting a list\n\n\n\n\n\n Matrix \n\nA matrix is a two-dimensional analog of a vector.\nUse command matrix() to create a matrix.\n\n\n## Create a 3 by 2 matrix called mat\n(mat <- matrix(data = 1:6, nrow = 3, ncol = 2)) \n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\ndim(mat); nrow(mat); ncol(mat)\n\n[1] 3 2\n\n\n[1] 3\n\n\n[1] 2\n\n\n Subsetting a Matrix \n\nTo extract a sub-matrix, use the same indexing approach as vectors.\nUse comma , to separate the row and column index.\n\n\nmat[2, 2] extracts the element of the second row and second column.\n\n\n\n\n\n\nmat\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n## all rows and 2nd column\n## leave row index blank\n## specify 2 in coln index\nmat[, 2]\n\n[1] 4 5 6\n\n\n\n\n\n\n## 2nd row and all columns\nmat[2, ] \n\n[1] 2 5\n\n## The 1st and 3rd rows\nmat[c(1, 3), ] \n\n     [,1] [,2]\n[1,]    1    4\n[2,]    3    6\n\n\n\n\n Binding Matrices \n\nWe can generalize c() used in vectors to cbind() (binding matrices by adding columns) and rbind() (binding matrices by adding rows) for matrices.\nWhen matrices are combined by columns, they should have the same number of rows.\nWhen matrices are combined by rows, they should have the same number of columns.\n\n\n\n\nmat\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\nmat_c <- matrix(data = c(7, 0, 0, 8, 2, 6), \n                nrow = 3, ncol = 2)\n## should have the same number of rows\ncbind(mat, mat_c)  \n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7    8\n[2,]    2    5    0    2\n[3,]    3    6    0    6\n\n\n\n\n\n\nmat_r <- matrix(data = 1:4, \n                nrow = 2, \n                ncol = 2)\n## should have the same number of columns\nrbind(mat, mat_r)  \n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n[4,]    1    3\n[5,]    2    4\n\n\n\n\n\n Data Frame: The Most Common Way of Storing Data \n\nA data frame is of type list of equal-length vectors, having a 2-dimensional structure.\nIt is more general than a matrix.\n\nDifferent columns can have different types.\n\n\nTo create a data frame, use data.frame() that takes named vectors as input.\n\n\n\n\n## data frame w/ an dbl column named  \n## and char column named grade.\n(df <- data.frame(age = c(19,21,40), \n                  gender = c(\"m\",\"f\",\"m\")))\n\n  age gender\n1  19      m\n2  21      f\n3  40      m\n\n## a data frame has a list structure\nstr(df)  \n\n'data.frame':   3 obs. of  2 variables:\n $ age   : num  19 21 40\n $ gender: chr  \"m\" \"f\" \"m\"\n\n\n\n\n\n\n## must set column names\n## or they are ugly and non-recognizable\ndata.frame(c(19, 21, 40), c(\"m\",\"f\", \"m\")) \n\n  c.19..21..40. c..m....f....m..\n1            19                m\n2            21                f\n3            40                m\n\n\n\n\n Properties of Data Frames \n\nData frame has properties of matrix and list.\n\n\n\n\nnames(df)  ## df as a list\n\n[1] \"age\"    \"gender\"\n\ncolnames(df)  ## df as a matrix\n\n[1] \"age\"    \"gender\"\n\nlength(df) ## df as a list\n\n[1] 2\n\nncol(df) ## df as a matrix\n\n[1] 2\n\ndim(df) ## df as a matrix\n\n[1] 3 2\n\n\n\n\n\n\n## rbind() and cbind() can be used on df\n\ndf_r <- data.frame(age = 10, \n                   gender = \"f\")\nrbind(df, df_r)\n\n  age gender\n1  19      m\n2  21      f\n3  40      m\n4  10      f\n\ndf_c <- \n    data.frame(col = c(\"red\",\"blue\",\"gray\"))\n(df_new <- cbind(df, df_c))\n\n  age gender  col\n1  19      m  red\n2  21      f blue\n3  40      m gray\n\n\n\n\n Subsetting a Data Frame \n\nWhen we subset data frames, we can use either list or matrix subsetting methods.\n\n\n\n\ndf_new\n\n  age gender  col\n1  19      m  red\n2  21      f blue\n3  40      m gray\n\n## Subset rows\ndf_new[c(1, 3), ]\n\n  age gender  col\n1  19      m  red\n3  40      m gray\n\n## select the row where age == 21\ndf_new[df_new$age == 21, ]\n\n  age gender  col\n2  21      f blue\n\n\n\n\n\n\n## Subset columns\n## like a list\ndf_new$age\n\n[1] 19 21 40\n\ndf_new[c(\"age\", \"gender\")]\n\n  age gender\n1  19      m\n2  21      f\n3  40      m\n\n## like a matrix\ndf_new[, c(\"age\", \"gender\")]\n\n  age gender\n1  19      m\n2  21      f\n3  40      m\n\n\n\n\n\n\n\n\n\n\n\nYou can do it!\n\n\n\n\nCreate a vector object called x that has 5 elements 3, 6, 2, 9, 14.\nCompute the average of elements of x.\nSubset the mtcars data set by selecting variables mpg and disp.\nSelect the cars (rows) in mtcars that have 4 cylinders."
  },
  {
    "objectID": "intro-r.html#exercises",
    "href": "intro-r.html#exercises",
    "title": "3Â  Tool foR Data",
    "section": "\n3.7 Exercises",
    "text": "3.7 Exercises\n\n# ==============================================================================\n## Vector\n# ==============================================================================\npoker_vec <- c(170, -20, 50, -140, 210)\nroulette_vec <- c(-30, -40, 70, -340, 20)\ndays_vec <- c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\")\nnames(poker_vec) <- days_vec\nnames(roulette_vec) <- days_vec\n\n\nVector\n\nThe code above shows a Marquette student poker and roulette winnings from Monday to Friday. Copy and paste them into your R and complete problem 1.\n\nAssign to the variable total_daily how much you won or lost on each day in total (poker and roulette combined).\nCalculate the winnings overall total_week. Print it out.\n\n\n\n# ==============================================================================\n## Factor\n# ==============================================================================\n# Create speed_vector\nspeed_vec <- c(\"medium\", \"low\", \"low\", \"medium\", \"high\")\n\n\nFactor\n\n\n\nspeed_vec above should be converted to an ordinal factor since its categories have a natural ordering. Create an ordered factor vector speed_fac by completing the code below. Set ordered to TRUE, and set levels to c(\"low\", \"medium\", \"high\"). Print speed_fac.\n\n\n_________ <- factor(________, ordered = ______, \n                    levels = ______________________)\n\n\n\n# ==============================================================================\n## Data frame\n# ==============================================================================\n# Definition of vectors\nname <- c(\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \n          \"Uranus\", \"Neptune\")\ntype <- c(\"Terrestrial planet\", \"Terrestrial planet\", \"Terrestrial planet\", \n          \"Terrestrial planet\", \"Gas giant\", \"Gas giant\", \n          \"Gas giant\", \"Gas giant\")\ndiameter <- c(0.375, 0.947, 1, 0.537, 11.219, 9.349, 4.018, 3.843)\nrotation <- c(57.63, -242.03, 1, 1.05, 0.42, 0.44, -0.73, 0.65)\nrings <- c(FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE)\n\n\nData Frame\n\nData frames have properties of lists and matrices, so we skip lists and matrices and focus on data frames. You want to construct a data frame that describes the main characteristics of eight planets in our solar system. You feel confident enough to create the necessary vectors: name, type, diameter, rotation and rings that have already been coded up as above. The first element in each of these vectors corresponds to the first observation.\n\nUse the function data.frame() to construct a data frame. Pass the vectors name, type, diameter, rotation and rings as arguments to data.frame(), in this order. Call the resulting data frame planets_df.\n\n\n________ <- data.frame(______, ______, ______, ______, ______)\n\n\nUse str() to investigate the structure of the new planets_df variable. Which are categorical (qualitative) variables and which are numerical (quantitative) variables? For those that are categorical, are they nominal or ordinal? For those numerical variables, are they interval or ratio level? discrete or continuous?\nFrom planets_df, select the diameter of Mercury: this is the value at the first row and the third column. Simply print out the result.\nFrom planets_df, select all data on Mars (the fourth row). Simply print out the result.\nSelect and print out the first 5 values in the diameter column of planets_df.\nUse $ to select the rings variable from planets_df.\nUse (f) to select all columns for planets that have rings."
  },
  {
    "objectID": "data-graphics.html#frequency-table-for-categorical-variable",
    "href": "data-graphics.html#frequency-table-for-categorical-variable",
    "title": "4Â  Data Visualization",
    "section": "\n4.1 Frequency Table for Categorical Variable",
    "text": "4.1 Frequency Table for Categorical Variable\n\nA frequency table (frequency distribution) lists variable values individually for categorical data along with their corresponding number of times occurred in the data (frequencies or counts).\nBelow is an example of a frequency table for categorical data with \\(n\\) being the total number of data values.\n\n\n\nCategory name\nFrequency\nRelative Frequency\n\n\n\n\\(C_1\\)\n\\(f_1\\)\n\\(f_1/n\\)\n\n\n\\(C_2\\)\n\\(f_2\\)\n\\(f_2/n\\)\n\n\nâ€¦\nâ€¦\nâ€¦\n\n\n\\(C_k\\)\n\\(f_k\\)\n\\(f_k/n\\)\n\n\n\n\nHere is another example of a categorical variable color that has three categories.\n\n\n\nCategory name\nFrequency\nRelative Frequency\n\n\n\nRed ðŸ”´\n8\n8/50 = 0.16\n\n\nBlue ðŸ”µ\n26\n26/50 = 0.52\n\n\nBlack âš«\n16\n16/50 = 0.32\n\n\n\n Categorical Frequency Table in R \nloan50\n\nBelow is the loan50 data set from the openintro package in R.\n\n\n# install.packages(\"openintro\")\nlibrary(openintro)\nstr(loan50)\n\ntibble [50 Ã— 18] (S3: tbl_df/tbl/data.frame)\n $ state                  : Factor w/ 51 levels \"\",\"AK\",\"AL\",\"AR\",..: 32 6 41 6 36 16 35 25 11 11 ...\n $ emp_length             : num [1:50] 3 10 NA 0 4 6 2 10 6 3 ...\n $ term                   : num [1:50] 60 36 36 36 60 36 36 36 60 60 ...\n $ homeownership          : Factor w/ 3 levels \"rent\",\"mortgage\",..: 1 1 2 1 2 2 1 2 1 2 ...\n $ annual_income          : num [1:50] 59000 60000 75000 75000 254000 67000 28800 80000 34000 80000 ...\n $ verified_income        : Factor w/ 4 levels \"\",\"Not Verified\",..: 2 2 4 2 2 3 3 2 2 3 ...\n $ debt_to_income         : num [1:50] 0.558 1.306 1.056 0.574 0.238 ...\n $ total_credit_limit     : int [1:50] 95131 51929 301373 59890 422619 349825 15980 258439 87705 330394 ...\n $ total_credit_utilized  : int [1:50] 32894 78341 79221 43076 60490 72162 2872 28073 23715 32036 ...\n $ num_cc_carrying_balance: int [1:50] 8 2 14 10 2 4 1 3 10 4 ...\n $ loan_purpose           : Factor w/ 14 levels \"\",\"car\",\"credit_card\",..: 4 3 4 3 5 5 4 3 3 4 ...\n $ loan_amount            : int [1:50] 22000 6000 25000 6000 25000 6400 3000 14500 10000 18500 ...\n $ grade                  : Factor w/ 8 levels \"\",\"A\",\"B\",\"C\",..: 3 3 6 3 3 3 5 2 2 4 ...\n $ interest_rate          : num [1:50] 10.9 9.92 26.3 9.92 9.43 ...\n $ public_record_bankrupt : int [1:50] 0 1 0 0 0 0 0 0 0 1 ...\n $ loan_status            : Factor w/ 7 levels \"\",\"Charged Off\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ has_second_income      : logi [1:50] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ total_income           : num [1:50] 59000 60000 75000 75000 254000 67000 28800 80000 34000 192000 ...\n\n\n\nhomeownership\n\nThe values as well as the frequency table for the variable homeownership from the loan50 data set are shown below.\n\n\n# 50 values (rent, mortgage, own) of categorical homeownership in loan50 data\n(x <- loan50$homeownership)\n\n [1] rent     rent     mortgage rent     mortgage mortgage rent     mortgage\n [9] rent     mortgage rent     mortgage rent     mortgage rent     mortgage\n[17] rent     rent     rent     mortgage mortgage mortgage mortgage rent    \n[25] mortgage rent     mortgage own      mortgage mortgage rent     mortgage\n[33] mortgage rent     rent     own      mortgage rent     mortgage rent    \n[41] mortgage rent     rent     mortgage mortgage mortgage mortgage rent    \n[49] own      mortgage\nLevels: rent mortgage own\n\n## frequency table\ntable(x)\n\nx\n    rent mortgage      own \n      21       26        3 \n\n\n\n\n\n\n\n\n\nIf we want to create a frequency table shown in definition, which R data structure we can use?\n\n\n\n\n\n\n\nfreq <- table(x)\nrel_freq <- freq / sum(freq)\ncbind(freq, rel_freq)\n\n         freq rel_freq\nrent       21     0.42\nmortgage   26     0.52\nown         3     0.06\n\n\n\n Visualizing a Frequency Table \n Bar Chart \n\nBelow is a bar chart that visualizes the homeownership frequency table.\n\n\nbarplot(height = table(x), main = \"Bar Chart\", xlab = \"Homeownership\")\n\n\n\n\n Pie Chart \n\nThe homeownership frequency table can also be visualized using a pie chart.\n\n\npie(x = table(x), main = \"Pie Chart\")"
  },
  {
    "objectID": "data-graphics.html#frequency-distribution-for-numerical-variables",
    "href": "data-graphics.html#frequency-distribution-for-numerical-variables",
    "title": "4Â  Data Visualization",
    "section": "\n4.2 Frequency Distribution for Numerical Variables",
    "text": "4.2 Frequency Distribution for Numerical Variables\n\nTo create a frequency distribution for numerical variables, one must\n\nDivide the data into \\(k\\) non-overlapping groups of intervals (classes).\nConvert the data into \\(k\\) categories with an associated class interval.\nCount the number of measurements falling in a given class interval (class frequency).\n\n\n\n\n\nClass\nClass Interval\nFrequency\nRelative Frequency\n\n\n\n\\(1\\)\n\\([a_1, a_2]\\)\n\\(f_1\\)\n\\(f_1/n\\)\n\n\n\\(2\\)\n\\((a_2, a_3]\\)\n\\(f_2\\)\n\\(f_2/n\\)\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\\(k\\)\n\\((a_k, a_{k+1}]\\)\n\\(f_k\\)\n\\(f_k/n\\)\n\n\n\n\n\n\\((a_2 - a_1) = (a_3 - a_2) = \\cdots = (a_{k+1} - a_k)\\). All class widths are the same!\n\n\n\n\n\n\n\nCan our grade conversion be used for creating a frequency distribution?\n\n\n\n\nNo, because the class widths are not all the same as seen in FigureÂ 4.2.\n\n\n\n\n\n\n\n\nGrade\n\n\nPercentage\n\n\n\n\n\nA\n\n\n[94, 100]\n\n\n\n\nA-\n\n\n[90, 94)\n\n\n\n\nB+\n\n\n[87, 90)\n\n\n\n\nB\n\n\n[83, 87)\n\n\n\n\nB-\n\n\n[80, 83)\n\n\n\n\nC+\n\n\n[77, 80)\n\n\n\n\nC\n\n\n[73, 77)\n\n\n\n\nC-\n\n\n[70, 73)\n\n\n\n\nD+\n\n\n[65, 70)\n\n\n\n\nD\n\n\n[60, 65)\n\n\n\n\nF\n\n\n[0, 60)\n\n\n\n\nFigureÂ 4.2: Grading scale for this class\n\n\n\n\n Interest Rate Data loan50 [OI] \n\nBelow is data for the interest rate variable in the loan 50 data set.\n\n\n(int_rate <- round(loan50$interest_rate, 1))\n\n [1] 10.9  9.9 26.3  9.9  9.4  9.9 17.1  6.1  8.0 12.6 17.1  5.3  7.3  5.3  8.0\n[16] 24.9 18.1 10.4  8.0 19.4 14.1 20.0  9.4  9.9 10.9  5.3  6.7 15.0 12.0 12.6\n[31] 10.9  9.4  9.9  7.3 18.4 17.1  8.0  6.1  6.7  7.3 12.6 16.0 10.9  9.9  9.4\n[46] 10.4 21.4 10.9  9.4  6.1\n\n\n\n\n\n\n\n\n\n\n Frequency Distribution of Interest Rate \n\n\n\n\n Class Class_Intvl Freq Rel_Freq\n     1     5%-7.5%   11     0.22\n     2    7.5%-10%   15     0.30\n     3   10%-12.5%    8     0.16\n     4   12.5%-15%    5     0.10\n     5   15%-17.5%    4     0.08\n     6   17.5%-20%    4     0.08\n     7   20%-22.5%    1     0.02\n     8   22.5%-25%    1     0.02\n     9   25%-27.5%    1     0.02\n\n\n\nrange(int_rate)\n\n[1]  5.3 26.3\n\n\n\n\nAll class widths are the same (2.5%)!\nThe number of classes should not be too big or too small.\nThe lower limit of the 1st class should not be greater than the minimum value of the data.\n\nThe lower limit of the 1st class is 5%, which is less than the minimum value of 5.3%.\n\n\nThe upper limit of the last class should not be smaller than the maximum value of the data.\n\nThe upper limit of the last class is 27.5%, which is greater than the maximum value of 26.3%.\n\n\n\n\n\n\n\n\n\n\n\nHow do we choose the number of classes or the class width?\n\n\n\nR decides the number of classes for us when we visualize the frequency distribution by a histogram.\n\n\n\n Visualizing Frequency Distribution by a Histogram \n\n\n\nUse default breaks (no need to specify)\n\n\nhist(x = int_rate, \n     xlab = \"Interest Rate (%)\",\n     main = \"Hist. of Int. Rate (Defualt)\")\n\n\n\n\n\n\n\n\nUse customized breaks\n\n\nclass_boundary\n\n [1]  5.0  7.5 10.0 12.5 15.0 17.5 20.0 22.5 25.0 27.5\n\nhist(x = int_rate, \n     breaks = class_boundary, #<<\n     xlab = \"Interest Rate (%)\",\n     main = \"Hist. of Int. Rate (Ours)\")\n\n\n\n\n\n\n Skewness \n\nKey characteristics of distributions include the shape, center and spread.\nSkewness provides a way to summarize the shape of a distribution.\n\n\n\n\n\nFigureÂ 4.3: Distribution characteristics\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs the interest rate histogram left skewed or right skewed?\n\n\n\n\n\n\n\n\n\n\nFigureÂ 4.4: Interest Rate Histogram\n\n\n\n\n\n\n\n\n\nFigureÂ 4.5: Trick for remembering skewness (Biostatistics for the Biological and Health Sciences p.53)\n\n\n\n\n\n\n\n Scatterplot for Two Numerical Variables \n\n\nA scatterplot provides a case-by-case view of data for two numerical variables.\nBelow is a scatterplot of Loan Amount vs.Â Total Income from the loan 50 data.\n\n\nplot(x = loan50$total_income, y = loan50$loan_amount,\n     xlab = \"Total Income\", ylab = \"Loan Amount\",\n     pch = 16, col = 4)"
  },
  {
    "objectID": "data-graphics.html#exercises",
    "href": "data-graphics.html#exercises",
    "title": "4Â  Data Visualization",
    "section": "\n4.3 Exercises",
    "text": "4.3 Exercises\nIn the following, we will be using the data set mtcars to do some data summary and graphics. First load the data set into your R session by the command data(mtcars). The data set is like\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nPlease see ?mtcars for the description of the data set.\n\nUse the function pie() to create a pie chart for the number of carburetors (carb). What the number of carburetors has the most frequencies in the data?\nUse the function barplot() to create a bar chart for the number of cylinders (cyl). What the number of cylinders has the most frequencies in the data?\nUse the function hist() to generate a histogram of the gross horsepower (hp). Is it right or left-skewed?\nUse the function plot() to create a scatter plot of weight (wt) vs.Â miles per gallon (mpg). As the weight increases, does the miles per gallon tend to increase or decrease?"
  },
  {
    "objectID": "data-numerics.html#measures-of-center",
    "href": "data-numerics.html#measures-of-center",
    "title": "5Â  Data Sample Statistics",
    "section": "\n5.1 Measures of Center",
    "text": "5.1 Measures of Center\n Mean \n\nThe (arithmetic) mean or average is calculated by adding up all of the values and then dividing by the total number of them.\nThe population mean is denoted as \\(\\mu\\).\nLet \\(x_1, x_2, \\dots, x_n\\) denote the measurements observed in a sample of size \\(n\\).\n\nThe sample mean is defined as\n\n\n\n\n\\[\\overline{x} = \\frac{\\sum_{i=1}^{n} x_i}{n} = \\frac{x_1 + x_2 + \\dots + x_n}{n}\\]\n\n\nFor the interest rate example,\n\n\n\\[\\overline{x} = \\frac{10.9\\% + 9.9\\% + \\cdots + 6.1\\%}{50} = 11.56\\%\\]\n\n Calculate Mean in R \n\n\n\n\nmean(int_rate)\n\n[1] 11.558\n\n\n Balancing Point \n\nThink of the mean as the balancing point of the distribution.\n\n\n\n\n\n\n\nFigureÂ 5.1: Mean as a balancing point for interest rate example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Median \n\nThe median is the middle value when data values are sorted.\nHalf of the values are less than or equal to the median, and the other half are greater than the median.\nTo find the median, we first sort the values.\nIf \\(n\\) is odd, the median is located in the exact middle of the ordered values.\n\n Data: (0, 2, 10, 14, 8) \n Sorted Data: (0, 2, 8, 10, 14) \n\n The median is \\(8\\) .\n\n\nIf \\(n\\) is even, the median is the average of the two middle numbers.\n\n Data: (0, 2, 10, 14, 8, 12) \n Sorted Data: (0, 2, 8, 10, 12, 14) \n\n The median is \\(\\frac{8 + 10}{2} = 9\\) .\n\n\n\n Calculate Median in R \n\nThere are two ways to calculate the median in R.\n\n\nmedian(int_rate)  ## Compute the median using command median()\n\n[1] 9.9\n\n\n\n## Compute the median using definition\n(sort_rate <- sort(int_rate))  ## sort data\n\n [1]  5.3  5.3  5.3  6.1  6.1  6.1  6.7  6.7  7.3  7.3  7.3  8.0  8.0  8.0  8.0\n[16]  9.4  9.4  9.4  9.4  9.4  9.9  9.9  9.9  9.9  9.9  9.9 10.4 10.4 10.9 10.9\n[31] 10.9 10.9 10.9 12.0 12.6 12.6 12.6 14.1 15.0 16.0 17.1 17.1 17.1 18.1 18.4\n[46] 19.4 20.0 21.4 24.9 26.3\n\nlength(int_rate)  ## Check sample size is odd or even\n\n[1] 50\n\n(sort_rate[25] + sort_rate[26]) / 2  ## Verify the answer\n\n[1] 9.9\n\n\n\n\n\n\n\n\nWarning\n\n\n\n\nBe sure to sort the data first if computing the median using its definition.\n\n\n\n\n(int_rate[25] + int_rate[26]) / 2  ## Using un-sorted data leads to a wrong answer!!\n\n[1] 8.1\n\n\n\n Mode \n\nThe mode is the value that occurs most frequently.\nFor continuous numerical data, it is common for there not to be any observations that share the same value.\nA more practical definition is that a mode is represented by a prominent peak in the distribution.\n\n Calculate Mode in R \n\n## Create a frequency table \n(table_data <- table(int_rate))\n\nint_rate\n 5.3  6.1  6.7  7.3    8  9.4  9.9 10.4 10.9   12 12.6 14.1   15   16 17.1 18.1 \n   3    3    2    3    4    5    6    2    5    1    3    1    1    1    3    1 \n18.4 19.4   20 21.4 24.9 26.3 \n   1    1    1    1    1    1 \n\n\n\n## Sort the table to find the mode that occurs most frequently\n## the number that happens most frequently will be the first one\nsort(table_data, decreasing = TRUE)\n\nint_rate\n 9.9  9.4 10.9    8  5.3  6.1  7.3 12.6 17.1  6.7 10.4   12 14.1   15   16 18.1 \n   6    5    5    4    3    3    3    3    3    2    2    1    1    1    1    1 \n18.4 19.4   20 21.4 24.9 26.3 \n   1    1    1    1    1    1"
  },
  {
    "objectID": "data-numerics.html#comparison-of-mean-median-and-mode",
    "href": "data-numerics.html#comparison-of-mean-median-and-mode",
    "title": "5Â  Data Sample Statistics",
    "section": "\n5.2 Comparison of Mean, Median and Mode",
    "text": "5.2 Comparison of Mean, Median and Mode\n\nThe mode is applicable for both categorical and numerical data, while the median and mean work for numerical data only.\nIt is also possible to have more than one mode, but there is only one median and one mean.\nThe mean is sensitive to extreme values (outliers).\nThe median and mode are more robust than the mean.\n\nBeing more robust means these measures of center are more resistant to the addition of extreme values to the data.\nAn example in R is shown below:\n\n\n\n\ndata_extreme\n\n [1] 90.0  9.9 26.3  9.9  9.4  9.9 17.1  6.1  8.0 12.6 17.1  5.3  7.3  5.3  8.0\n[16] 24.9 18.1 10.4  8.0 19.4 14.1 20.0  9.4  9.9 10.9  5.3  6.7 15.0 12.0 12.6\n[31] 10.9  9.4  9.9  7.3 18.4 17.1  8.0  6.1  6.7  7.3 12.6 16.0 10.9  9.9  9.4\n[46] 10.4 21.4 10.9  9.4  6.1\n\n\n\nmean(data_extreme)  ## Large mean! Original mean is 11.56\n\n[1] 13.14\n\nmedian(data_extreme)  ## Median does not change!\n\n[1] 9.9\n\nnames(sort(table(data_extreme), decreasing = TRUE))[1] ## Mode does not change either!\n\n[1] \"9.9\"\n\n\n\nBelow is a figure that shows the differences in where the mean, median, and mode lie for skewed distributions vs.Â symmetric distributions.\n\n\n\n\n\nFigureÂ 5.2: Comparison of mean, median, and mode for symmetrical vs.Â skewed distributions"
  },
  {
    "objectID": "data-numerics.html#measures-of-variation",
    "href": "data-numerics.html#measures-of-variation",
    "title": "5Â  Data Sample Statistics",
    "section": "\n5.3 Measures of Variation",
    "text": "5.3 Measures of Variation\n\nMeasures of variation, just like measures of center, affect the shape of the distribution (FigureÂ 5.3).\n\n\n\n\n\nFigureÂ 5.3: Effects of variation on the shape of distributions\n\n\n\n\n\n p-th percentile \n\n\n\nThe p-th percentile (quantile) is a data value such that\n\nat most \\(p\\%\\) of the values are below it\nat most \\((1-p)\\%\\) of the values are above it\n\n\n\n\n\n\n\n\n\nThere are two data sets with the same mean 20.\n\n\n\n\nOne data set has 99-th percentile = 30, and 1-st percentile = 10.\nThe other has 99-th percentile = 40, and 1-st percentile = 0.\nWhich data set has larger variation?\n\n\n\n\n\n\n\n\nFigureÂ 5.4: Percentiles for ACT scores (https://en.wikipedia.org/wiki/ACT_(test))\n\n\n\n\n\n\n\n Interquartile Range (IQR) \n\n\nFirst Quartile (Q1): the 25-th percentile\n\nSecond Quartile (Q2): the 50-th percentile (Median)\n\nThird Quartile (Q3): the 75-th percentile\n\nInterquartile Range (IQR): Q3 - Q1\n\n\n\n\n## Use quantile() to find any percentile \n## through specifying the probability\nquantile(x = int_rate, \n         probs = c(0.25, 0.5, 0.75))\n\n   25%    50%    75% \n 8.000  9.900 13.725 \n\n## IQR by definition\nquantile(x = int_rate, probs = 0.75) - \n  quantile(x = int_rate, probs = 0.25) \n\n  75% \n5.725 \n\n\n\n\n\n\n## IQR()\nIQR(int_rate)  \n\n[1] 5.725\n\n## summary() to get the numeric summary\nsummary(int_rate)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.30    8.00    9.90   11.56   13.72   26.30 \n\n\n\n\n\n\n\n\n\n\nDoes a larger IQR means more or less variation?\n\n\n\n\n\n\n\n Variance and Standard Deviation \n\nThe distance of an observation from its mean, \\(x_i - \\overline{x}\\), is its deviation.\n\nSample Variance is defined as \\[ s^2 = \\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n-1} \\]\n\n\nSample Standard Deviation (SD) is defined as the square root of the variance. \\[ s = \\sqrt{\\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n-1}} \\]\n\nThe corresponding population variance and SD are denoted as \\(\\sigma^2\\) and \\(\\sigma\\) respectively.\nThe variance is the average of squared deviation from the sample mean \\(\\overline{x}\\) or the mean squared deviation from the mean.\nThe standard deviation is the root mean squared deviation from the mean.\n\nIt measures, on average, how far the data spread out around the average.\n\n\n\n Compute Variance and SD in R \n\nvar(int_rate)\n\n[1] 25.54942\n\nsqrt(var(int_rate))\n\n[1] 5.054644\n\nsd(int_rate)\n\n[1] 5.054644"
  },
  {
    "objectID": "data-numerics.html#visualizing-data-variation",
    "href": "data-numerics.html#visualizing-data-variation",
    "title": "5Â  Data Sample Statistics",
    "section": "\n5.4 Visualizing Data Variation",
    "text": "5.4 Visualizing Data Variation\n Boxplot \n\nWhen plotting the whiskers for a boxplot,\n\nthe minimum is the minimal value that is not a potential outlier.\nthe maximum is the maximal value that is not a potential outlier.\n\n\n\n\n\n\n\nFigureÂ 5.5: Example of a boxplot (https://www.leansigmacorporation.com/box-plot-with-minitab/)\n\n\n\n\n Interest Rate Boxplot \n\nBelow is the boxplot for the interest rate data (FigureÂ 5.6).\n\n\n\n\n\nFigureÂ 5.6: Boxplot for interest rate example\n\n\n\n\n Boxplot in R \n\n\n\nboxplot(int_rate,ylab =\"Interest Rate (%)\")\n\n\n\n\n\n\n\n\nsort(int_rate, decreasing = TRUE)[1:5]\n\n[1] 26.3 24.9 21.4 20.0 19.4\n\nsort(int_rate)[1:5]\n\n[1] 5.3 5.3 5.3 6.1 6.1\n\nQ3 <- quantile(int_rate, probs = 0.75, \n               names = FALSE)\nQ1 <- quantile(int_rate, probs = 0.25, \n               names = FALSE)\nIQR <- Q3 - Q1\nQ1 - 1.5 * IQR\n\n[1] -0.5875\n\nQ3 + 1.5 * IQR\n\n[1] 22.3125"
  },
  {
    "objectID": "data-numerics.html#exercises",
    "href": "data-numerics.html#exercises",
    "title": "5Â  Data Sample Statistics",
    "section": "\n5.5 Exercises",
    "text": "5.5 Exercises\n\nIn the following, we will be using the data set mtcars to do some data summary and graphics. First load the data set into your R session by the command data(mtcars). The data set is like\n\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nPlease see ?mtcars for the description of the data set.\n\nUse the function boxplot() to generate a boxplot of 1/4 mile time (qsec). Are there any outliers?\nCompute the mean, median and standard deviation of displacement (disp).\n\n\n\nMean and standard deviation (SD): For each part, compare data (1) and (2) based on their mean and SDs. You donâ€™t need to calculate these statistics, but compare (1) and (2) by stating which one has a larger mean/SD or they have the same mean/SD. Explain your reasoning.\n\n\n-30, 0, 0, 0, 15, 25, 25\n-50, 0, 0, 0, 15, 20, 25\n\n\n\n0, 1, 3, 5, 7\n21, 23, 25, 27, 29\n\n\n\n100, 200, 300, 400, 500\n0, 50, 350, 500, 600\n\n\n\n\nSkewness: Facebook data indicate that \\(50\\%\\) of Facebook users have 130 or more friends, and that the average friend count of users is 115. What do these findings suggest about the shape (right-skewed, left-skewed, symmetric) of the distribution of number of friends of Facebook users? Please explain."
  },
  {
    "objectID": "prob-define.html#language-of-uncertainty",
    "href": "prob-define.html#language-of-uncertainty",
    "title": "6Â  Definition of Probability",
    "section": "\n6.1 Language of Uncertainty",
    "text": "6.1 Language of Uncertainty\n Why Study Probability \nIt goes without saying that we live in a world full of chances and uncertainty. People do care about chances and usually make decisions given the information about some uncertain situations. FigureÂ 6.1 shows the Google search result of â€œwhat are chancesâ€ on my personal computer on September 19, 2022. It looks like people are curious about getting pregnant, getting COVID of course at that time, and getting struck by lightning or tornado. And of course, it is the chance or uncertainty that makes so many games so fun, amusing and even additive, for example, the board game monopoly, and the gambling machines like slots and blackjacks.\n\n\n\n\nFigureÂ 6.1: Google search result of â€œwhat are chancesâ€.\n\n\n\n\n\n\n\n\n\n\nFigureÂ 6.2: Monopoly baord game\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 6.3: Slots\n\n\n\n\n\n\n\n\nFigureÂ 6.4: Blackjacks\n\n\n\n\n\n\nApparently most people want to quantify uncertainty about something happening, or measure the chances of some event happening for better decision making. The question is, how? We need a consistent way of measuring chances and uncertainty so that our society can be operated in order. Thanks to great enthusiasm for gambling, the mathematical study of chances starts quite early, and nowadays, the most formal and rigorous way of studying chances is to use probability. Therefore, we could probably view probability as the language of uncertainty.\nMost of the time, we cannot do statistical inference or prediction using machine learning without probability because we usually assume our data at hand are random realizations from some targeted population that are described by a probability distribution. In other words, we are doing data analysis in the world of uncertainty. For example, we are interested in the mean height of Marquette female students, which is usually assumed to be bell-shaped distributed. By chances, our collected sample of girls may all have heights below 5â€™4â€, which is not representative of the target population, and the sample mean is far from the true population mean height being interested. Examining the chance of getting such biased data set becomes important and helps us quantify the plausibility of the numerical results we obtain from the data.\nAs a result, before jumping into statistical inference or data analysis, we need to have basic understanding of probability definitions, rules, and operations that are frequently used in the data science community.\n\n Why Probability Before Statistics? \nAlthough probability and statistics are closely related and usually taught in one single introductory course, they are two distinct subjects. Since the randomness of sampling from the target population, statistical inference and data analysis usually involve uncertainty quantification, and hence probability is used in the analysis.\nIn a typical statistical analysis, we assume the target population, for example the Marquette studentsâ€™ height follows some probability distribution, and the collected sample data are the realized data points from the distribution. With this, the population probability distribution is a mechanism that generates data. In probability theory, we examine how this mechanism generates data, and how the observed data will behave given the fact that they are from the probabilistic data generating process. For example, we assume the height follows some probability distribution, and we are curious about the probability that the sample mean is larger than 5â€™10â€, or that the sample mean is between 5â€™6â€ and 5â€™11â€.\nIn the probability theory, the process generating the data is assumed known and we are interested in properties of observations. However, in reality, the data generating process, or the target population distribution, is unknown to us, and is what we would like to infer to using the sample data we collect. For example, we want to estimate the unknown mean height of Marquette students using the data of 100 Marquette students sampled at random from the unknown target population distribution. This is what statistical inference is all about. For statistics, we observe the data (sample) and are interested in determining what process generates such data (population). These principles are illustrated below in FigureÂ 6.5.\n\n\n\n\nFigureÂ 6.5: Relationship between probability and statistical inference\n\n\n\n\nEven though the data generating process is fixed and unchanged every time a data set is collected, the data replicates are all different due to the random sampling from the population probability distribution. Such randomness creates the uncertainty about how we do the inference about the population properties because a different data set represents only a part of, and probably biased, information about the the whole distribution. As a result, when doing inference, we prefer probabilistic statements to deterministic statements."
  },
  {
    "objectID": "prob-define.html#interpretation-of-probability",
    "href": "prob-define.html#interpretation-of-probability",
    "title": "6Â  Definition of Probability",
    "section": "\n6.2 Interpretation of Probability",
    "text": "6.2 Interpretation of Probability\n Relative Frequency \nThere are several ways of interpreting probability. The first interpretation is relative frequency. Formally speaking, the probability that some outcome of a process will be obtained is interpreted as the relative frequency with which that outcome would be obtained if the process were repeated a large number of times independently under similar conditions.\nThink about the following scenario. Your mom gave you a unfair coin, but she does not know the probability of getting heads when one tosses the coin. How do you obtain, or at least approximate the probability? Well, we can use the concept of relative frequency. First, we decide how many times we want to flip the coin. Each time after flipping the coin, we record either heads or tails shows up. Once we are done all the flips, we count the frequency or the total number of times heads shows up among all the flips. To obtain the probability of getting heads, we calculate the relative frequency, the ratio of the frequency of heads to the number of tosses.\nBelow is an example depicting the relative frequency of flipping a coin and getting heads or tails.\n\n\n\n\n      Frequency Relative Frequency\nHeads         4                0.4\nTails         6                0.6\nTotal        10                1.0\n---------------------\n      Frequency Relative Frequency\nHeads       514              0.514\nTails       486              0.486\nTotal      1000              1.000\n---------------------\n\n\n\n\nWhen we flip the coin 10 times, 4 of them end up being heads, and the probability of getting heads is 40%. You may be skeptical of the result, and want to have more replicates. Some day you have lots of spare time, and you decide to flip the coin 1000 times. The relative frequency, or the probability of getting heads, now becomes 51.4%.\n\n\n\n\n\n\nDo you see any issues with relative frequency probability?\n\n\n\n\n\n\nApparently, we donâ€™t know the true probability if it does exist. And as you learned in the coin-flipping example, we donâ€™t have one unique answer for that if we use relative frequency as the way of interpreting probability. In fact, there are some issues when we treat relative frequency as probability.\n Issues with Relative Frequency \n\nðŸ˜• How large of a number is large enough?\n\nThere is no correct answer for how many replicates of the experiment we should have. We may think 10 times is not enough, but how about 1000 times? one million times? How well the relative frequency approximates the true probability depends on the complexity of the experiments. In general, the larger the number of times of repeating the process, the better the approximation of the relative frequency. This is the result of the so-called law of large numbers that is discussed in ChapterÂ 12.\n\nðŸ˜• What is the meaning of â€œunder similar conditionsâ€?\n\nIn the definition, the experiment or process needs to be repeated â€œunder similar conditionsâ€. What does that mean? The definition itself is not rigorous enough. Do we need to control the airflow when the experiment is conducted? How about temperature? Can your mom and you take turns to flip the coin? Be honest, there is no answer for that.\n\nðŸ˜• Is the relative frequency reliable under identical conditions?\n\nCan we trust the relative frequency when the experiment is conducted under identical conditions? If there is a skilled person who can control whether heads or tails shows up every time he flips a coin, should we believe the relative frequency is a good approximation to the true probability?\n\nðŸ‘‰ We can only obtain an approximation instead of exact value for the probability.\n\nYou may already find out that the relative frequency is only an approximation instead of exact value for the probability. If we want to get the true probability (if it does exist), we need to get the relative frequency whose process is repeated infinitely many of times, which is unrealistic. Such probability stems from the frequentist philosophy that interprets probability as the long-run relative frequency of a repeatable experiment.\n\nðŸ˜‚ How do you compute the probability that Chicago Cubs win the World Series next year?\n\nIn the real world and our daily lives, lots of times we want to compute the probability of something happening where the something cannot be a repeatable process or experiment. For example, it is impossible to compute the probability that Chicago Cubs win the World Series next year because we would never to able to obtain the relative frequency of Chicago Cubs winning the World Series next year.\n\n\n\n\nSource: https://media.giphy.com/media/EKURBxKKkw0uY/giphy.gif\n\n\n\n\n\n Classical Approach \nAnother interpretation of probability follows the classical approach, whose probability is based on the concept of equally likely outcomes. If the outcome of some process must be one of \\(n\\) different outcomes, the probability of each outcome is simply \\(1/n\\). For example, if you toss a fair coin (2 outcomes) ðŸª™, the probability of getting heads is 1/2. If you roll a well-balanced die (6 outcomes) ðŸŽ², the probability of each outcome being shown is 1/6. If you draw one from a deck of cards (52 outcomes) ðŸƒ, the probability of each card being drawn is 1/52.\n\n\n\n\n\n\nDo you see any issues with classical probability?\n\n\n\n\n\n\nIt wouldnâ€™t make sense to say that the probability that [you name it] wins the World Series next year is 1/30. Even though there are 30 teams in the MLB, each team is not equally likely to win the World Series. Donâ€™t you agree?!\n\n Subjective Approach \nThe last interpretation of probability we discuss here is the subjective approach, whose probability is assigned or estimated using peopleâ€™s knowledge, beliefs and information about the data generating process. In this case, it is a personâ€™s subjective probability of an outcome, rather than the true probability of that outcome. For example, I think â€œthe probability that the Milwaukee Brewers win the World Series this year is 30%â€. My probability that the Milwaukee Brewers win the World Series this year is likely to be different from an ESPN analystâ€™s probability.\n\n\n\n\n\n\nSource: https://www.nj.com/yankees/2020/02/mlb-rumors-espns-sunday-night-baseball-will-feature-a-lot-of-ex-yankee-alex-rodriguez-and-not-much-else.html\n\n\n\n\n\n\n\n\n\nSource: Wiki: ESPN Major League Baseball\n\n\n\n\n\n\nHere, a probability measures the relative plausibility of some event or outcome, and such probability stems from the so-called Bayesian philosophy. With this, we can claim that candidate A has a 0.9 probability of winning because the probability represents our plausibility or belief about the winning chance of the candidate A. A Bayesian statistician would say based on analysis the candidate A is 9 times more likely to win than to lose. For a statistician with the frequentist philosophy, he might say the statement is wrong or there is no such claim. Or he might weirdly say in long-run hypothetical repetitions of the election, candidate A would win roughly 90% of the time.\n\n\n\n\n\n\n\nNote\n\n\n\nProbability operations and rules do NOT depend on the interpretation of probability!"
  },
  {
    "objectID": "prob-rule.html#probability-operations-and-rules",
    "href": "prob-rule.html#probability-operations-and-rules",
    "title": "7Â  Probability Rules",
    "section": "\n7.1 Probability Operations and Rules",
    "text": "7.1 Probability Operations and Rules\n Experiments, Events and Sample Space \nProbability starts with the concept of sets. When we calculate the probability of â€œsomethingâ€, that something is represented as a set, which is a collection of some outcomes generated by an process or experiment associated to the something we are interested. To denote a set, we usually use a pair of curly braces { }, and the elements of the set is put inside the braces, each separated by a comma, for example, {red, green, yellow} is a set with three color elements.\nHere we define some terminology that are commonly used in set and probability concepts.\n\nAn experiment is any process in which the possible outcomes can be identified ahead of time.\n\nThe key words is ahead of time. For example, we know what is the result of flipping a coin, which is heads or tails showing up, before we actually do it. Therefore, flipping a coin is an experiment. Similarly, before we roll a six-sided die, we already know the possible outcome of doing that, which is 1, 2, 3, 4, 5, 6, so rolling a die is also an experiment.\n\nAn event is a set of possible outcomes of the experiment.\n\nGenerally there are two or more potential outcomes for some experiment. Any collection of those outcomes is called an event. For example, there are 6 possible outcomes for rolling a die, 1, 2, 3, 4, 5, 6. Then any collection of those 6 numbers is an event. So â€œAn odd number showing upâ€ which corresponds to the collection {1, 3, 5} is an event. â€œAn even number showing upâ€ that is represented by {2, 4, 6} is also an event.\n\nThe sample space \\((\\mathcal{S})\\) of an experiment is the collection of ALL possible outcomes of the experiment.\n\nBased on the definition, the sample space the largest set associated with an experiment because it collects all possible outcomes. In other words, when an experiment is conducted, no matter what outcome shows up, it is always in the sample space.\n\n\n\n\n\n\nIs the sample space also an event?\n\n\n\n\nYes, the sample space itself is an event because it is also a set of possible outcomes of the experiment.\n\n\n\nThe table below provides a summary of experiments flipping a coin and rolling a die.\n\n\n\n\n\n\n\n\nExperiment\nPossible Outcomes\nSome Events\nSample Space\n\n\n\nFlip a coin ðŸª™\nHeads, Tails\n{Heads}, {Heads, Tails}, â€¦\n{Heads, Tails}\n\n\nRoll a die ðŸŽ²\n1, 2, 3, 4, 5, 6\n{1, 3, 5}, {2, 4, 6}, {2}, {3, 4, 5, 6}, â€¦\n{1, 2, 3, 4, 5, 6}\n\n\n\n\n Set Concept: Example of Rolling a six-side balanced die\n\n\n\n\n\n\nTip\n\n\n\nDraw a Venn Diagram every time you get stuck! Venn diagram is a very useful tool for identifying a set, so I encourage you to draw a venn diagram when you get stuck on complicated set operations.\n\n\n\n\n The complement  of an event (set) \\(A\\), is denoted  \\(A^c\\) . It is the set of all outcomes (elements) of \\(\\mathcal{S}\\) in which \\(A\\) does not occur. For the die example, let \\(A\\) be an event that a number greater than 2 is rolled. Then \\(A = \\{3, 4, 5, 6\\}\\) and \\(A^c = \\{1, 2\\}\\).\n\n\n\n\n\n\n\n\n\n\n\nThe  union \\((A \\cup B)\\)  is the set of all outcomes of \\(\\mathcal{S}\\) in \\(A\\) or \\(B\\).  For the die example, let \\(B\\) be an event that an even number is rolled. Then \\(B = \\{2, 4, 6\\}\\) and \\(A \\cup B = \\{2, 3, 4, 5, 6\\}\\).  Basically, as long as an element is in either \\(A\\) or \\(B\\), not necessarily in both \\(A\\) and \\(B\\), the element is collected in the set \\((A \\cup B)\\).\n\n\n\n\n\n\n\n\n\n\nThe  intersection \\((A \\cap B)\\)  is the set of all outcomes of \\(\\mathcal{S}\\) in both \\(A\\) and \\(B\\).  For the die example, \\(A \\cap B = \\{4, 6\\}\\). Basically, for any element in the set \\((A \\cap B)\\), it must be an element of \\(A\\) and of \\(B\\).\n\n\n\n\n\n\n\n\n\n\n\n\\(A\\) and \\(B\\) are disjoint or mutually exclusive if they have no outcomes in common \\((A \\cap B = \\emptyset)\\). \\(\\emptyset\\) means an empty set, \\(\\{\\}\\), i.e., no elements in the set. If the two events are disjoint, it means that they cannot occur at the same time for one single trial of the experiment.  For the die example, let \\(C\\) be an event that an odd number is obtained. Then \\(C = \\{1, 3, 5\\}\\) and \\(B \\cap C = \\emptyset\\).  When we roll a die one time, we cannot get a number that is odd and even at the same time.\n\n\n\n\n\n\n\n\n\n\nThe containment \\((A \\subset B)\\) means every elements of \\(A\\) also belongs to \\(B\\). In other words, if \\(A\\) occurs, then so does \\(B\\).  For the die example, let \\(B\\) be the event that an even number is obtained and \\(D\\) be the event that a number greater than 1 is obtained. Then \\(B = \\{2, 4, 6\\}\\) and \\(D = \\{2, 3, 4, 5, 6\\}\\).  In this case, every even number is greater than one, therefore \\(B\\) is a subset of \\(D\\), i.e., \\(B \\subset D\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind that every event (set) being considered is a subset of the sample space \\((\\mathcal{S})\\) because it only makes sense to discuss the events that are possibly to be occurred. As a result, for any event \\(A\\), \\(A \\subset \\mathcal{S}\\).\n\n\n\n Probability Rules \nWe have learned how to represent an event in terms of sets and set operations. Here we are going to learn several probability rules for events.\nFirst, we denote the probability of an event \\(A\\) on a sample space \\(\\mathcal{S}\\) as \\(P(A)\\).\n\n\n\n\n\n\nTip\n\n\n\nTreat the probability of an event as the area of the event in the Venn diagram.\n\n\nIn order to have a coherent and logically consistent set of probability rules, we need some axioms that are self-evident to anyone. The three axioms are as follows.\n\n\\(P(\\mathcal{S}) = 1\\)\nFor any event \\(A\\), \\(P(A) \\ge 0\\)\n\nIf \\(A\\) and \\(B\\) are disjoint or mutually exclusive, \\(P(A \\cup B) = P(A) + P(B)\\)\n\n\nIf we treat the sample space as an event, the probability of the entire sample space is always equal to one because this event must happen every time the experiment is conducted. In the Venn diagram, the sample space is the entire rectangle, and in probability, we presume the area of the rectangle is one.\nBecause any event is a collection of some outcomes that could possibly occur or not occur, its probability is greater than or equal to zero. Any probability cannot be negative. It is clearly shown in terms of Venn diagram because an area of any shape of an object is greater than or equal to zero.\nFinally, if the two events are disjoint, the probability of the union of the two is just the sum of their own probability. For example, if the probability of getting a green M&M is 20% and that of getting a blue M&M is 15%, then the probability of getting a green or blue M&M is 20% + 15% = 35%. It is clearly shown in the Venn diagram too because the total area of the two disjoint events in the sample space is the sum of the individual area.\nWith the three axioms, the entire probability operation system can be constructed. Some basic properties are listed here.\n\n\n\\(P(\\emptyset) = 0\\).\n\\(0 \\le P(A) \\le 1\\)\n\nAddition Rule: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\\(P(A^c) = 1 - P(A)\\)\nIf \\(A \\subset B\\), then \\(P(A) \\le P(B)\\)\n\n\nThe empty set does not contain any possible outcomes of an experiment. Because some outcome must be occurred after an experiment is conducted, it is impossible for some event to happen without any outcome involved. Therefore, the probability of the empty set is zero. In terms of Venn diagram, an empty set is a set with area zero because it does not occupy any part (outcome) of the entire sample space.\nSince every event being considered must be a subset of the sample space, the area of any event is smaller than the area of the sample space which is one. Therefore, for any event \\(A\\), \\(P(A) \\le 1\\). \\(P(A) = 1\\) if and only if \\(A = \\mathcal{S}\\).\n\n\nThe addition rule can be clearly understood using the Venn diagram. FigureÂ 7.1 shows how \\(P(A \\cup B)\\) is expressed by \\(P(A)\\), \\(P(B)\\) and \\(P(A \\cap B)\\). To get the area of \\(A \\cup B\\), we can first consider the sum of the area of \\(A\\) and \\(B\\), the left and right circles. However, the middle part which is \\(A \\cap B\\) is counted twice when we take the sum, so the one piece of area of \\(A \\cap B\\) should be removed from the sum of the area.\n\n\n\n\nFigureÂ 7.1: Venn Diagram depiction of the addition rule\n\n\n\n\nIn fact, the third axiom is a special case of the addition rule. FigureÂ 7.2 illustrates the case. Since the two events are disjoint, \\(A \\cap B = \\emptyset\\), and the area of \\(A \\cap B\\), or \\(P(A \\cap B)\\) is zero.\n\n\n\n\n\nFigureÂ 7.2: Venn Diagram depiction of the addition rule for the disjoint case\n\n\n\n\nSince \\(A \\cup A^c = \\mathcal{S}\\) and \\(A \\cap A^c = \\emptyset\\), we have \\[P(A \\cup A^c) = P(\\mathcal{S}) = P(A) + P(A^c)\\] Therefore, \\(P(A) + P(A^c) = 1\\) and \\(P(A^c) = 1 - P(A)\\).\nIf \\(A \\subset B\\), the area of \\(A\\) is smaller or equal to the area of \\(B\\). Therefore, \\(P(A) \\le P(B)\\).\n Example: M&M Colors\n\nThe makers of the M&Ms report that their plain M&Ms are composed of\n\n15% Yellow, 10% Red, 20% Orange, 25% Blue, 15% Green and 15% Brown\n\n\n\n\n\n\n\n\n\nSource: Unsplash: Robert Anasch\n\n\n\n\n\n\n\n\n\n\n\nIf you randomly select an M&M, what is the probability of the following?\n\n\n\n\nIt is brown.\nIt is red or green.\nIt is not blue.\nIt is red and brown.\n\n\n\n\n\n\n\nSolution\n\n\\(P(\\mathrm{Brown}) = 0.15\\)\n\\(\\begin{align} P(\\mathrm{Red} \\cup \\mathrm{Green}) &= P(\\mathrm{Red}) + P(\\mathrm{Green}) - P(\\mathrm{Red} \\cap \\mathrm{Green}) \\\\ &= 0.10 + 0.15 - 0 = 0.25 \\end{align}\\)\n\\(P(\\text{Not Blue}) = 1 - P(\\text{Blue}) = 1 - 0.25 = 0.75\\)\n\\(P(\\text{Red and Brown}) = P(\\emptyset) = 0\\)\n\n\n\n\n\n\n\n\n\nWhich interpretation of probability is used in this question?"
  },
  {
    "objectID": "prob-rule.html#conditional-probability-and-independence",
    "href": "prob-rule.html#conditional-probability-and-independence",
    "title": "7Â  Probability Rules",
    "section": "\n7.2 Conditional Probability and Independence",
    "text": "7.2 Conditional Probability and Independence\n Conditional Probability \nQuite often people are interested in the probability of something happening given the fact that some other event has been occurred or some information about the experiment or its outcomes have been known. In this case, we can calculate the conditional probability that takes the occurred event or known information into account. The conditional probability would be more appropriate for quantifying uncertainty about what we are interested because knowing some event being occurred is a piece of valuable information that helps us properly adjust the chance of something happening.\nBy definition, the conditional probability of \\(A\\) given \\(B\\) is \\[ P(A \\mid  B) = \\frac{P(A \\cap B)}{P(B)}.\\]\nThe vertical bar â€œ\\(\\mid\\)â€ is read as given or conditional on. Therefore, we consider the event \\(A\\) not in the entire sample space, but the event \\(A\\) that is conditional on the event \\(B\\), or \\(A \\mid B\\). In other words, we donâ€™t consider all possible parts of \\(A\\). Instead, we only care about the part of \\(A\\) for which \\(B\\) has already occurred.\nThe formula is well defined when \\(P(B) > 0\\) and undefined if \\(P(B) = 0\\). Intuitively, one cannot calculate the probability of \\(A\\) given \\(B\\) when \\(B\\) is not occurred by any chance. FigureÂ 7.3 illustrates the conditional probability of \\(A\\) given \\(B\\) using the Venn diagram. When we compute the probability of \\(A\\), the information about \\(B\\) have been given, and the probability of \\(A\\) is adjusted, according to this information. The conditional probability is the ratio of \\(P(A \\cap B)\\) to \\(P(B)\\).\n\n\n\n\n\n\n\n\n\n\nFigureÂ 7.3: Venn Diagram illustration of the conditional probability of A given B\n\n\n\n\nSo what is the difference between \\(P(A)\\) and \\(P(A \\mid B)\\)? How knowing event \\(B\\) occurred affects the probability of \\(A\\)? Well, FigureÂ 7.4 describes the difference. When we calculate \\(P(A)\\), we assume we donâ€™t have any specific information at hand. What we can base on is the entire sample space because we need to take all possible outcomes into account, and see if any outcome is related to the event \\(A\\). Therefore, although we just write \\(P(A)\\), the probability is actually calculated conditional on the entire sample space, i.e., \\(P(A \\mid \\mathcal{S})\\), which is the ratio of area of \\(A\\) to the area of \\(\\mathcal{S}\\) that is one. Such probability is usually called unconditional or marginal probability because being conditional on \\(\\mathcal{S}\\) is like being not conditional on some specific event, and â€œmarginalâ€ means all other possible events or outcomes have been â€œmarginalizedâ€ out, and only event \\(A\\) is of our interest.\nNow if we know \\(B\\) has occurred, we donâ€™t need to consider the entire sample space any more. Instead, we can focus only on \\(B\\) since we know \\(B\\) has occurred, and anything not related to \\(B\\), or \\(B^c\\) becomes irrelevant. We shrink the search pool from \\(\\mathcal{S}\\) to the smaller space \\(B\\). To find \\(P(A \\mid B)\\), we just need to find how large part of \\(B\\) that also belongs to \\(A\\). Intuitively speaking, the event \\(B\\) has become our new sample space that are smaller than the original \\(\\mathcal{S}\\). We calculate the probability of \\(A\\) based on \\(B\\), not \\(\\mathcal{S}\\). Since \\(B\\) is the new sample space, we can treat \\(P(B)\\) as one. In other words, any probability conditional on \\(B\\) is scaled up by \\(1 / P(B)\\) so that \\(P(B) \\times \\frac{1}{P(B)} = 1\\). This is why \\(P(A \\cap B)\\) is multiplied by \\(1 / P(B)\\) in the conditional probability formula.\nHere is an example of new sample space or search pool. Suppose we would like to calculate the probability of a woman who is greater than 20 years old in a certain area. When we donâ€™t have any background information about the woman, to compute the probability, we need to base on the entire female population of interest. But if we do know that the woman has two children, we shrink our focus on the pool of women who have two children, and compute the proportion of the women pool that is over 20 years of age.\n\n\n\n\n\n\n\n\nFigureÂ 7.4: Difference Between \\(P(A)\\) and \\(P(A \\mid B)\\)\n\n\n\n\nThe conditional probability formula lead to the multiplication rule: \\[P(A \\cap B) = P(A \\mid  B)P(B) = P(B \\mid  A)P(A)\\] The rule is a rearranged form of the formula by multiplying both sides by \\(P(B)\\). Notice that \\(P(B \\mid A) = \\frac{P(B \\cap A)}{P(A)}\\) and hence \\(P(B \\mid A)P(A) = P(B \\cap A) = P(A \\cap B)\\).\n Example: Peanut Butter and Jelly\n\nSuppose 80% of people like peanut butter, 89% like jelly and 78% like both. Given that a randomly sampled person likes peanut butter, what is the probability that she also likes jelly?\n\n\n\n\n\n\n\n\n\n\n\n\nWe want \\(P(J\\mid PB) = \\frac{P(PB \\cap J)}{P(PB)}\\).\nFrom the problem we have \\(P(PB) = 0.8\\), \\(P(J) = 0.89\\) and \\(P(PB \\cap J) = 0.78\\)\n\n\\(P(J\\mid PB) = \\frac{P(PB \\cap J)}{P(PB)} = \\frac{0.78}{0.8} = 0.975\\)\nIf we donâ€™t know if the person loves peanut butter, the probability that he or she loves jelly is 89%.\nIf we do know she loves peanut butter, the probability that he or she loves jelly is going up to 97.5%.\n\n\n\n\n Independence \nIn the previous example, we learn that whether a person loves peanut butter affects the probability that she loves jelly. This piece of information is relevant, and the two events â€œlove peanut butterâ€ and â€œlove jellyâ€ are dependent each other because the one event will affect the chance of the other event happening. Uncovering the association or dependence is important for statistical inference because it helps statisticians better pin down the probability of being interest.\nFormally speaking, event \\(A\\) and \\(B\\) are independent if \\(\\begin{align} P(A \\mid B) &= P(A) \\text{ or }\\\\ P(B \\mid A) &= P(B) \\text{ or } \\\\P(A\\cap B) &= P(A)P(B)\\end{align}\\) \\(\\text{ for } P(A) > 0 \\text{ and } P(B) > 0.\\)\nIntuitively, this means that knowing \\(B\\) occurs does not change the probability that \\(A\\) occurs and vice versa. The information about \\(B\\) is irrelevant to probability of \\(A\\).\nHere is a question. Can we compute \\(P(A \\cap B)\\) if we only know \\(P(A)\\) and \\(P(B)\\) with no information other than sample space? The answer is no. We cannot compute \\(P(A \\cap B)\\) because we donâ€™t know if \\(A\\) and \\(B\\) are independent. We can only do so if \\(A\\) and \\(B\\) are independent. In general, we need to consider the dependence of two events and use the multiplication rule \\(P(A \\cap B) = P(A \\mid B)P(B)\\).\nFigureÂ 7.5 explain independence using the Venn diagram. Independence means that the ratio of area of \\(A\\) to area of \\(\\mathcal{S}\\) is the same as the ratio of area of \\(A \\cap B\\) to area of \\(B\\). Look at the case of non-independence on the right, the two events (circles) in particular. The area of \\(A \\cap B\\) is very close to the area of \\(B\\) because the two events are quite overlapped each other. It means that the ratio of area of \\(A \\cap B\\) to area of \\(B\\) is pretty close to one. So if we know \\(B\\) has occurred, there will be a very high chance that \\(A\\) would happen as well. In this case, the information about \\(B\\) does matter, and affect probability of \\(A\\). The idea is that the two events describe pretty much similar set of outcomes for an experiment. As a result, when one occurs, we are pretty sure the other happens as well.\n\n\n\n\n\n\n\n\n\n\nFigureÂ 7.5: Venn Diagram Explanation of Independence\n\n\n\n\n Independence Example \n\n\n\n\n\n\nAssuming that events \\(A\\) and \\(B\\) are independent and that \\(P(A) = 0.3\\) and \\(P(B) = 0.7\\).\n\n\n\n\n\n\\(P(A \\cap B)\\)?\n\n\\(P(A \\cup B)\\)?\n\n\\(P(A \\mid B)\\)?\n\n\n\nSolution\n\n\\(P(A \\cap B) = P(A)P(B)=0.21\\)\n\\(P(A \\cup B) = P(A)+P(B)-P(A\\cap B) = 0.3+0.7-0.21=0.79\\)\n\\(P(A \\mid B) = P(A) = 0.3\\)"
  },
  {
    "objectID": "prob-rule.html#bayes-formula",
    "href": "prob-rule.html#bayes-formula",
    "title": "7Â  Probability Rules",
    "section": "\n7.3 Bayesâ€™ Formula",
    "text": "7.3 Bayesâ€™ Formula\nBayesâ€™ formula is one of the most important theorems in the probability and statistical theory. It is the basis of Bayesian inference and Bayesian machine learning discussed in ChapterÂ 21, which is getting more and more popular these days due to fast computation technology. In this section, we learn why we need the Bayesâ€™s formula, and how we can use it to obtain the probability we are interested.\n Why Bayesâ€™ Formula? \nQuite often, we know \\(P(B \\mid A)\\), but we are much more interested in \\(P(A \\mid B)\\). Letâ€™s take COVID diagnostic test as an example. Suppose you are having a sore throat and muscle and headache, and you decide to test if you got COVID. Of course, any test may not be 100% accurate. A person who does get COVID may be tested negative, which is called false negative, and a person who doesnâ€™t get COVID may get a positive testing result, false positive in this case. With lots of trials, we can have false negative rate \\(P(\\text{test negative} \\mid \\text{COVID})\\) and false positive rate \\(P(\\text{test positive} \\mid \\text{not COVID})\\) of some COVID test.\nLet me ask you a question. Suppose that during a doctorâ€™s visit, you tested positive for COVID. If you only get to ask the doctor one question, which would it be?\n\nWhatâ€™s the chance that I actually have COVID?\nIf in fact I donâ€™t have COVID, whatâ€™s the chance that I wouldâ€™ve gotten this positive test result?\n\nIf I were you, I would choose a. because I care more about whether I got COVID or not, not the efficacy of the test! In fact, diagnostic tests provide \\(P(\\text{test positive} \\mid \\text{COVID})\\) and \\(P(\\text{test positive} \\mid \\text{not COVID})\\), but what we are really interested is \\(P(\\text{COVID} \\mid \\text{test positive})\\)!\nSo, how can we utilize the diagnostic test efficacy to get the chance that one actually gets COVID? Bayesâ€™ formula is the answer. It provides a way to find \\(P(A \\mid B)\\) from \\(P(B \\mid A)\\).\n\n\n\n\n\n\nSource: Unsplash Martin Sanchez\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Formula \nThe Bayesâ€™ formula comes from the conditional probability. If \\(A\\) and \\(B\\) are events whose probability is not zero or one, then the Bayesâ€™ formula is derived as below. \\[\\begin{align*} P(A \\mid B) &= \\frac{P(A \\cap B)}{P(B)} \\quad ( \\text{def. of cond. prob.}) \\\\ &= \\frac{P(A \\cap B)}{P((B \\cap A) \\cup (B \\cap A^c))} \\quad ( \\text{partition } B) \\\\ &= \\frac{P(B \\mid A)P(A)}{P(B \\mid A)P(A) + P(B \\mid A^c)P(A^c)}  \\quad ( \\text{multiplication rule}) \\end{align*}\\]\n\n\n\n\n\nFigureÂ 7.6: Venn Diagram illustration for Bayesâ€™ formula\n\n\n\n\nThe first equality is just the definition of conditional probability. For the second equality, we partition \\(B\\) into \\((B \\cap A)\\) and \\((B \\cap A^c)\\) as \\((B \\cap A) \\cup (B \\cap A^c) = B\\) and \\((B \\cap A)\\) and \\((B \\cap A^c)\\) are disjoint, as illustrated in FigureÂ 7.6. 1 Since \\((B \\cap A)\\) and \\((B \\cap A^c)\\) are disjoint, \\(P((B \\cap A) \\cup (B \\cap A^c)) = P(B \\cap A) + P(B \\cap A^c)\\). Finally, we can use the multiplication rule to write \\(P(B \\cap A)\\) as \\(P(B \\mid A)P(A)\\) and \\(P(B \\cap A^c)\\) as \\(P(B \\mid A^c)P(A^c)\\). The derivation of the Bayesâ€™ formula is complete.\nNotice that we use the information about \\(P(B \\mid A)\\), \\(P(B \\mid A^c)\\), \\(P(A)\\) and \\(P(A^c)\\) to obtain \\(P(A \\mid B)\\). In general, \\(P(A \\mid B) \\ne P(A \\mid B)\\), and they are completely different probabilities. Interpret your probability with additional care.\n[Extended formula]\n Example: Passing Rate \n\n\nAfter taking MATH 4720, \\(80\\%\\) of students understand the Bayesâ€™ formula.\n\nOf those who understood the Bayesâ€™ formula, \\(95\\%\\) passed.\nOf those who did not understand the Bayesâ€™ formula, only \\(60\\%\\) passed.\n\n\n\n\n\n\nSource: Unsplash JESHOOTS.COM\n\n\n\n\n\n\n\n\n\n\n\n\nCalculate the probability that a student understands the Bayesâ€™ formula given the fact that she passed.\n\n\n\n\n\n\n\n\n Step 1: Formulate what we would like to compute \n\n\\(P(\\text{understood} \\mid \\text{passed})\\)\n\n\n\n Step 2: Define relevant events in the formula: \\(A\\), \\(A^c\\) and \\(B\\) \n\nLet \\(A =\\) understood and \\(B =\\) passed. Then \\(A^c =\\) didnâ€™t understand and \\(P(\\text{understood} \\mid \\text{passed}) = P(A \\mid B)\\).\n\n\n\n Step 3: Find probabilities in the Bayesâ€™ formula using provided information. \n\n\\(P(B \\mid A) = P(\\text{passed} \\mid \\text{understood}) = 0.95\\)\n\n\\(P(B \\mid A^c) = P(\\text{passed} \\mid \\text{didn't understand}) = 0.6\\)\n\n\\(P(A) = P(\\text{understood}) = 0.8\\)\n\\(P(A^c) = 1 - P(A) = 0.2\\)\n\n\n\n Step 4: Apply Bayesâ€™ formula. \n\n\\(\\small P(\\text{understood} \\mid \\text{passed}) = P(A \\mid B) = \\frac{P(B \\mid A)P(A)}{P(B \\mid A)P(A) + P(B \\mid A^c)P(A^c)} = \\frac{(0.95)(0.8)}{(0.95)(0.8) + (0.6)(0.2)} = 0.86\\)\n\n\n\n Tree Diagram Illustration \n\n\n\\(80\\%\\) of students understand the Bayesâ€™ formula.\nOf those who understood the Bayesâ€™ formula, \\(95\\%\\) passed (\\(5\\%\\) failed).\nOf those who did not understand the formula, \\(60\\%\\) passed (\\(40\\%\\) failed).\n\n\n\n\n\n\n\nFigureÂ 7.7: Tree Diagram illustration of Passing Rate example\n\n\n\n\n\n\n\n\\[\\begin{align*} & P(\\text{yes} \\mid \\text{pass}) \\\\ &= \\frac{P(\\text{yes and }  \\text{pass})}{P(\\text{pass})} \\\\ &= \\frac{P(\\text{yes and }  \\text{pass})}{P(\\text{pass and yes}) + P(\\text{pass and no})}\\\\ &= \\frac{P(\\text{pass | yes})P(\\text{yes})}{P(\\text{pass | yes})P(\\text{yes}) + P(\\text{pass | no})P(\\text{no})} \\\\ &= \\frac{0.76}{0.76 + 0.12} = 0.86 \\end{align*}\\]"
  },
  {
    "objectID": "prob-rule.html#exercises",
    "href": "prob-rule.html#exercises",
    "title": "7Â  Probability Rules",
    "section": "\n7.4 Exercises",
    "text": "7.4 Exercises\n\nA Pew Research survey asked 2,422 randomly sampled registered voters their political affiliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 38% of respondents identified as Independent, 25% identified as swing voters, and 13% identified as both.\n\nAre being Independent and being a swing voter disjoint, i.e.Â mutually exclusive?\nWhat percent of voters are Independent but not swing voters?\nWhat percent of voters are Independent or swing voters?\nWhat percent of voters are neither Independent nor swing voters?\nIs the event that someone is a swing voter independent of the event that someone is a political Independent?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEarth is warming\nNot warming\nDonâ€™t Know/Refuse\nTotal\n\n\n\nConservative Republican\n0.11\n0.20\n0.02\n0.33\n\n\nMod/Lib Republican\n0.06\n0.06\n0.01\n0.13\n\n\nMod/Cons Democrat\n0.25\n0.07\n0.02\n0.34\n\n\nLiberal Democrat\n0.18\n0.01\n0.01\n0.20\n\n\nTotal\n0.60\n0.34\n0.06\n1.00\n\n\n\n\nA Pew Research poll asked 1,423 Americans, â€œFrom what youâ€™ve read and heard, is there solid evidence that the average temperature on earth has been getting warmer over the past few decades, or not?â€. The table above shows the distribution of responses by party and ideology, where the counts have been replaced with relative frequencies.\n\nAre believing that the earth is warming and being a liberal Democrat mutually exclusive?\nWhat is the probability that a randomly chosen respondent believes the earth is warming or is a Mod/Cons Democrat?\nWhat is the probability that a randomly chosen respondent believes the earth is warming given that he is a Mod/Cons Democrat?\nWhat is the probability that a randomly chosen respondent believes the earth is warming given that he is a Mod/Lib Republican?\nDoes it appear that whether or not a respondent believes the earth is warming is independent of their party and ideology? Explain your reasoning.\n\n\nAfter an MATH 4740/MSSC 5740 course, 73% of students could successfully construct scatter plots using R. Of those who could construct scatter plots, 84% passed, while only 62% of those students who could not construct scatter plots passed. Calculate the probability that a student is able to construct a scatter plot if it is known that she passed."
  },
  {
    "objectID": "prob-rv.html#recap",
    "href": "prob-rv.html#recap",
    "title": "8Â  Random Variables",
    "section": "\n8.1 Recap",
    "text": "8.1 Recap\n\nA variable in a data set is a characteristic that varies from one object to another.\n\nA variable can be either categorical or numerical.\nNumerical variables can be either discrete or continuous.\n\n\nA random variable, usually written as \\(X\\) 1, is a variable whose possible values are numerical outcomes determined by the chance or randomness of a procedure or experiment.\n\n \\(X\\) = # of heads after flipping a coin twice. \n \\(X\\) = # of accidents in W. Wisconsin Ave. per day.\n\n\nA random variable has a probability distribution associated with it, accounting for its randomness.\n\n[1] Usually in statistics, a capital \\(X\\) represents a random variable and a small \\(x\\) represents a realized value of \\(X\\)."
  },
  {
    "objectID": "prob-rv.html#discrete-and-continuous-random-variables",
    "href": "prob-rv.html#discrete-and-continuous-random-variables",
    "title": "8Â  Random Variables",
    "section": "\n8.2 Discrete and Continuous Random Variables",
    "text": "8.2 Discrete and Continuous Random Variables\nAs variables, since a random variable takes numerical values, it can be discrete or continuous.\nA discrete random variable takes on a finite or countable number of values.\n\nThe number of relationships youâ€™ve ever had is discrete variable because we can count the number and it is finite.\nIf we can further determine the probability that the number is 0, 1, 2 or any possible number, then it is a discrete random variable.\n\nA continuous random variable has infinitely many values, and the collection of values is uncountable.\n\nHeight is a continuous variable because it can be any number within a range.\nIf we have a way to quantify the probability that the height is from any value \\(a\\) to any value \\(b\\), it is a continuous random variable."
  },
  {
    "objectID": "prob-disc.html#introduction",
    "href": "prob-disc.html#introduction",
    "title": "9Â  Discrete Probability Distributions",
    "section": "\n9.1 Introduction",
    "text": "9.1 Introduction\n\nThe probability (mass) function of a discrete random variable (rv) \\(X\\) is a function \\(P(X = x)\\) (or \\(p(x)\\)) that assigns a probability to every possible number \\(x\\).\nThe probability distribution for a discrete r.v. \\(X\\) displays its probability function.\nThe display can be a table, graph or mathematical formula of \\(P(X = x)\\).\n\n Example:ðŸª™ðŸª™ Toss a fair coin twice independently where \\(X\\) is the number of heads. \n\nThe probability distribution of \\(X\\) as a table is\n\n\n\n\n\n\nx\n0\n1\n2\n\n\nP(X = x)\n0.25\n0.5\n0.25\n\n\n\n\n\n\n\n\n\n\n\nðŸ‘‰ \\(\\{X = x\\}\\) corresponds to an event of some experiment.\n\n\n\n\nWhat is the event that \\(\\{X = 0\\}\\) corresponds to?\nHow do we determine \\(P(X = 0)\\), \\(P(X=1)\\) and \\(P(X=2)\\) ?\n\n\n\n\n\n\n\n\nFigureÂ 9.1: Discrete probability distribution of two coin flips as a graph\n\n\n\n\n\n\n\\(0 \\le P(X = x) \\le 1\\) for every value \\(x\\) of \\(X\\).\n\n \\(x = 0, 1, 2\\) \n\n\n\n\\(\\sum_{x}P(X=x) = 1\\), where \\(x\\) assumes all possible values.\n\n \\(P(X=0) + P(X = 1) + P(X = 2) = 1\\) \n\n\nThe probabilities for a discrete r.v. are additive because \\(\\{X = a\\}\\) and \\(\\{X = b\\}\\) are disjoint for any possible values \\(a \\ne b\\).\n\n \\(P(X = 1 \\text{ or } 2) = P(\\{X = 1\\} \\cup \\{X = 2\\}) = P(X = 1) + P(X = 2)\\). \n\n\n\n\n Mean \n\nSuppose \\(X\\) takes values \\(x_1, \\dots, x_k\\) with probabilities \\(P(X = x_1), \\dots, P(X = x_k)\\).\nThe mean or expected value of \\(X\\) is the sum of each outcome multiplied by its corresponding probability: \\[E(X) := x_1 \\times P(X = x_1) + \\dots + x_k \\times P(X = x_k) = \\sum_{i=1}^kx_iP(X=x_i)\\]\n\nThe Greek letter \\(\\mu\\) may also be used in place of the notation \\(E(X)\\).\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe mean of a discrete random variable \\(X\\) is a weighted average.\nThe possible values, \\(x\\), are weighted by their corresponding probability.\n\n\n\n\n\n\n\n\n\nWhat is the mean of \\(X\\) (the number of heads) in the previous example?\n\n\n\n\n\n\n\n Variance \n\nSuppose \\(X\\) takes values \\(x_1, \\dots , x_k\\) with probabilities \\(P(X = x_1), \\dots, P(X = x_k)\\) and expected value \\(\\mu = E(X)\\).\nThe variance of \\(X\\), denoted by \\(Var(X)\\) or \\(\\sigma^2\\), is \\[\\small Var(X) := (x_1 - \\mu)^2 \\times P(X = x_1) + \\dots + (x_k - \\mu)^2 \\times P(X = x_k) = \\sum_{i=1}^k(x_i - \\mu)^2P(X=x_i)\\]\n\nThe standard deviation of \\(X\\), \\(\\sigma\\), is the square root of the variance.\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe variance of a discrete random variable \\(X\\) is also weighted.\nIt is the sum of squared deviation from the mean weighted by probability values.\n\n\n\n\n\n\n\n\n\nWhat is the variance of \\(X\\) (the number of heads) in the previous example?"
  },
  {
    "objectID": "prob-disc.html#binomial-distribution",
    "href": "prob-disc.html#binomial-distribution",
    "title": "9Â  Discrete Probability Distributions",
    "section": "\n9.2 Binomial Distribution",
    "text": "9.2 Binomial Distribution\n Binomial Experiment and Random Variable \nBinomial distribution is generated from the so-called binomial experiment that has the following properties:\n\nðŸ‘‰ The experiment consists of a fixed number of identical trials, say \\(n\\). That is, \\(n\\) is pre-specified before the experiment is conducted, and remains unchanged while the experiment is in progress. Also, all the trials or repetitions in the experiment should be performed with exactly the same condition or procedure.\nðŸ‘‰ Each trial results in one of exactly two outcomes. In practice, we use success (S) and failure (F) to represent the two outcomes. The word success just means one of the two outcomes and does not necessarily mean something good. ðŸ˜² Depending on your research question, you could define Drug abuse as success and No drug abuse as failure.\nðŸ‘‰ Trials are independent, meaning that the outcome of one trial does not affect the outcome of any other trial.\nðŸ‘‰ The probability of success, say \\(\\pi\\), is constant for all trials.\n\nIf a binomial experiment is conducted, and \\(X\\) is defined as  the number of successes observed in \\(n\\) trials , then \\(X\\) is a binomial random variable.\n\n\n\n\n\n Distribution \nThe probability function \\(P(X = x)\\) of a binomial variable \\(X\\) can be fully determined by the number of trials \\(n\\) and the probability of success \\(\\pi\\). Once \\(n\\) and \\(\\pi\\) are fixed and known, we know exactly what the distribution looks like, and we can form a table, graph, and provide a mathematical formula of the binomial probability function. A different \\((n, \\pi)\\) pair generates a different binomial probability distribution. The value(s) that determines an entire probability distribution is called the parameter of the distribution. Therefore, \\(X\\) is said to follow a binomial distribution with parameters \\(n\\) and \\(\\pi\\), written as \\(\\color{blue}{X \\sim binomial(n, \\pi)}\\).\nThe binomial probability function is \\[ \\color{blue}{P(X = x \\mid n, \\pi) = \\frac{n!}{x!(n-x)!}\\pi^x(1-\\pi)^{n-x}, \\quad x = 0, 1, 2, \\dots, n}\\]\nIt is not that important to memorize the formula as nowadays we use computing software to obtain \\(P(X = x)\\) for any \\(x\\). Notice that the maximal possible number of \\(x\\) is \\(n\\), the number of trials. We cannot have 5 successes when there are only 4 trials in the experiment. Second, when both \\(n\\) and \\(pi\\) are known and fixed, with a value of \\(x\\), everything in the formula is known, and the probability can be calculated.\nIt can be shown that the binomial distribution has mean \\(\\mu = E(X) = n\\pi\\) and variance \\(\\sigma^2 = Var(X) = n\\pi(1-\\pi)\\).\n\n\n\n\n\n\nIf we toss a fair coin two times independently and let \\(X =\\) # of heads, is \\(X\\) a binomial random variable?\n\n\n\n\n\n\nTo answer this question, we need to check if the experiment satisfies the four properties.\n\nThe number of trials is 2, and the two trials, tossing a fair coin are identical (if you are not nitpicking).\nEach trial results in one of exactly two outcomes, heads or tails.\nTrials are independent. Well itâ€™s hard to say, but at least they are nearly independent.\nThe probability of heads is 1/2 for all trials because we got a fair coin.\n\nSo, is \\(X\\) a binomial random variable? You tell me.\n Example \n\n\nAssume that 20% of all drivers have a blood alcohol level above the legal limit. For a random sample of 15 vehicles, compute the probability that:\n\nExactly 6 of the 15 drivers will exceed the legal limit.\nOf the 15 drivers, 6 or more will exceed the legal limit.\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose itâ€™s a binomial experiment with \\(n = 15\\) and \\(\\pi = 0.2\\). Let \\(X\\) be the number of drivers exceeding limit. Then \\(X \\sim binomial(15, 0.2)\\). Therefore,\n\\[ \\color{blue}{P(X = x \\mid n=15, \\pi=0.2) = \\frac{15!}{x!(15-x)!}(0.2)^x(1-0.2)^{15-x}, \\quad x = 0, 1, 2, \\dots, 15.}\\]\nSince we know the value of parameter \\(n\\) and \\(\\pi\\), the entire binomial distribution can be described, as shown in FigureÂ 9.2.\n\n\n\n\nFigureÂ 9.2: Binomial Distribution Example \\(X \\sim binomial(15, 0.2).\\)\n\n\n\n\nTo answer the first question, we just need to calculate \\(P(X = 6)\\) using the formula: \\[\\small P(X = 6) = \\frac{n!}{x!(n-x)!}\\pi^x(1-\\pi)^{n-x} = \\frac{15!}{6!(15-6)!}(0.2)^6(1-0.2)^{15-6} = 0.043\\]\nThe second question asks for \\(P(X \\ge 6)\\) because of â€œ6 or more will exceed the legal limitâ€. One can calculate the probability like \\(\\small P(X \\ge 6) = P(X = 6 \\cup X = 7 \\cup \\cdots \\cup X = 15) = p(6) + \\dots + p(15)\\). It requires 10 probability calculations. One simpler way of obtaining the probability is to consider the complement set of \\(\\{X \\ge 6\\}\\) which is \\(\\{X \\le 5\\}\\). Then use the property that \\(P(A) = 1 - P(A^c)\\) to get the answer. So we can do the following \\(P(X \\ge 6) = 1 - P(X \\le 5) = 1 - (p(0) + p(1) + \\dots + p(5)) = 0.0611\\). In this case, we only need to calculate 6 probabilities from the formula.\nWell I believe youâ€™ve seen how tedious calculating a binomial probability is! It is so true especially when \\(n\\) is relatively large. No worries. We are living in the 21th century with lots of advancing computing technology. Weâ€™ll never do such calculation by hand, and weâ€™ll learn to compute them using R!\n\n\n\n\n Computation in R\nIn practice, we are not gonna calculate probabilities of binomial or other commonly used probability distributions. Instead, we use computing software. In R we can use dpqr familty functions to calculate probabilities or generate values from the distributions. In general, for some distribution, short for dist, R has the following functions\n\n\nddist(x, ...): calculate density value \\(f(x)\\) or probability value \\(P(X = x)\\).\n\npdist(q, ...): calculate \\(P(X \\le q)\\).\n\nqdist(p, ...): obtain quantile of probability \\(p\\).\n\nrdist(n, ...): generate \\(n\\) random numbers.\n\nWhen we use these functions, the dist is replaced with the shortened name of the distribution we consider. For example, we use dbinom(x, ...) to do the calculation for the binomial distribution.\nThe function ddist(x, ...) gives us the probability density value \\(f(x)\\) if the distribution is continuous, and it is why the function starts with d. The continuous probability distribution will be discussed in ChapterÂ 10 in detail. If the distribution is discrete, like binomial, it gives us the value \\(P(X = x)\\) where \\(X\\) follows the distribution being considered, and \\(x\\) is the value specified in the first argument of the function.\nFor the binomial distribution, we use dbinom(x, size, prob) to compute \\(P(X = x)\\), where size is the number of trials and prob is the probability of success. Besides \\(x\\), we need to provide the values of size and prob because remember that they are the parameters of the binomial distribution. Without them, we cannot have a specific binomial distribution, and its probability cannot be calculated.\nTo obtain \\(P(X = 6)\\) where \\(X \\sim binomial(n=15, \\pi=0.2)\\), in R, we do\n\n## 1. P(X = 6)\ndbinom(x = 6, size = 15, prob = 0.2) \n\n[1] 0.04299262\n\n\nTo answer the second question \\(P(X \\ge 6)\\), we can use the function pbinom(q, size, prob) that calculates \\(P(X \\le q)\\) for \\(X \\sim bionomial(n = \\texttt{size}, \\pi = \\texttt{prob})\\). Notice that \\(P(X >= 6) = 1 - P(X <= 5)\\), so in R, we can do\n\n## 2. P(X >= 6) = 1 - P(X <= 5)\n1 - pbinom(q = 5, size = 15, prob = 0.2) \n\n[1] 0.06105143\n\n\nBy default, the function pbinom(q, size, prob) calculates the probability \\(P(X \\le q)\\) which is the left or lower tail part of the distribution. The function provides an argument lower.tail that is logical, and is TRUE by default. When we set lower.tail = FALSE in the function, it will instead calculate \\(P(X > q)\\) which is the right or upper tail part of the distribution. Since \\(P(X \\ge 6) = P(X > 5)\\), in R we can do\n\n## 2. P(X >= 6) = P(X > 5)\npbinom(q = 5, size = 15, prob = 0.2, lower.tail = FALSE) \n\n[1] 0.06105143\n\n\nNotice that we use q = 5 instead of q = 6 because we want \\(P(X > 5)\\). Also, lower.tail = FALSE is added into the function, and the probability value is the same as the value before.\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBelow is an example of how to generate the binomial probability distribution as a graph.\n\nplot(x = 0:15, y = dbinom(0:15, size = 15, prob = 0.2), \n     type = 'h', xlab = \"x\", ylab = \"P(X = x)\", \n     lwd = 5, main = \"Binomial(15, 0.2)\")\n\n\n\n\n\n\n\nHere a sequence of integers 0 to 15 are created and put in the x-axis. Then dbinom(0:15, size = 15, prob = 0.2) is used to create probabilities of \\(binomial(15, 0.2)\\) for each integer. The vertical bar geometry comes from the argument type = 'h' standing for â€œhistogramâ€.1\nSince \\(n = 15\\) and \\(\\pi = 0.2\\), the mean is \\((15)(0.2) = 3\\). For the binomial distribution, it means that the number of success is more likely to be happened around \\(x = 3\\). It is very uncommon to see that more than 10 drivers have alcohol level above the legal limit."
  },
  {
    "objectID": "prob-disc.html#poisson-distribution",
    "href": "prob-disc.html#poisson-distribution",
    "title": "9Â  Discrete Probability Distributions",
    "section": "\n9.3 Poisson Distribution",
    "text": "9.3 Poisson Distribution\n Poisson Random Variables \nIf we want to count the number of occurrences of some event2 over a unit of time or space/region/volume and observe its associated probability, we could consider the Poisson distribution. For example,\n\nThe number of COVID patients arriving at ICU in one hour\nThe number of Marquette students logging onto D2L in one day\nThe number of dandelions per square meter on Marquetteâ€™s campus\n\nLet \\(X\\) be a Poisson random variable. Then \\(\\color{blue}{X \\sim Poisson(\\lambda)}\\), where \\(\\lambda\\) is the parameter representing the mean number of occurrences of the event in some time interval or region. The Poisson probability function is\n\\[\\color{blue}{P(X = x \\mid \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}, \\quad x = 0, 1, 2, \\dots}\\]\nAgain, the parameter \\(\\lambda\\) determines the shape of the distribution. The constant \\(e\\) is the Eulerâ€™s number that is approximately \\(2.7182818284\\). \\(x! = x \\times (x-1) \\times \\cdots \\times 2 \\times 1\\) and \\(0! = 1\\). Note that the possible value of \\(x\\) could be any positive integer. Theoretically speaking, there is no upper limit for the number of occurrences of any event. No worries. You donâ€™t need to memorize the formula, but itâ€™s good to recognize it.\nOne interesting property of the Poisson distribution is that its mean and variance are both equal to its parameter \\(\\lambda\\). So a \\(Poisson(5)\\) distribution has mean and variance being equal to 5.\n\n\n Assumptions and Properties of Poisson Variables \nAs the binomial distribution, the Poisson distribution comes from the Poisson experiment having the following properties and assumptions:\n\nðŸ‘‰ Events occur one at a time; two or more events do not occur at the same time or in the same space or spot. For example, one cannot say two patients arrived at ICU at the same time. There must be a way to separate one event from the other, and one can always know which patient arrives at ICU earlier.\nðŸ‘‰ The occurrence of an event in a given period of time or region of space is independent of the occurrence of the event in a nonoverlapping time period or region of space. For example, number of patients arriving at ICU between 2 PM and 3 PM has nothing to do with the number of patients arriving at ICU between 8 PM and 9 PM because the two time periods have no overlap.\nðŸ‘‰ \\(\\lambda\\) is constant for any period or region. For example, the mean number of patients arriving at ICU between 2 PM and 3 PM is the same as the mean number of patients arriving at ICU between 8 PM and 9 PM. This assumption is pretty strong, and usually violated in reality. If you want to use Poisson distribution to build your statistical model, use it with additional care.\n\n\n\n\n\n\n\nWhat are the differences between Binomial and Poisson distributions?\n\n\n\nThe Poisson distribution\n\nis determined by one single parameter \\(\\lambda\\)\nhas possible values \\(x = 0, 1, 2, \\dots\\) with no upper limit (countable), while a binomial variable has possible values \\(0, 1, 2, \\dots, n\\) (finite)\n\n\n\n\n Example \n\n\nLast year there were 4200 births at the University of Wisconsin Hospital. Let \\(X\\) be the number of births in a given day at the center, and assume \\(X \\sim Poisson(\\lambda)\\). Find\n\n\\(\\lambda\\), the mean number of births per day.\nthe probability that on a randomly selected day, there are exactly 10 births.\n\\(P(X > 10)\\)?\n\n\n\n\n\n\nSource: Unsplash kaushal mishra\n\n\n\n\n\n\n\n\\(\\small \\lambda = \\frac{\\text{Number of birth in a year}}{\\text{Number of days}} = \\frac{4200}{365} = 11.5.\\) There are totally 4200 births in one year, so on average there are 11.5 per day. According to how we define \\(X\\), the time unit is a day, not a year. The parameter \\(\\lambda\\) and \\(X\\) should have the same time unit.\n\\(\\small P(X = 10 \\mid \\lambda = 11.5) = \\frac{\\lambda^x e^{-\\lambda}}{x!} = \\frac{11.5^{10} e^{-11.5}}{10!} = 0.113.\\)\n\\(\\small P(X > 10) = p(11) + p(12) + \\dots + p(20) + \\dots\\) (No end!) \\(\\small P(X > 10) = 1 - P(X \\le 10) = 1 - (p(1) + p(2) + \\dots + p(10))\\).\n\nDid you see how tedious it is to calculate the Poisson probabilities even using a calculator? I know you are waiting for R implementation!\n\n Computation in R \n\n\nInstead of using dbinom() and pbinom(), for Poisson distribution, we replace binom with pois, and use dpois(x, lambda) and ppois(q, lambda) to calculate the probabilities.\nWith lambda being the mean of Poisson distribution, and \\(X\\sim Poisson(\\lambda)\\), we\n\nuse dpois(x, lambda) to compute \\(P(X = x \\mid \\lambda)\\)\nuse ppois(q, lambda) to compute \\(P(X \\le q \\mid \\lambda)\\)\nuse ppois(q, lambda, lower.tail = FALSE) to compute \\(P(X > q \\mid \\lambda)\\)\n\n\n# 1.\n(lam <- 4200 / 365)\n\n[1] 11.50685\n\n## 2. P(X = 10)\ndpois(x = 10, lambda = lam)  \n\n[1] 0.112834\n\n\n\n## 3.\n## P(X > 10) = 1 - P(X <= 10)\n1 - ppois(q = 10, lambda = lam)  \n\n[1] 0.5990436\n\n## P(X > 10)\nppois(q = 10, lambda = lam, \n      lower.tail = FALSE) \n\n[1] 0.5990436\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBelow is an example of how to generate the Poisson probability distribution as a graph.\n\nplot(0:24, dpois(0:24, lambda = lam), type = 'h', \n     lwd = 5, ylab = \"P(X = x)\", xlab = \"x\", \n     main = \"Poisson(11.5)\")\n\n\n\n\nBe careful that the Poisson \\(X\\) has no upper limit; the graph is truncated at \\(x = 24\\). Strictly speaking, the graph does not accurately display the \\(Poisson(11.5)\\) distribution. Since the mean is 11.5, we know that it is very unlikely to have a very large \\(x\\), that is \\(P(X = x)\\) is very close to zero for \\(x > 25\\). As the binomial distribution, the number of occurrences is more likely to be around its mean number 11.5, and the chance is decaying as the number is away from the mean."
  },
  {
    "objectID": "prob-disc.html#exercises",
    "href": "prob-disc.html#exercises",
    "title": "9Â  Discrete Probability Distributions",
    "section": "\n9.4 Exercises",
    "text": "9.4 Exercises\n\nData collected by the Substance Abuse and Mental Health Services Administration (SAMSHA) suggests that 65% of 18-20 year olds consumed alcoholic beverages in any given year.\n\nSuppose a random sample of twelve 18-20 year olds is taken. When does it make sense to use binomial distribution for calculating the probability that exactly five consumed alcoholic beverages?\nWhat is the probability that exactly five out of twelve 18-20 year olds have consumed an alcoholic beverage?\nWhat is the probability that at most 3 out of 7 randomly sampled 18-20 year olds have consumed alcoholic beverages?\n\n\nA Dunkinâ€™ Donuts in Milwaukee serves an average of 65 customers per hour during the morning rush.\n\nWhich distribution have we studied that is most appropriate for calculating the probability of a given number of customers arriving within one hour during this time of day?\nWhat are the mean and the standard deviation of the number of customers this Starbucks serves in one hour during this time of day?\nCalculate the probability that this Dunkinâ€™ Donuts serves 55 customers in one hour during this time of day."
  },
  {
    "objectID": "prob-cont.html#introduction",
    "href": "prob-cont.html#introduction",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.1 Introduction",
    "text": "10.1 Introduction\nUnlike a discrete random variable taking finite or countable values, a continuous random variable takes on any values from an interval of the real number line. For example, a continuous random variable \\(X\\) could take any value in the unit interval \\([0, 1]\\). Its possible values are uncountable.\nInstead of probability functions, a continuous random variable \\(X\\) has the probability density function (pdf) denoted \\(f(x)\\) such that for any real value \\(a < b\\), \\[P(a < X < b) = \\int_{a}^b f(x) dx.\\]\nThe probability that \\(X\\) is in some interval is computed from the integral of the density function with respect to \\(x\\). Keep in mind that the density function \\(f(x)\\) itself is not the probability that \\(X = x\\). The probability of continuous random variables is defined through the integral of \\(f(x)\\).\nThe cumulative distribution function (cdf) of \\(X\\) is defined as \\[F(x) := P(X \\le x) = \\int_{-\\infty}^x f(t)dt.\\]\nðŸ˜Ž Luckily, we donâ€™t calculate integrals in this course. You just need to remember that for continuous random variables,\n\n\n\n\n\n\nImportant\n\n\n\n\nThe pdf does not represent a probability.\nThe integral of pdf represents a probability.\nThe cdf itself by definition is a probability that is also from the integral of pdf.\n\n\n\nEvery probability density function must satisfy the two properties:\n\n\\(f(x) \\ge 0\\) for all \\(x\\) on the real line\n\\(\\int_{-\\infty}^{\\infty} f(x) dx = 1\\)\n\n\\(f(x)\\) is a density value. For property 1, like density used in Physics, it cannot be negative. The density here represents how much likely the random variable \\(X\\) is around the value \\(x\\). When \\(f(x) = 0\\), it means that it is not possible to have \\(X\\) having value in the tiny neighborhood around \\(x\\). On the other hand, when \\(f(x)\\) is large, it is pretty likely to have \\(X\\) having values around \\(x\\). Because \\(f(x)\\) is the integrand, a larger value of \\(f(x)\\) in the interval \\([a, b]\\) will lead to a larger probability \\(P(a < X < b)\\).\nThe second property tells us that \\(P(-\\infty < X < \\infty) = 1\\). Remember that a random variable, whether it is discrete or continuous, must take a real value. Therefore the probability that \\(X\\) lives on the entire real line \\((-\\infty, \\infty)\\) is one.\nIn fact, any function satisfying the two properties can be served as a probability density function for some random variable.\n\n Density Curve \nA probability density function generates a graph called a density curve that shows the likelihood of a random variable at all possible values. FigureÂ 10.1 shows an example of density curve colored in blue. From Calculus 101, we have two important findings:\n\nThe integral of \\(f(x)\\) between \\(a\\) and \\(b\\) is actually the area under the density curve between \\(a\\) and \\(b\\). Therefore, the area under the density curve represents the probability \\(P(a < X < b) = \\int_{a}^b f(x) dx\\), the density value \\(f(x)\\), or the height of the density curve does not.\nThe total area under any density curve is equal to 1: \\(\\int_{-\\infty}^{\\infty} f(x) dx = 1\\).\n\n\n\n\n\nFigureÂ 10.1: Density curve for a random variable\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nKeep in mind that the area under the density curve represents probability, not the density value or the height of the density curve at some value of \\(x\\).\nOne question is for a continuous random variable \\(X\\), what is the probability that \\(X\\) equals any real number, or \\(P(X = a)\\) for any \\(a \\in \\mathbf{R}\\)? Since \\(P(X = a) = P(a \\le X \\le a) = \\int_{a}^a f(x) dx = 0\\), we know that \\(P(X = a) = 0\\) for any real number \\(a\\). Graphically speaking, it means that there is no area under the density curve between \\(a\\) and \\(a\\).\nTherefore, for a continuous random variable \\(X\\), \\(P(a \\le X\\le b) = P(a < X < b)\\) for any real value \\(a\\) and \\(b\\) because there is no probability mass on \\(x = a\\) and \\(x = b\\).\n\n\n\n Commonly Used Continuous Distributions \n\nThere are tons of continuous distributions out there, and we wonâ€™t be able to discuss all of them. In this book, we will touch on normal (Gaussian), studentâ€™s t, chi-square, and F distributions. Some other popular distributions include uniform, exponential, gamma, beta, inverse gamma, Cauchy, etc. If you are interested in learning more distributions and their properties, please take a calculus-based probability theory course."
  },
  {
    "objectID": "prob-cont.html#normal-gaussian-distribution",
    "href": "prob-cont.html#normal-gaussian-distribution",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.2 Normal (Gaussian) Distribution",
    "text": "10.2 Normal (Gaussian) Distribution\nWe now discuss the most important distribution in probability and statistics, the normal distribution or Gaussian distribution.1\nThe normal distribution, referred to as \\(N(\\mu, \\sigma^2\\)), has the probability density function given by \\[\\small f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}, \\quad -\\infty < x < \\infty,\\] where the two parameters \\(\\mu\\) and \\(\\sigma^2\\) (\\(\\sigma\\)) are the mean and variance (standard deviation) of the distribution respectively. The normal variable \\(X\\) lives on the entire real line. The normal density value \\(f(x)\\) is not exactly equal to zero although it is tiny for extremely large \\(x\\) in absolute value. When \\(\\mu = 0\\) and \\(\\sigma = 1\\), \\(N(0, 1)\\) is called standard normal.\nFigureÂ 10.2 are examples of normal density curves and how they change with different means and standard deviations. The normal distribution is always bell-shaped and symmetric about the mean \\(\\mu\\), regardless of the value of \\(\\mu\\) and \\(\\sigma\\). The parameter \\(\\mu\\) is the location parameter that controls the â€œlocationâ€ of the distribution. The navy \\(N(100, 10^2)\\) is 80 units right of the red \\(N(20, 10^2)\\). The parameter \\(\\sigma\\) is the scale parameter that determines the variability or spreadness of the distribution. The navy \\(N(100, 10^2)\\) and the yellow \\(N(100, 15^2)\\) are at the same location, but \\(N(100, 15^2)\\) has more variation than \\(N(100, 10^2)\\). Since the total area under the density curve is always one, to account for large variation, the density curve of \\(N(100, 15^2)\\) has heavier tails and lower density values around the mean. Heavier tails means it is more probable to have extreme values like 130 or 70 that are away from the mean 100, comparing to \\(N(100, 10^2)\\) with smaller variation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 10.2: Normal density curves with varying means and standard deviations"
  },
  {
    "objectID": "prob-cont.html#standardization-and-z-scores",
    "href": "prob-cont.html#standardization-and-z-scores",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.3 Standardization and Z-Scores",
    "text": "10.3 Standardization and Z-Scores\nStandardization is a transformation that allows us to convert any normal distribution \\(N(\\mu, \\sigma^2)\\) to \\(N(0, 1)\\), the standard normal distribution.\nWhy do we want to perform standardization? We want to put data on a standardized scale, because it helps us make comparisons more easily. Later we will see why. Letâ€™s first see how we can do standardization.\nIf \\(x\\) is an observation from a distribution, not necessarily normal, with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), the standardized value of \\(x\\) is called \\(z\\)-score: \\[z = \\frac{x - \\mu}{\\sigma}\\]\nThe \\(z\\)-score tells us how many standard deviations \\(x\\) falls away from its mean and in which direction.\n\nObservations larger than the mean have positive \\(z\\)-scores.\nObservations smaller than the mean have negative \\(z\\)-scores.\nA \\(z\\)-score -1.2 means that \\(x\\) is 1.2 standard deviations to the left of or below the mean.\nA \\(z\\)-score 1.8 means that \\(x\\) is 1.8 standard deviations to the right of or above the mean.\n\n If \\(X \\sim N(\\mu, \\sigma^2)\\), then \\(Z = \\frac{X - \\mu}{\\sigma}\\), the transformed random variable, follows the standard normal distribution \\(Z \\sim N(0, 1)\\). \n\n\n\n\n\n\nNote\n\n\n\nAny transformation of a random variable is still a random variable but with a different probability distribution.\n\n\n\n Graphical Illustration \nWhat does the standardization really do? Well it first subtracts the original variable value \\(x\\) from the mean \\(\\mu\\), then divided by its standard deviation \\(\\sigma\\).\n\nFirst, \\(X - \\mu\\) shifts the mean from \\(\\mu\\) to 0. FigureÂ 10.3 illustrates this. The original distribution is \\(X \\sim N(3, 4)\\) (navy). Then the new variable \\(Y = X-\\mu\\) is \\(Y = X - 3\\) that follows \\(N(0, 4)\\) distribution (blue). \\(X - \\mu\\) means the distribution is shifted to the left 3 units, so that the new location or center becomes zero.\n\n\n\n\n\nFigureÂ 10.3: Standardization shifts mean from 3 to 0\n\n\n\n\n\nSecond, \\(\\frac{X - \\mu}{\\sigma}\\) scales the variation from 4 to 1. \\(Y = X-3 \\sim N(0, 4).\\) Because \\(\\sigma = 2\\), \\(Z = \\frac{X - 3}{2} \\sim N(0, 1)\\). The idea is that one unit change in \\(X\\) is one unit change in \\(Y\\), but just 1/2 unit change in \\(Z\\). Through dividing by \\(\\sigma\\), the variation measured in the new scale becomes smaller, and the new variance is one. For any normal variable with an arbitrary finite value of \\(\\mu\\) and \\(\\sigma\\), the variable after standardization will always follow \\(N(0, 1)\\) (red).\n\n\n\n\n\nFigureÂ 10.4: Standardization scales variance from 4 to 1\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf \\(\\sigma < 1\\), then the variation measured in the new scale becomes larger, because the new variance is one.\n\n\nA value of \\(x\\) that is 2 standard deviation below the mean, \\(\\mu\\), corresponds to \\(z = -2\\). For any \\(\\mu\\) and \\(\\sigma\\), \\(x\\) and \\(z\\) have a one-to-one correspondence relationship: \\(z = \\frac{x -\\mu}{\\sigma} \\iff x = \\mu + z\\sigma\\). So if \\(z = -2\\), \\(x = \\mu - 2\\sigma\\). FigureÂ 10.5 depicts how the values on the x-axis change when standardization is performed.\n\n\n\n\nFigureÂ 10.5: Standardized Normal Distribution\n\n\n\n\n\n SAT and ACT Example (OS Example 4.2) \nStandardization can help us compare the performance of students on the SAT and ACT, which both have nearly normal distributions. The table below lists the parameters for each distribution.\n\n\nMeasure\nSAT\nACT\n\n\n\nMean\n1100\n21\n\n\nSD\n200\n6\n\n\n\n\n\n\n\n\n\n\n\nSuppose Anna scored a 1300 on her SAT and Tommy scored a 24 on his ACT. We want to determine whether Anna or Tommy performed better on their respective tests.\n Standardization \nSince SAT and ACT are measured on a different scale, we are not able to compare the two scores unless we measure them using the same scale. What we do is standardization. Both SAT and ACT are normally distributed but with different mean and variance. We first transform the two distributions into the standard normal distribution, then examining Anna and Tommysâ€™ performance by checking the location of their score on the standard normal distribution.\nThe idea is that we first measure the two scores using the same scale and unit. The new transformed score in both cases is how many standard deviations the original score is away from its original mean. That is, both SAT and ACT are measured using the z-score. Then if Aâ€™s z-score is larger than Bâ€™ z-score, we know that A performs better than B because A has a relatively higher score than B.\nThe z-score of Anna and Tommy is \\(z_{A} = \\frac{x_{A} - \\mu_{SAT}}{\\sigma_{SAT}} = \\frac{1300-1100}{200} = 1\\); \\(z_{T} = \\frac{x_{T} - \\mu_{ACT}}{\\sigma_{ACT}} = \\frac{24-21}{6} = 0.5\\).\n\n\n\n\nFigureÂ 10.6: SAT and ACT distribution\n\n\n\n\nThis standardization tells us that Anna scored 1 standard deviation above the mean and Tommy scored 0.5 standard deviations above the mean. From this information, we can conclude that Anna performed better on the SAT than Tommy performed on the ACT.\nFigureÂ 10.6 shows the SAT and ACT distributions. Note that the two distributions are depicted using the same density curve, as if they are measured on the same scale or standard normal distribution. Clearly we can see that Anna tends to do better with respect to everyone else than Tommy did."
  },
  {
    "objectID": "prob-cont.html#tail-areas-and-normal-percentiles",
    "href": "prob-cont.html#tail-areas-and-normal-percentiles",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.4 Tail Areas and Normal Percentiles",
    "text": "10.4 Tail Areas and Normal Percentiles\n Finding Tail Areas \\(P(X < x)\\) \nFinding tail areas allows us to determine the percentage of cases that are above or below a certain score. Going back to the SAT and ACT example, this can help us determine the fraction of students have an SAT score below Annaâ€™s score of 1300. This is the same as determining what percentile Anna scored at, which is the percentage of cases that had lower scores than Anna. Therefore, we are looking for \\(P(X < 1300 \\mid \\mu = 1100, \\sigma = 200)\\) or \\(P(Z < 1 \\mid \\mu = 0, \\sigma = 1)\\) that corresponds to the blue area size shown in FigureÂ 10.7. How? We can calculate this value using R.\n\n\n\n\nFigureÂ 10.7: Tail area for scores below 1300\n\n\n\n\n Calculation in R \nWith mean and sd representing the mean and standard deviation of a normal distribution, we use\n\npnorm(q, mean, sd) to compute \\(P(X \\le q)\\)\npnorm(q, mean, sd, lower.tail = FALSE) to compute \\(P(X > q)\\)\n\n\npnorm(1, mean = 0, sd = 1)\n\n[1] 0.8413447\n\npnorm(1300, mean = 1100, sd = 200)\n\n[1] 0.8413447\n\n\nNotice that the z-score 1 in standard normal is equivalent to 1300 in \\(N(1100, 200^2)\\). The shaded area represents the 84.1% of SAT test takers who had z-score below 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n Second ACT and SAT Example \nShannon is an SAT taker, and nothing else is known about her SAT aptitude. With SAT score following \\(N(1100, 200^2)\\), what is the probability Shannon SAT score is at least 1190?\n\n\n\n\n\nLetâ€™s get the probability step by step. The first step is to figure out the probability we want to compute from the description of the question.\n\n\n Step 1: State the problem \n\n We want to compute \\(P(X \\ge 1190)\\). \n\n\n\nIf you are an expert like me, you may already know how to get the probability using R once you know what you want to compute. But if you are a beginner, I strongly recommend you drawing a normal picture, and figure out which area is your goal.\n\n Step 2: Draw a picture\n\n\n\n\n\nFigureÂ 10.8: Tail area for scores greater than 1190\n\n\n\n\n\n\n\n\nFigureÂ 10.9: Method to determine right tail areas\n\n\n\n\nNote that FigureÂ 10.9 reflects the fact that \\(P(X \\ge 1190) = 1 - P(X < 1190).\\) The area on the right is equal to the whole area which is one minus the area on the left.\nThe next step, which is not necessary, is to find the z-score. Using z-scores help us write shorter R code to compute the wanted probability.\n\n Step 3: Find \\(z\\)-score \n\n \\(z = \\frac{1190 - 1100}{200} = 0.45\\) and we want to compute \\(\\begin{align*} P(X > 1190) &= P\\left( \\frac{X - \\mu}{\\sigma} > \\frac{1190 - 1000}{200} \\right) \\\\&= P(Z > 0.45) = 1 - P(Z \\le 0.45) \\end{align*}\\) \nAt this point, we obtain the target probability once we get \\(P(Z \\le 0.45)\\). The last step is to use pnorm() function to get it done.\n\n Step 4: Find the area using pnorm() \n\n\n1 - pnorm(0.45)\n\n[1] 0.3263552\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we use R pnorm() to compute normal probabilities, standardization is not a must. However, if we donâ€™t use z-scores, we must specify the mean and SD of the original distribution of \\(X\\), like pnorm(x, mean = mu, sd = sigma). Otherwise, R does not know which normal distribution we are considering. For example,\n\n1 - pnorm(1190, mean = 1100, sd = 200)\n\n[1] 0.3263552\n\n\nBy default, pnorm() uses the standard normal distribution assuming mean = 0 and sd = 1. So if we use z-scores to compute probabilities, we donâ€™t need to specify the value of mean and standard deviation, and our code is shorter:\n\n1 - pnorm(0.45)\n\n[1] 0.3263552\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAny probability can be computed using the â€œless thanâ€ form (lower or left tail). In the previous example, we use \\(P(X \\ge 1190) = 1 - P(X < 1190)\\) expression, and we find \\(P(X < 1190)\\) that has the â€œless thanâ€ form.\nThis step is not necessary too, and we can directly compute \\(P(X \\ge 1190)\\) using pnorm(). However, if the calculation involves the â€œgreater thanâ€ form, or we focus on upper or right tail part of the distribution, we need to add lower.tail = FALSE in pnorm(). For example,\n\npnorm(1190, mean = 1100, sd = 200, lower.tail = FALSE)\n\n[1] 0.3263552\n\n\nBy default, lower.tail = TRUE, and pnorm(q, ...) finds a probability \\(P(X < q)\\), the lower tail part of the distribution.\n\n\n\n Normal Percentiles in R \nQuite often we want to know what score we need to get in order to be in the top 10% of the test takers, or the minimal score we should get to be not at the bottom 20%. To answer such questions, we need to find the percentile or quantile of the underlying distribution.\n\n\nTo get the \\(100p\\)-th percentile (or the \\(p\\) quantile denoted as \\(q\\) ) of a normal distribution, given probability \\(p\\), we use\n\nqnorm(p, mean, sd) to get a value of \\(X\\), \\(q\\), such that \\(P(X \\le q) = p\\)\nqnorm(p, mean, sd, lower.tail = FALSE) to get \\(q\\) such that \\(P(X \\ge q) = p\\)\n\n SAT and ACT Example \nBack to our SAT example. What is the 95th percentile for SAT scores?\nKeep in mind that a percentile or quantile is a value of random variable \\(x\\), not a probability. When we find the quantile, its associated probability is given because the probability is the required information to obtain the quantile.\nThe first step again is to figure out what we want. If we want to find the 95th percentile, it means that we want to find the variable value \\(q\\) so that \\(P(X < q) = 0.95\\). In other words, we want to find an \\(x\\) value of the normal distribution, which is greater than 95% of all other cases.\n\n\n Step 1: State the problem \n\n We want to find \\(q\\) s.t \\(P(X < q) = 0.95\\). \n\n\n\nThe whole idea is shown graphically in FigureÂ 10.10. We already know the percentage 95%. All we need to do is to find the value \\(q\\) so that the area left to it is 95%.\n\n Step 2: Draw a picture\n\n\n\n\n\nFigureÂ 10.10: Picture for the 95th percentile of SAT scores\n\n\n\n\n\n\n\nLike we do in finding probabilities, we can first do the standardization for finding quantiles although it is not necessary. So we use qnorm() to find the z-score \\(z^*\\), or the value of a standard normal variable that is the 95th percentile, i.e., \\(P(Z < z^*) = 0.95\\).\n\n\n Step 3: Find \\(z\\)-score s.t. \\(P(Z < z^*) = 0.95\\) using qnorm():\n\n\n(z_95 <- qnorm(0.95))\n\n[1] 1.644854\n\n\nNow, since we are interested in the 95th percentile of SAT, not the z-score, we need to transform the 95th percentile of \\(N(0, 1)\\) back to the 95th percentile of \\(N(1100, 200^2)\\), the original SAT distribution.\n\n\n Step 4: Find the \\(x\\) of the original scale \n\n \\(z_{0.95} = \\frac{x-\\mu}{\\sigma}\\). So \\(x = \\mu + z_{0.95}\\sigma = 1100+(1.645)\\times200 = 1429\\). \n\n\n\n\n(x_95 <- 1100 + z_95 * 200)\n\n[1] 1428.971\n\n\nTherefore, the 95th percentile for SAT scores is 1429.\nNote that we can directly find the 95th percentile of SAT without standardization. We just need to remember to stay in the original SAT distribution by explicitly specifying mean = 1100 and sd = 200 in the qnorm() function, as we do for pnorm().\n\nqnorm(p = 0.95, mean = 1100, sd = 200)\n\n[1] 1428.971"
  },
  {
    "objectID": "prob-cont.html#finding-probabilties",
    "href": "prob-cont.html#finding-probabilties",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.5 Finding Probabilties",
    "text": "10.5 Finding Probabilties\nðŸ‘‰ To find a probability, if you are a beginner, it is always good to draw and label the normal curve and shade the area of interest. Below is a summary of how we can use pnorm() to compute various kinds of probabilities.\n\nðŸ‘‰ Less than\n\n\\(\\small P(X < x) = P(Z < z)\\)\npnorm(z)\npnorm(x, mean = mu, sd = sigma)\n\n\nðŸ‘‰ Greater than\n\n\\(\\small P(X > x) = P(Z > z) = 1 - P(Z \\le z)\\)\n1 - pnorm(z)\n1 - pnorm(x, mean = mu, sd = sigma)\npnorm(x, mean = mu, sd = sigma, lower.tail = FALSE)\n\n\n\n\n\nðŸ‘‰ Between two numbers\n\n\\(\\small P(a < X < b) = P(z_a < Z < z_b) = P(Z < z_b) - P(Z < z_a)\\)\npnorm(z_b) - pnorm(z_a)\npnorm(b, mean = mu, sd = sigma) - pnorm(a, mean = mu, sd = sigma)\n\n\n\nðŸ‘‰ Outside of two numbers \\((a < b)\\) \\[\\small \\begin{align} P(X < a \\text{ or } X > b) &= P(Z < z_a \\text{ or } Z > z_b) \\\\ &= P(Z < z_a) + P(Z > z_b) \\\\ &= P(Z < z_a) + 1 - P(Z < z_b) \\end{align}\\]\n\npnorm(z_a) + pnorm(z_b, lower.tail = FALSE)\npnorm(z_a) + 1 - pnorm(z_b)\npnorm(a, mean = mu, sd = sigma) + pnorm(b, lower.tail = FALSE)\npnorm(a, mean = mu, sd = sigma) + 1 - pnorm(b, mean = mu, sd = sigma)"
  },
  {
    "objectID": "prob-cont.html#checking-normality-normal-quantile-plot",
    "href": "prob-cont.html#checking-normality-normal-quantile-plot",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.6 Checking Normality: Normal Quantile Plot",
    "text": "10.6 Checking Normality: Normal Quantile Plot\nIf we use a statistical method with its assumption being violated, the analysis results and conclusion made by the method will be worthless. Many statistical methods assume variables are normally distributed. Therefore, testing the appropriateness of the normal assumption is a key step.\nWe can check this normality assumption using a so-called normal quantile plot (normal probability plot) or a Quantile-Quantile plot (QQ plot).\nThe construction of the QQ plot is technical, and we donâ€™t need to dig into that at this moment. The bottom line is if the data are (nearly) normally distributed, the points on the QQ plot will lie close to a straight line.\nIf the data are right-skewed, the points on the QQ plot will be convex-shaped. If the data are left-skewed, the points on the QQ plot will be concave-shaped.\n\n\n\n\n\n QQ plot in R \nTo generate a QQ-plot for checking normality in R, we can use qqnorm() and qqline(), where the first argument in the functions is the sample data we would like to check. FigureÂ 10.11 shows QQ plots at the bottom for normal and right-skewed data samples. Since the data normal_sample actually come from a normal distribution, its histogram looks like normal, and its QQ plot look like a perfect straight line. On the other hand, on the right hand side we have a right skewed data set right_skewed_sample. Clearly, its QQ plot is a upward curve, and definitely not linear, indicating that the sample data are not normally distributed.\n\nqqnorm(normal_sample, main = \"Normal data\", col = 4)\nqqline(normal_sample)\nqqnorm(right_skewed_sample, main = \"Right-skewed data\", col = 6)\nqqline(right_skewed_sample)\n\n\n\nFigureÂ 10.11: QQ plots for normal and right-skewed data samples"
  },
  {
    "objectID": "prob-cont.html#exercises",
    "href": "prob-cont.html#exercises",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.7 Exercises",
    "text": "10.7 Exercises\n\nWhat percentage of data that follow a standard normal distribution \\(N(\\mu=0, \\sigma=1)\\) is found in each region? Drawing a normal graph may help.\n\n\\(Z < -1.75\\)\n\\(-0.7 < Z < 1.3\\)\n\\(|Z| > 1\\)\n\n\nThe average daily high temperature in June in Chicago is 74\\(^{\\circ}\\)F with a standard deviation of 4\\(^{\\circ}\\)F. Suppose that the temperatures in June closely follows a normal distribution.\n\nWhat is the probability of observing an 81\\(^{\\circ}\\) F temperature or higher in Chigcago during a randomly chosen day in June?\nHow cool are the coldest 15% of the days (days with lowest average high temperature) during June in Chicago?\n\n\nHead lengths of Virginia opossums follow a normal distribution with mean 104 mm and standard deviation 6 mm.\n\nCompute the \\(z\\)-scores for opossums with head lengths of 97 mm and 108 mm.\nWhich observation (97 mm or 108 mm) is more unusual or less likely to happen than another observation? Why?"
  },
  {
    "objectID": "prob-samdist.html#introduction",
    "href": "prob-samdist.html#introduction",
    "title": "11Â  Sampling Distribution",
    "section": "\n11.1 Introduction",
    "text": "11.1 Introduction\n Parameter \nParameters in a probability distribution are the values describing the entire distribution. For example,\n\n Binomial: two parameters, \\(n\\) and \\(\\pi\\) \n Poisson: one parameter, \\(\\lambda\\) \n Normal: two parameters, \\(\\mu\\) and \\(\\sigma\\) \n\nAs long as we know the values of the parameters of some distribution, we are able to calculate any probability of the distribution, and describe the distribution exactly. The entire distribution is controlled solely by the few parameters.\nIn statistics, we usually assume our target population follows some distribution, but its parameters are unknown to us. For example, we may assume human weight follows \\(N(\\mu, \\sigma^2)\\) although we are not quite sure what its mean and/or variance is. We may think the number of snowstorms in one year in the US follows \\(Poisson(\\lambda)\\) although we have no idea of the mean number of occurrences.\n\n\n\n Human weight \\(\\sim N(\\mu, \\sigma^2)\\) \n\n\n\n\n\n\n\n\n\n\n\n # of snowstorms \\(\\sim Poisson(\\lambda)\\) \n\n\n\n\n\n\n\n\n\n\n\n\n\n Treat Each Data Point as a Random Variable \n\nA statistical data analysis more or less involves some probability. How do we bring probability into the analysis? How is the data related to probability? Here we are going to learn some insight about it. Suppose in order to do a data analysis and inference about some population characteristic, the population mean for example, we collect a sample data of size \\(n\\), a data set having \\(n\\) data points or values.\nHere is how the probability comes into play. First, we assume the target population follows some probability distribution, say \\(N(\\mu, \\sigma^2)\\). Then we treat each data point as a random variable whose realized value, the value shown in our collected data set, is drawn from the population distribution.\nTake Marquette students weight for example. Suppose the weight follows \\(N(\\mu, \\sigma^2)\\). Suppose we decide to collect ten data points, so \\(n = 10\\). Now before we actually collect the data, the ten data points are all random variables that follow \\(N(\\mu, \\sigma^2)\\). If we write the ten variables as \\(X_1\\), \\(X_2, \\dots, X_{10}\\), then we have \\(X_i \\sim N(\\mu, \\sigma^2), i = 1, 2, \\dots, 10.\\) Notice that \\(X_1, X_2, \\dots, X_{10}\\) all follow the same distribution because they all come from the same population. Now, after we collect our data, we have the realized value of those ten random variables. For example, out data set may look like\n\n\n134 110 177 183 144 150 95 200 145 189\n\n\nSo the realized value of \\(X_1\\) is 134, the realized value of \\(X_2\\) is 110, and so on. Each data value is drawn from the population.\n\n\n\n\n\n\n\nFigureÂ 11.1: Illustration of sampling from a population\n\n\n\n\nIn statistics, we usually assume that \\(X_1, X_2, \\dots, X_n\\) are independent, meaning that the value of \\(X_i\\) is not affected by any other \\(X_j, j\\ne i\\). With the same distribution, \\(X_1, X_2, \\dots, X_n\\) are independent and identically distributed , or iid, denoted as\n\n \\(X_1, X_2, \\dots, X_n \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2).\\) \n\nThen we call such sample data \\((X_1, X_2, \\dots, X_n)\\) a random sample of size \\(n\\) from the population.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nBefore we actually collect the data, the data \\(X_1, X_2, \\dots, X_n\\) are random variables from the population distribution \\(N(\\mu, \\sigma^2)\\).\nOnce we collect the data, we know the realized value of these random variables: \\(x_1, x_2, \\dots, x_n\\)."
  },
  {
    "objectID": "prob-samdist.html#sampling-distribution",
    "href": "prob-samdist.html#sampling-distribution",
    "title": "11Â  Sampling Distribution",
    "section": "\n11.2 Sampling Distribution",
    "text": "11.2 Sampling Distribution\nAny value computed from a sample \\((X_1, X_2, \\dots, X_n)\\) is called a (sample) statistic.\n\n The sample mean \\(\\frac{1}{n}\\sum_{i=1}^n X_i\\) is a statistic. \n Sample variance \\(\\frac{\\sum_{i=1}^n \\left(X_i - \\overline{X}\\right)^2}{n-1}\\) is also a statistic. \n\nSince \\(X_1, X_2, \\dots, X_n\\) are random variables, any transformation or function of \\((X_1, X_2, \\dots, X_n)\\) or its statistics is also a random variable. The probability distribution of a statistic is called the sampling distribution of that statistic. It is the probability distribution of that statistic if we were to repeatedly draw samples of the same size from the population.\n\n\n\n\n\n\nDoes the sample mean \\(\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i\\) have a sampling distribution?\n\n\n\nYes, because sample mean is a statistic, and it is a random variable! Keep in mind that before we get the realized values of data, data points are random variables. Because \\(X_1, X_2, \\dots, X_n\\) are random, \\(\\frac{1}{n}\\sum_{i=1}^n X_i\\) is random too. The reason why we can calculate sample mean and same variance in ChapterÂ 5 is because we get the realized values of data. They are actual numbers, so we can do calculations.\n\n\n\n Sampling Distribution of Sample Mean \nSince \\(X_1, X_2, \\dots, X_n\\) are random, if we repeat the sampling couple of times, every time we will be getting different realized values.\nThe following table shows 5 replicates of sample data of size 10. The first data set has 10 realized values 117 169 111 190  98  94 127 105  93 187. If we were to collect another data set, the first realized value of \\(X_1\\) could be any other number from the population, not necessarily to be 117 because again \\(X_1\\) is a random variable. In our example \\(x_1 = 192\\) in the second data set. The idea applies to \\(X_2\\) to \\(X_{10}\\). Now because every time we collect a new data set we get different realized values \\(x_1, x_2, \\dots, x_{10}\\), the realized value of sample mean will vary from sample to sample as well. The first data set gets the sample mean 129.1, the second one 153.2, and so on. This shows why the sample mean is random by nature, and its value varies according to a distribution that is its sampling distribution.\n\n\n           x1  x2  x3  x4  x5  x6  x7  x8  x9 x10  mean\nDataset-1 117 169 111 190  98  94 127 105  93 187 129.1\nDataset-2 192 175 179 159 168 167 103 145 151  93 153.2\nDataset-3  93 110 129 173 145 156 189 184 182  94 145.5\nDataset-4 155 136 129 173 137  92 176 130 189 161 147.8\nDataset-5 121 131 132  91 168 143 138 191 145 140 140.0\n\n\nFigureÂ 11.2 illustrates how we collect the sample of sample means that represents its sampling distribution. In short, if we were able to collect lots of samples of size \\(n\\), and get the sample mean for each sample of size \\(n\\), the histogram of those sample means gives us a pretty good understanding of what the sampling distribution of the sample mean looks like.\n\n\n\n\nFigureÂ 11.2: Sampling distribution of sample means (Biostatistics for the Biological and Health Sciences p.241)\n\n\n\n\nThe following histogram shows the sampling distribution of the sample mean for the sample of size 10 when the sampling are repeated 1000 times. That is, we have 1000 \\(\\overline{x}\\)s, each being computed from \\(\\frac{1}{10}\\sum_{i=1}^{10}x_{i}\\).\n\n\n\n\n\n\n\n\nThe concept is a little abstract, and you may need time to digest it. The applet Sampling Distribution Applet provides animation of how the sampling distribution is formed. I highly recommend that you play with it, and figure out the entire building process.\n\n\n\n\n\n\nWhat are the differences between the sampling distribution of \\(\\overline{X}\\) and the population distribution each individual random variable, \\(X_i\\), is drawn from?\n\n\n\n\n\n\nThis is an important question. So far we know each data point or random variable \\(X_i, i = 1, \\dots, n\\) is drawn from the population distribution. The sample mean \\(\\overline{X}\\) is also a random variable following its sampling distribution. Fo r any population distribution, not necessarily normal, \\(\\overline{X}\\) has the following two properties:\n\n\nThe sample mean \\((\\overline{X})\\) is  less variable  than an individual observation \\(X_i\\). Although \\(\\overline{X}\\) and \\(X_i\\) are both random variables, the sampling distribution of \\(\\overline{X}\\) has smaller variance than \\(X_i\\). Intuitively, \\(\\overline{X}\\) is the average of bunch of \\(X_i\\)s. Averaging is washing the extreme values out, resulting in values similar to each other.\n\n\n\ndata 1: 30 40 50 60 70\n\n\ndata 2: 0 5 50 95 100\n\n\ndata 3: 0 5 10 15 220\n\n\nThe three data sets all have \\(x_1, \\dots, x_5\\). Clearly, \\(X_i\\) could generate pretty small or large values. However, when all five \\(x_1, \\dots, x_5\\) are averaged, the extreme values are combined together, moving toward to some value in between. In this example, all three data sets have the sample mean \\(50\\) with even no variation at all. The sample mean is much more stable than individual \\(X_i\\), especially when the sample size \\(n\\) is large.\n\nThe sample mean \\((\\overline{X})\\) is  more normal  than an individual observation \\(X_i\\).\n\nThe population distribution \\(X_i\\) is drawn from is not necessarily a normal distribution, and it can be any distribution that is not bell-shaped or not unimodal. However, the sampling distribution will always look more like a normal distribution than the assumed population distribution. This sounds unreal, but it is true. The important central limit theorem proves this, and we will talk about it in ChapterÂ 12.\nSuppose \\((X_1, \\dots, X_n)\\) is the random sample from a population distribution with mean \\(\\mu\\), and standard deviation \\(\\sigma\\). Can we know the mean and variance of the sampling distribution of the sample mean \\(\\overline{X} = \\frac{\\sum_{i=1}^nX_i}{n}\\), denoted by \\(\\mu_{\\overline{X}}\\) and \\(\\sigma_{\\overline{X}}\\) respectively? The answer is yes. In fact,\n\n \\(\\mu_{\\overline{X}} = \\mu\\) . The mean of \\(\\mu_{\\overline{X}}\\) is equal to the population mean \\(\\mu\\), i.e., \\(E(\\overline{X}) = \\mu\\).\n \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\) . The standard deviation of \\(\\overline{X}\\) is not equal to the population standard deviation \\(\\sigma\\). It is actually \\(\\frac{\\sigma}{\\sqrt{n}}\\) that is smaller than \\(\\sigma\\). This is consistent with the property that \\(\\overline{X}\\) is less variable than an individual variable \\(X_i\\) we learned before. Notice that the variation of \\(\\overline{X}\\) is getting smaller as the sample size \\(n\\) get large. \\(\\sigma_{\\overline{X}}\\) is also known as the standard error of \\(\\overline{X}\\).\n\nIf the population distribution is  \\(N(\\mu, \\sigma^2)\\) , then the sampling distribution of \\(\\overline{X}\\) is also normally distributed:  \\(N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\\) .\nFigureÂ 11.3 depicts that the sampling distributions of the sample mean are less variable than the population distribution (black colored). As the sample size \\(n\\) increases from 2 (red), 4 (blue), to 8 (green), its corresponding sampling distribution is getting less variable, with smaller chance to have extreme values. Since the population distribution is normally distributed, so is the sampling distribution. The population distribution and the sampling distribution have the same mean, both centered at one.\n\n\n\n\nFigureÂ 11.3: Comparison between sampling distributions and the population distribution.\n\n\n\n\n Example: Rolling a Die \nLetâ€™s see how we get a sampling distribution through an example. Suppose one rolls a fair die 3 times ðŸŽ²ðŸŽ² ðŸŽ² independently to obtain 3 values from the â€œpopulationâ€ \\(\\{1, 2, 3, 4, 5, 6\\}\\). Well if we let \\(X_i, i = 1, 2, 3\\) be the number showing up for the \\(i\\)th roll, then each \\(X_i\\) follows the discrete uniform distribution \\(P(X_i = 1) = P(X_i = 2) = \\cdots = P(X_i = 6) = 1/6\\) because \\(X_i\\) is a discrete random variable and a fair die is rolled. The population mean is \\((1+2+3+4+5+6)/6 = 3.5.\\) FigureÂ 11.4 shows the population distribution.\nTo obtain the sampling distribution of the sample mean, we first repeat the process 10,000 times, and get 10,000 corresponding sample means.\n\n\n          x1 x2 x3     mean\nDataset-1  6  3  2 3.666667\nDataset-2  4  2  5 3.666667\nDataset-3  3  2  6 3.666667\n\n\n. . . . . .\n\n\n              x1 x2 x3     mean\nDataset-9998   5  4  6 5.000000\nDataset-9999   4  1  1 2.000000\nDataset-10000  4  6  1 3.666667\n\n\nThen plot the histogram of those sampling means. FigureÂ 11.5 shows the histogram of those 10000 sample means which can be treated as the sampling distribution of the sample mean. What do we see from the plots? First, since the population distribution is discrete, so is the sampling distribution. Second, both have the identical mean 3.5. 1 Third, the sampling distribution look more like a normal distribution.\n\n\n\n\n\n\nFigureÂ 11.4: Population distribution is discrete uniformly distributed.\n\n\n\n\n\n\n\n\n\nFigureÂ 11.5: Sampling distribution is more normal-like."
  },
  {
    "objectID": "prob-samdist.html#standardization-of-sample-mean",
    "href": "prob-samdist.html#standardization-of-sample-mean",
    "title": "11Â  Sampling Distribution",
    "section": "\n11.3 Standardization of Sample Mean",
    "text": "11.3 Standardization of Sample Mean\nAny random variable can be standardized. For a single random variable \\(X \\sim N(\\mu, \\sigma^2)\\), we have \\(Z = \\frac{X - \\mu}{\\sigma} \\sim N(0, 1)\\). For the sample mean of \\(n\\) variables, we know \\(\\overline{X} \\sim N(\\mu_{\\overline{X}}, \\sigma^2_{\\overline{X}}) = N(\\mu, \\frac{\\sigma^2}{n})\\). To standardize \\(\\overline{X}\\), and make a new standard normal variable from it, we just subtract it from its own mean and divided by it own standard deviation:\n \\[Z = \\frac{\\overline{X} - \\mu_{\\overline{X}}}{\\sigma_{\\overline{X}}} = \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1)\\]\nAgain, since \\(\\overline{X}\\) is a random variable, its transformation is also a random variable. \\(\\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}\\) is a standard normal variable.\n Example: Psychomotor Retardation \n\n\nSuppose psychomotor retardation scores for a group of patients have a normal distribution with a mean of 930 and a standard deviation of 130.\n\nWhat is the probability that the mean retardation score of a random sample of 20 patients was between 900 and 960?\n\n\n\n\n\n\n\n\n\n\n\n\nFirst, from the question assume that \\((X_1, \\dots, X_{20})\\) forms a random sample, and \\(X_1, \\dots, X_{20} \\stackrel{iid}{\\sim} N(930, 130^2)\\). Then \\(\\overline{X} = \\frac{\\sum_{i=1}^{20}X_i}{20} \\sim N\\left(930, \\frac{130^2}{20} \\right)\\).\nWhat we want to compute is \\(P(900 < \\overline{X} < 960)\\). We can first standardize \\(\\overline{X}\\) and represent the probability using standard normal \\(Z\\): \\[\\small \\begin{align}\nP(900 < \\overline{X} < 960) &= P\\left( \\frac{900-930}{130/\\sqrt{20}} < \\frac{\\overline{X}-930}{130/\\sqrt{20}} < \\frac{960-930}{130/\\sqrt{20}}\\right)=P(-1.03 < Z < 1.03)\\\\\n&=P(Z < 1.03) - P(Z < -1.03)\n  \\end{align}\\]\nFinally we just need to find \\(P(Z < 1.03)\\) and \\(P(Z < -1.03)\\) using R:\n\n(960-930)/(130/sqrt(20))\n\n[1] 1.032031\n\n(900-930)/(130/sqrt(20))\n\n[1] -1.032031\n\npnorm(1.032031) - pnorm(-1.032031)\n\n[1] 0.6979424\n\n\nIf we donâ€™t do standardization, remember to use values in the original scale, and specify the mean and standard deviation. Keep in mind the standard deviation is \\(\\sigma_{\\overline{X}} = 130/\\sqrt{20}\\), not \\(130\\).\n\n## P(Xbar < 960) - P(Xbar < 900)\npnorm(960, mean = 930, sd = 130/sqrt(20)) - \n  pnorm(900, mean = 930, sd = 130/sqrt(20))\n\n[1] 0.6979426\n\n\nThe probability that the mean psychomotor retardation score of a random sample of 20 patients is between 900 and 960 is about 70%."
  },
  {
    "objectID": "prob-samdist.html#exercises",
    "href": "prob-samdist.html#exercises",
    "title": "11Â  Sampling Distribution",
    "section": "\n11.4 Exercises",
    "text": "11.4 Exercises\n\nHead lengths of Virginia possums follow a normal distribution with mean 104 mm and standard deviation 6 mm.\n\nWhat is the sampling distribution of the sample mean of the head length when the sample size \\(n = 18\\)?\n\n\nAssume that females have pulse rates that are normally distributed with a mean of 76.0 beats per minute and a standard deviation of 11.5 beats per minute.\n\nIf 1 adult female is randomly selected, find the probability that her pulse rate is less than 81 beats per minute.\nIf 18 adult female are randomly selected, find the probability that their mean pulse rate is less than 81 beats per minute."
  },
  {
    "objectID": "prob-llnclt.html#central-limit-theorem",
    "href": "prob-llnclt.html#central-limit-theorem",
    "title": "12Â  Law of Large Numbers and Central Limit Theorem",
    "section": "\n12.2 Central Limit Theorem",
    "text": "12.2 Central Limit Theorem\nItâ€™s time to talk about the most important theorem in probability and statistics, at least in my opinion, the central limit theorem (CLT).\nIn sampling distribution ChapterÂ 11, we learned that if \\(X_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\), then \\(\\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\\). But the question is  what if the population distribution is NOT normal?  What does the sampling distribution of the sample mean look like if the population distribution is multimodal? or skewed? or not bell-shaped? Well, the central limit theorem gives us the answer!\n\n\n\n\nCentral Limit Theorem (CLT):\nSuppose \\(\\overline{X}\\) is the sample mean from a random sample of size \\(n\\) and from a population distribution having mean \\(\\mu\\) and standard deviation \\(\\sigma < \\infty\\). As \\(n\\) increases, the sampling distribution of \\(\\overline{X}\\) looks more and more like \\(N(\\mu, \\sigma^2/n)\\) regardless of the distribution from which we are sampling!\n\n\n\n\nFigureÂ 12.1: Illustration of Central Limit Theorem. Source: Wiki.\n\n\n\n\nFigureÂ 12.1 illustrates the CLT. First, the random sample \\((X_1, \\dots, X_n)\\) can be collected from any population distribution, whether it is normal or not. The magic part is that the sampling distribution of the sample mean \\(\\overline{X}\\) always looks like normal distribution \\(N(\\mu, \\sigma^2/n)\\) as long as the sample size \\(n\\) is sufficiently large. The larger \\(n\\) is, the more normal-like the sampling distribution of \\(\\overline{X}\\) is. One question is how large is enough for \\(n\\). Amazingly the normal approximation is quite well when \\(n \\ge 30\\). The variance of the sampling distribution which is \\(\\sigma^2/n\\) is decreasing with \\(n\\) as well.\nPlease try the app and see how the shape of the sampling distribution changes with the sample size \\(n\\) and with the shape of the population distribution. You will find that it requires larger \\(n\\) to get a more normal-like sampling distribution if the population distribution is very skewed. You can also see how the CLT works in FigureÂ 12.2 and FigureÂ 12.3. The population distribution can be discrete, like binomial or Poisson distribution. Their sampling distribution of \\(\\overline{X}\\) will still look like normal although the sampling distribution is not continuous.\n\n\n\n\n\n\nFigureÂ 12.2: CLT Illustration: A Right-Skewed Distribution.\n\n\n\n\n\n\n\n\nFigureÂ 12.3: CLT Illustration: A U-shaped Distribution.\n\n\n\n\nIn sum, for a random sample \\((X_1, \\dots, X_n)\\), if the population distribution is normally distributed, then of course with no surprise the sampling distribution of the sample mean is also exactly normally distributed. If the population distribution is not normally distributed, as long as its mean and variance exist, its sampling distribution of the sample mean will still look like a normal distribution when the sample size \\(n\\) is large enough.\n\n\\(X_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\). \\(\\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\\)\n\\(X_i \\stackrel{iid}{\\sim}\\) any distribution (\\(\\mu, \\sigma^2\\)). \\(\\overline{X}\\) looks like \\(N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\\) (for \\(n\\) sufficiently large)\n\nWhy is the central limit theorem Important? Many well-developed statistical methods are based on the normal distribution assumption. With the central limit theorem, we can use these methods even if we are sampling from a non-normal distribution or if we have no idea what the population distribution is, provided that the sample size is large enough."
  },
  {
    "objectID": "prob-llnclt.html#central-limit-theorem-example",
    "href": "prob-llnclt.html#central-limit-theorem-example",
    "title": "12Â  Law of Large Numbers and Central Limit Theorem",
    "section": "\n12.3 Central Limit Theorem Example",
    "text": "12.3 Central Limit Theorem Example\n\n\nSuppose that the selling prices of houses in Milwaukee are known to have a mean of $382,000 and a standard deviation of $150,000.\nIn 100 randomly selected sales, what is the probability the average selling price is more than $400,000?\n\n\n\n\n\n\n\n\nSince the sample size is fairly large \\((n = 100)\\), by the central limit theorem, the sampling distribution of the average selling price is approximately normal with a mean of $382,000 and a standard deviation of \\(150,000 / \\sqrt{100}\\).\nThen \\(P(\\overline{X} > 400000) = P\\left(\\frac{\\overline{X} - 382000}{150000/\\sqrt{100}} > \\frac{400000 - 382000}{150000/\\sqrt{100}}\\right) \\approx P(Z > 1.2)\\) where \\(Z \\sim N(0, 1)\\).\n\nTherefore using R we get the probability\n\npnorm(1.2, lower.tail = FALSE)\n\n[1] 0.1150697\n\npnorm(400000, mean = 382000, \n      sd = 150000/sqrt(100), lower.tail = FALSE)\n\n[1] 0.1150697"
  },
  {
    "objectID": "infer-ci.html#foundations-for-inference",
    "href": "infer-ci.html#foundations-for-inference",
    "title": "13Â  Confidence Interval",
    "section": "\n13.1 Foundations for Inference",
    "text": "13.1 Foundations for Inference\n Inference Framework \n\n\nInferential statistics uses sample data to learn about an unknown population.\n\nIdea: Assume the target population follows some distribution but with unknown parameters.\n\n Assume the population is normally distributed but its mean and/or variance are unknown. \n\n\n\nGoal: Learn the unknown parameters of the assumed population distribution.\n\n\n\n\n\n\n\nFigureÂ 13.1: Sampling from a population\n\n\n\n\n\n\n\n\n\nFigureÂ 13.2: Relationship between probabiltity and statistical inference\n\n\n\n\n\n\n\nThere are two approaches in parameter learning.\n\nEstimation\nHypothesis Testing"
  },
  {
    "objectID": "infer-ci.html#point-estimator",
    "href": "infer-ci.html#point-estimator",
    "title": "13Â  Point and Interval Estimation",
    "section": "\n13.1 Point Estimator",
    "text": "13.1 Point Estimator\nLet me ask you a question.\n\n\n\n\n\n\nIf you could only use a single number to guess the unknown population mean, \\(\\mu\\), what number would you like to use?\n\n\n\n\n\n\nIf the single number you use can be computed from of sample data \\((X_1, X_2, \\dots, X_n)\\), then you use a point estimator to estimate the unknown parameter \\(\\mu\\). Previously we learned that a sample statistic is any transformation or function of \\((X_1, X_2, \\dots, X_n)\\). Therefore, any statistic is considered a point estimator if it is used to estimate a population parameter.\nA point estimate is a value of a point estimator used to estimate a population parameter. So here is the subtle difference. A point estimator is a random variable which is a function of sample data \\((X_1, X_2, \\dots, X_n)\\) (before actually being collected), and a point estimate is the realized value a point estimator, which is a value calculated from the collected data. For example, \\(\\overline{X} = \\frac{1}{n}\\sum_{i=1}^nX_i\\) is a point estimator, and with the sample data \\((x_1, x_2, x_3) = (2, 3, 7)\\), the point estimate is \\(\\overline{x} = \\frac{1}{3}\\sum_{i=1}^3x_i = \\frac{1}{3}(2+3+7) = 4.\\)\nBack to the question. If we want to estimate the unknown population mean, which number we use to estimate it? We now have an intuitive answer. The sample mean \\(\\overline{X}\\) is a statistic and a point estimator for the population mean \\(\\mu\\).\n\n\n\n\n\n\n Sample Mean as an Point Estimator \nLetâ€™s see how the sample mean is used as an point estimator for \\(\\mu.\\) Suppose the true population distribution is \\(N(2, 1)\\). Here the population mean \\(\\mu\\) is two, but letâ€™s pretend we donâ€™t know its value and see how the sample mean performs. Such analysis is called simulation study.\nWe are going to collect a sample of size five, \\((x_1, x_2, x_3, x_4, x_5)\\). In the simulation, we draw five values from \\(N(2, 1)\\). The five drawn values are treated as our sample data, and \\(N(2, 1)\\) is the population distribution. In R, we use rnorm() to generate random numbers from a normal distribution, where the first argument is the number of observations to be generated.\n\n## Generate data x1, x2, x3, x4, x5, each from distribution N(2, 1)\nset.seed(1234)\nx_data_1 <- rnorm(n = 5, mean = 2, sd = 1)\n\nThe following shows the realized five data points and the sample mean.\n\n\n\n\nx1\nx2\nx3\nx4\nx5\nsample mean\n\n\n0.79\n2.28\n3.08\n-0.35\n2.43\n1.65\n\n\n\n\nHere we use the sample mean \\(\\overline{X} = \\frac{1}{5}\\sum_{i=1}^5X_i\\) as our point estimator for \\(\\mu\\), and given the sample, the point estimate is \\(\\overline{x}=\\) 1.65. You can see that the true \\(\\mu\\) is two, but the point estimate \\(\\overline{x}\\) is not equal to \\(\\mu\\). Why?\nAs we discussed in ChapterÂ 11, due to the randomness nature of drawing a sample value from the population distribution, we do not expect the statistic to be the same as the corresponding parameter. It is possible that most of our sample values happen to be larger or smaller than the true mean, or we may unluckily get an outlier sample value that distorts and drags the sample value toward it. In such cases, the sample mean will be not close to the true population mean. You can think this way. One data point represents one piece of information about the unknown population distribution. With a small sample size, our sample only represents a small part of the unknown distribution. The gap between sample mean and the true population mean is kind of like information lost because of not being able to collect the rest of the subjects in the population.\nFigureÂ 13.1 shows the sample data and the population distribution \\(N(2, 1)\\). Notice that we have an extreme value \\(-0.35\\) that is two standard deviations below the mean, and this causes the sample mean to be small.\n\n\n\n\n\n\n\n\nFigureÂ 13.1: Population distribution and sample data.\n\n\n\n\nWell, we could collect a sample again if resources are permitted. In simulation, another sample of size five is drawn from the same population \\(N(2, 1)\\), and the result is shown below.\n\n\n\n\n\n\n\nx1\nx2\nx3\nx4\nx5\nsample mean\n\n\n2.59\n2.71\n1.89\n1.55\n2.61\n2.27\n\n\n\n\nThe second sample mean, \\(\\overline{x} =\\) 2.27, is different from the first one. Why do the first sample and the second sample give us different sample means? Now you see why we want to learn sampling distribution. We use sample mean as the point estimator for \\(\\mu\\), and the sample mean has its own sampling distribution. Therefore, the sample mean varies from sample to sample due to its randomness nature.\n\n\n\n\nWe have connected sampling distribution to statistical inference, in particular the point estimation together. FigureÂ 13.2 shows the sampling distribution of \\(\\overline{X}\\) which is \\(N(2, 1/5)\\) and the two sample mean values calculated from the two data sets. Now can you see why we want to use \\(\\overline{X}\\) as the point estimator for \\(\\mu\\)? It is because the expected value of \\(\\overline{X}\\), \\(E(\\overline{X})\\) is exactly equal to \\(\\mu\\), meaning that if we were able to produces a lot of \\(\\overline{x}\\)s, the average of these \\(\\overline{x}\\)s will be very close to the true unknown \\(\\mu\\) although single one \\(\\overline{x}\\) may still be distant from \\(\\mu\\). When the expected value of a point estimator is equal to the parameter it estimates, we say it is an unbiased estimator. Therefore, the sample mean \\(\\overline{X}\\) is an unbiased estimator for the population mean \\(\\mu\\) because \\(E(\\overline{X}) = \\mu\\).\n\n\n\n\nFigureÂ 13.2: Sampling Distribution of Sampling Mean.\n\n\n\n\n\n Why Point Estimates Are Not Enough \n\n\n\n\n\n\nIf you want to estimate \\(\\mu\\), would you prefer to report a range of values the parameter might be in or a single estimate like \\(\\overline{x}\\)?\n\n\n\n\n\n\nSince \\(\\overline{X}\\) is random and has its own distribution, its value varies from sample to sample. However, in reality we usually have only one data set, and one realized sample mean, and we are not able to replicate other data sets due to limited resources. We donâ€™t know the sample mean we got is close to the true unknown population mean or not. First, the sample mean can go anywhere of its distribution, and the one we got may be far away from \\(\\mu\\). Moreover, we donâ€™t know the value of \\(\\mu\\)! It does not make much sense to use just one single number when those uncertainty are there.\nIf you want to catch a fish, would you prefer to use a spear or a net? I would use a net because Iâ€™m not a sharpshooter, and using a net covers a large range of possible locations where the fish can be. Due to the variation of \\(\\overline{X}\\), if we report a point estimate, we probably wonâ€™t hit the exact population parameter. If we report a range of plausible values, we have a good shot at capturing the parameter."
  },
  {
    "objectID": "infer-ci.html#confidence-intervals",
    "href": "infer-ci.html#confidence-intervals",
    "title": "13Â  Point and Interval Estimation",
    "section": "\n13.2 Confidence Intervals",
    "text": "13.2 Confidence Intervals\nIn statistics, a plausible range of values for \\(\\mu\\) is called a confidence interval (CI). This range depends on how precise and reliable our statistic is as an estimate of the parameter. To construct a CI for \\(\\mu\\), we first need to quantify the variability of our sample mean. Quantifying this uncertainty requires a measurement of how much we would expect the sample statistic to vary from sample to sample. This is in fact the variance of the sampling distribution of the sample mean! Intuitively speaking, if \\(\\overline{x}\\) varies a lot, we are more uncertain about whether the \\(\\overline{x}\\) we got is close to the \\(\\mu\\) or not. In other words, the precision of the estimation is not that good. In order to make sure that the plausible range of values does capture \\(\\mu\\), we need to include more possible values, and make the range larger. Do we know the variance of \\(\\overline{X}\\)? Absolutely. Thanks to CLT, \\(\\overline{X} \\sim N(\\mu, \\sigma^2/n)\\) regardless of what the population distribution is.\nHow confident we are about the CI covering the parameter is called the level of confidence. The higher the confidence level is, the more reliable the CI is because the CI is more likely to capture the parameter.\n\n\n\n\n\n\n\nNote\n\n\n\nGiven the same level of confidence, the larger the variation of \\(\\overline{X}\\) is, the wider the CI for \\(\\mu\\) will be.\n\n\n\n Precision vs.Â Reliability \nWith a fixed sample size, the precision and reliability of a confidence interval are trading off. Here is a question.\n\n\n\n\n\n\nIf we want to be very certain that we capture \\(\\mu\\), should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n\n\n\n\n\nWe use a wider interval because a wider interval is more likely to capture the population parameter value. So a more reliable confidence interval is wider than a less reliable confidence interval. But What drawbacks are associated with using a wider interval?\nThe precision and reliability trade-off is clearly explained in the cute comic in FigureÂ 13.3. I can say I am 100% confident that your exam 1 score is between 0 and 100. Am I right? Yes. But do I provide helpful information? Absolutely not, the interval includes every possible score of the exam. The interval is too wide to be helpful. Such interval is 100% reliable but with no precision at all.\n\n\n\n\nFigureÂ 13.3: Balance between precision and reliability. Source: https://thestatsninja.com/2019/02/19/how-to-navigate-confidence-intervals-with-confidence/\n\n\n\n\n\nNarrower intervals are more precise but less reliable, while wider intervals are more reliable but less precise. How can we get best of both worlds â€“ high precision and high reliability/accuracy, meaning short interval with high level of confidence? What we need is larger sample size, given that the sample quality is good. It is a quite easy statement, but sometimes itâ€™s hard to collect more samples.\n\n A Confidence Interval Is for a Parameter \nA confidence interval is for a parameter, NOT a statistic. Remember, a confidence interval is a way of doing estimation for a unknown parameter. For example, we use the sample mean to form a confidence interval for the population mean.\nWe NEVER say â€œThe confidence interval of the sample mean, \\(\\overline{X}\\), is â€¦.â€ We SAY â€œThe confidence interval for the true population mean \\(\\mu\\), is â€¦â€\nIn general, a confidence interval for \\(\\mu\\) has the form\n\n\\(\\large \\overline{x} \\pm m = (\\overline{x} - m, \\overline{x} + m)\\)\n\nThe \\(m\\) is called the margin of error. It controls the width of the interval \\(2m\\). The CI is centered at the sample mean, and \\(\\overline{x} - m\\) is the lower bound and \\(\\overline{x} + m\\) is the upper bound of the confidence interval. The point estimate, \\(\\overline{x}\\), and margin of error, \\(m\\), can be obtained from known quantities and our data once sampled.\n\n \\((1 - \\alpha)100\\%\\) Confidence Intervals \nFormally, for \\(0 \\le \\alpha \\le 1\\), we define the confidence level \\(1-\\alpha\\) as the proportion of times that the CI contains the population parameter, assuming that the estimation process is repeated a large number of times.\nThe confidence level can be any number between zero and one. Common choices for the confidence level include 90% \\((\\alpha = 0.10)\\), 95% \\((\\alpha = 0.05)\\) and 99% \\((\\alpha = 0.01)\\). Keep in mind that confidence level tells us the reliability of the interval. Because precision and reliability have a trade-off relationship, a CI with very high confidence level (high reliability) will have less precision, i.e., larger margin of error and with width of the interval. 95% is the most common level because it has a good balance between precision (width of the CI) and reliability (confidence level).\n\n\n High reliability and Low precision: I am 100% confident that the mean height of Marquette students is between 3â€™0â€ and 8â€™0â€. \n\nDuhâ€¦ðŸ¤·\n\n\n\n Low reliability and High precision: I am 20% confident that mean height of Marquette students is between 5â€™6â€ and 5â€™7â€. \n\nThis is far from the truthâ€¦ ðŸ™…\n\n\n\n\n \\(95\\%\\) Confidence Intervals for \\(\\mu\\) \nWeâ€™ve learned the general form of a confidence interval for \\(\\mu\\) and defined the confidence level. We now formally derive the form of the \\((1-\\alpha)100\\%\\) confidence interval for \\(\\mu\\). For simplicity, here we assume \\(\\sigma\\) is known to us when the interval is constructed. A confidence interval can be derived from the sampling distribution of the point estimator. Such approach is called the distribution-based approach. A confidence interval can also be derived using simulation, and such approach is called simulation-based approach, bootstraping method for example. This chapter we build a CI based on the sampling distribution of \\(\\overline{X}\\). We discuss bootstraping in ChapterÂ 14.\n\nSuppose we want to obtain the \\(95\\%\\) confidence interval for \\(\\mu\\). So \\(\\alpha = 0.05\\). We start with the sampling distribution of \\(\\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\) shown in FigureÂ 13.4. The sampling distribution tells us that the realized value \\(\\overline{x}\\) will be within 1.96 SDs of the population mean, \\(\\mu\\), \\(95\\%\\) of the time. In other words,\n\\[P\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + 1.96\\frac{\\sigma}{\\sqrt{n}} \\right) = 0.95\\]\nHere the \\(z\\)-score of 1.96 is the 97.5% percentile of the standard normal distribution and -1.96 is the 2.5% percentile. The \\(z\\)-score 1.96 is associated with 2.5% area to the right and is called a critical value denoted as \\(z_{0.025} = z_{\\alpha/2}\\) . The \\(z\\)-score -1.96 is associated with 2.5% area to the left, and it happens to be the negative value of \\(z_{0.025}\\) because of the symmetry of normal distribution.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 13.4: Sampling distribution of the sample mean with 95% probability in the middle.\n\n\n\n\n\n\n\n\n\nWe learned that \\[P\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + 1.96\\frac{\\sigma}{\\sqrt{n}} \\right) = 0.95.\\] The probability that the variable \\(\\overline{X}\\) is in the interval \\(\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}}, \\mu+1.96\\frac{\\sigma}{\\sqrt{n}} \\right)\\) is 95%. But is the interval \\(\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}}, \\mu+1.96\\frac{\\sigma}{\\sqrt{n}} \\right)\\) our confidence interval?\nThe answer is No âŒ! Remember that we donâ€™t know \\(\\mu\\) and we are estimating it. The interval cannot be determined because it involves the unknown quantity \\(\\mu\\). But donâ€™t be too disappointed. We are almost there.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can arrange the inequality in the probability so that \\(\\mu\\) is in the middle and the probability remains unchanged.\n\n\\[ \\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} \\iff \\mu < \\overline{X} + 1.96\\frac{\\sigma}{\\sqrt{n}}\\]\n\\[ \\overline{X}  < \\mu+ 1.96\\frac{\\sigma}{\\sqrt{n}} < \\iff \\overline{X} - 1.96\\frac{\\sigma}{\\sqrt{n}} < \\mu\\]\n\\[\\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + 1.96\\frac{\\sigma}{\\sqrt{n}} \\iff \\overline{X}-1.96\\frac{\\sigma}{\\sqrt{n}} < \\mu < \\overline{X} + 1.96\\frac{\\sigma}{\\sqrt{n}}\\]\n\n\\[\\small \\begin{align} P\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + 1.96\\frac{\\sigma}{\\sqrt{n}} \\right) =\nP\\left( \\boxed{\\overline{X}-1.96\\frac{\\sigma}{\\sqrt{n}} < \\mu < \\overline{X} + 1.96\\frac{\\sigma}{\\sqrt{n}}} \\right) = 0.95\n\\end{align}\\]\nWe are done!  With sample data of size \\(n\\), \\(\\left(\\overline{x}-1.96\\frac{\\sigma}{\\sqrt{n}}, \\overline{x} + 1.96\\frac{\\sigma}{\\sqrt{n}}\\right)\\) is our \\(95\\%\\) CI for \\(\\mu\\).  Note that if \\(\\sigma\\) is known to us, the interval can be computed from our data because we know the sample size, and we can get the sample mean. The margin of error \\(m = 1.96\\frac{\\sigma}{\\sqrt{n}}\\)."
  },
  {
    "objectID": "infer-ci.html#confidence-intervals-for-mu-when-sigma-is-known",
    "href": "infer-ci.html#confidence-intervals-for-mu-when-sigma-is-known",
    "title": "13Â  Point and Interval Estimation",
    "section": "\n13.3 Confidence Intervals for \\(\\mu\\) When \\(\\sigma\\) is Known",
    "text": "13.3 Confidence Intervals for \\(\\mu\\) When \\(\\sigma\\) is Known\nWe just obtained the 95% confident interval for \\(\\mu\\). How about the general \\((1-\\alpha)100%\\) confident interval for \\(\\mu\\) (when \\(\\sigma\\) is known)? We first introduce the requirements for constructing the interval, then provide the interval formula.\nThe requirements for estimating \\(\\mu\\) when \\(\\sigma\\) is known include\n\nðŸ‘‰ The sample should be a random sample, such that all data \\(X_i\\) are drawn from the same population and \\(X_i\\) and \\(X_j\\) are independent. In fact,  any methods in this course are based on the assumption of a random sample \n\nðŸ‘‰ The population standard deviation, \\(\\sigma\\), is known.\nðŸ‘‰ The population is either normally distributed, \\(n > 30\\) or both, i.e., \\(X_i \\sim N(\\mu, \\sigma^2)\\).  The sample size \\(n > 30\\) allows the central limit theorem to be applied and hence normality is satisfied. \n\n\nThe general \\((1-\\alpha)100\\%\\) confidence interval for \\(\\mu\\) can be borrowed from the \\(95\\%\\) confidence interval for \\(\\mu\\), \\(\\left(\\overline{x}-z_{0.025}\\frac{\\sigma}{\\sqrt{n}}, \\overline{x} + z_{0.025}\\frac{\\sigma}{\\sqrt{n}}\\right)\\). The 95% confidence level means \\(\\alpha = 0.05\\). For the general \\((1-\\alpha)100\\%\\) confidence interval, we just replace \\(z_{0.025}\\) with \\(z_{\\alpha/2}\\) for any \\(\\alpha\\) between zero and one. Therefore, the general \\((1-\\alpha)100\\%\\) confidence interval for \\(\\mu\\) is\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo sum up, we provide procedures for constructing a confidence interval for \\(\\mu\\) when \\(\\sigma\\) is known:\n\nCheck that the requirements are satisfied.\nDecide \\(\\alpha\\) or the confidence level \\((1 - \\alpha)\\).\nFind the critical value, \\(z_{\\alpha/2}\\).\nEvaluate margin of error, \\(m = z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\).\nConstruct the \\((1 - \\alpha)100\\%\\) CI for \\(\\mu\\) using the sample mean, \\(\\overline{x}\\), and margin of error, \\(m\\):\n\n\n \\[\\boxed{\\overline{x} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\text{  or  } \\left( \\overline{x} -z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\, \\overline{x} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\right)}\\]\n\n\n Example \n\n\nSuppose we want to know the mean systolic blood pressure (SBP) of a population. Assume that the population distribution is normal and has a standard deviation of 5 mmHg. We have a random sample of 16 subjects from this population with a mean of 121.5 mmHg. Estimate the mean SBP with a 95% confidence interval.\n\n\n\n\n\n\n\n\n\n\n\nWe construct the confidence interval step by step using the procedure.\n\nRequirements:\n\n Normality is assumed, \\(\\sigma = 5\\) is known and a random sample is collected.\n\n\nDecide \\(\\alpha\\):\n\n \\(\\alpha = 0.05\\) \n\n\nFind the critical value \\(z_{\\alpha/2}\\):\n\n \\(z_{\\alpha/2} = z_{0.025} = 1.96\\) \n\n\nEvaluate margin of error \\(m = z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\):\n\n \\(m = (1.96) \\frac{5}{\\sqrt{16}} = 2.45\\) \n\n\nConstruct the \\((1 - \\alpha)100\\%\\) CI:\n\n The 95% CI for the mean SBP is \\(\\overline{x} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} = (121.5 -2.45, 121.5 + 2.45) = (119.05, 123.95)\\) \n\n\n\nBelow is a demonstration of how to find the 95% CI for SBP using R.\n\n## save all information we have\nalpha <- 0.05\nn <- 16\nx_bar <- 121.5\nsig <- 5\n\n## 95% CI\n## z-critical value\n(cri_z <- qnorm(p = alpha / 2, lower.tail = FALSE))  \n\n[1] 1.959964\n\n## margin of error\n(m_z <- cri_z * (sig / sqrt(n)))  \n\n[1] 2.449955\n\n## 95% CI for mu when sigma is known\nx_bar + c(-1, 1) * m_z  \n\n[1] 119.05 123.95\n\n\n\n\n\n\n\n\nConstruct a 99% CI for the mean SBP. Do you expect it to have a wider or narrower interval than the 95% CI? Why?\n\n\n\n\n\n\n Interpreting the Confidence Interval\nWe have known how to construct a confidence interval. But what on earth is that? How do we interpret the interval correctly? This is pretty important because the interval is usually misinterpreted and inappropriately used in statistical analysis. Donâ€™t blame yourself if you find it hard to understand the meaning. The confidence interval concept is not intuitive, and it does not really answer what we care about the unknown parameter. The confidence interval is a concept in the classical or frequestist point of view. Another way of interval estimation is to use the so called credible interval that uses Bayesian philosophy. We will discuss their difference in detail in ChapterÂ 20.\nBack to a 95% confidence interval. The following statements and interpretations are wrong. Please do not interpret the interval this way.\n\nWRONG âŒ â€œThere is a 95% chance/probability that the true population mean will fall between 119.1 mm and 123.9 mm.â€\nWRONG âŒ â€œThe probability that the true population mean falls between 119.1 mm and 123.9 mm is 95%.â€\n\nAlthough those statements are often what we want, they are completely wrong. Letâ€™s learn why. The sample mean is a random variable with a sampling distribution, so it makes sense to compute a probability of it being in some interval. The population mean is unknown and FIXED, so we cannot assign or compute any probability of it. If we were using Bayesian inference ChapterÂ 20, a different inference method, we could compute a probability associated with \\(\\mu\\) because in Bayesian statistics \\(\\mu\\) is treated as a random variable.\nSo how do we correctly interpret a confidence interval? Here is the answer.\n â€œWe are 95% confident that the mean SBP lies between 119.1 mm and 123.9 mm.â€ \nBut still what does â€œ95% confidentâ€ really mean? This means if we were able to collect our data many times and build the corresponding CIs, we would expect that about 95% of those intervals would contain the true population parameter, which, in this case, is the mean systolic blood pressure.\nRemember that \\(\\overline{x}\\) varies from sample to sample, so does its corresponding CI because the CI is a function of \\(\\overline{X}\\) given \\(n\\) and \\(\\sigma\\). This idea is shown in FigureÂ 13.5. Here we do a simulation assuming \\(\\mu\\) is known at 120, and \\(\\sigma = 5\\). Also, assume we were able to repeatedly collect our sample of the same size \\(n = 16\\). Here 100 data sets are generated, and for each data set, the sample mean and its corresponding 95% CI are computed. Since the confidence level is 95%, 95% of those intervals would contain the true population parameter, 120 in this example. The 36th, 45th, 52nd, 82nd, and 99th data sets have the interval not capturing the true parameter.\n\n\n\n\nFigureÂ 13.5: Illustration of 100 95% confidence intervals.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease keep the following ideas in mind.\n\nA 95% CI does not mean that if 100 data sets are collected, there will be exactly 95 intervals capturing \\(\\mu\\). It is a long-term sampling idea.\nWe never know with certainty that 95% of the intervals, or any single interval for that matter, contains the true population parameter because again we never know what the true value of the parameter is.\nIn reality, we usually have only one data set, and we are not able to collect more data. We have no idea of whether our 95% confidence interval capture the unknown parameter or not. We are only â€œ95% confidentâ€.\n\n\n\nThe procedure of generating 100 confidence intervals for \\(\\mu\\) when \\(\\sigma\\) is known is shown in the algorithm below.\n\n\nAlgorithm\nSimulation Result\nCode\n\n\n\n\nAlgorithm\n\nGenerate 100 sampled data of size \\(n\\): \\((x_1^1, x_2^1, \\dots, x_n^1), \\dots (x_1^{100}, x_2^{100}, \\dots, x_n^{100})\\), where \\(x_i^m \\sim N(\\mu, \\sigma^2)\\).\nObtain 100 sample means \\((\\overline{x}^1, \\dots, \\overline{x}^{100})\\).\nFor each \\(m = 1, 2, \\dots, 100\\), compute the corresponding confidence interval \\[\\left(\\overline{x}^m - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}, \\overline{x}^m + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmu <- 120; sig <- 5 \nal <- 0.05; M <- 100; n <- 16\n\nset.seed(2023)\nx_rep <- replicate(M, rnorm(n, mu, sig))\nxbar_rep <- apply(x_rep, 2, mean)\nE <- qnorm(p = 1 - al / 2) * sig / sqrt(n)\nci_lwr <- xbar_rep - E\nci_upr <- xbar_rep + E\n\nplot(NULL, xlim = range(c(ci_lwr, ci_upr)), ylim = c(0, 100), \n     xlab = \"95% CI\", ylab = \"Sample\", las = 1)\nmu_out <- (mu < ci_lwr | mu > ci_upr)\nsegments(x0 = ci_lwr, y0 = 1:M, x1 = ci_upr, col = \"navy\", lwd = 2)\nsegments(x0 = ci_lwr[mu_out], y0 = (1:M)[mu_out], x1 = ci_upr[mu_out], \n         col = 2, lwd = 2)\nabline(v = mu, col = \"#FFCC00\", lwd = 2)"
  },
  {
    "objectID": "infer-ci.html#confidence-intervals-for-mu-when-sigma-is-unknown",
    "href": "infer-ci.html#confidence-intervals-for-mu-when-sigma-is-unknown",
    "title": "13Â  Point and Interval Estimation",
    "section": "\n13.4 Confidence Intervals for \\(\\mu\\) When \\(\\sigma\\) is Unknown",
    "text": "13.4 Confidence Intervals for \\(\\mu\\) When \\(\\sigma\\) is Unknown\nWe complete the discussion of confidence intervals for \\(\\mu\\) when \\(\\sigma\\) is known. Do you see anything unreasonable? Do you think that assuming \\(\\sigma^2\\) is known is reasonable? In fact, the population variance is calculated as \\(\\sigma^2 = \\frac{\\sum_{i=1}^{N}(x_i - \\mu)^2}{N}\\), where \\(N\\) is the population size. The formula involves \\(\\mu\\), the unknown parameter weâ€™d like to estimate. Itâ€™s rare that we donâ€™t know \\(\\mu\\) but know \\(\\sigma\\). What do we do if \\(\\sigma\\) is unknown?\nWhen \\(\\sigma\\) is unknown to us, we cannot use normal distribution anymore. Instead, we use the Studentâ€™s t distribution (or \\(t\\)-distribution) to construct a confidence interval for \\(\\mu\\) when \\(\\sigma\\) is unknown. To construct these confidence intervals we still need\n\nA random sample\nA population that is normally distributed and/or \\(n > 30\\).\n\nThe confidence interval when \\(\\sigma\\) is known includes \\(\\sigma\\) in the formula. When \\(\\sigma\\) is unknown, we cannot use the formula and need to find \\(\\sigma\\)â€™s surrogate.\n\n\n\n\n\n\nWhat is a natural estimator for the unknown \\(\\sigma\\)?\n\n\n\n\n\n\nWhen \\(\\sigma\\) is unknown, we use the sample standard deviation, \\(S = \\sqrt{\\frac{\\sum_{i=1}^{n}(X_i - \\overline{X})^2}{n-1}}\\), instead when constructing the CI.\n\n Studentâ€™s t Distribution \nIf the population is normally distributed or \\(n > 30\\), we know \\(\\overline{X}\\) is exactly or approximately \\(N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\\). Therefore \\(Z = \\frac{\\overline{X} - \\mu}{\\color{red}\\sigma/\\sqrt{n}} \\sim N(0, 1)\\). Now if \\(\\sigma\\) is replaced with its surrogate \\(S\\), then the new random variable say \\(T\\) will be studentâ€™s t distributed with the degrees of freedom (df) \\(n-1\\):\n \\[T = \\frac{\\overline{X} - \\mu}{\\color{red}S/\\sqrt{n}} \\sim t_{n-1}\\]  \nHere the degrees of freedom is the parameter of the studentâ€™s t distribution.\n Properties \nThe studentâ€™s t distribution, as shown in FigureÂ 13.6, looks pretty similar to the standard normal distribution, but they are different. Some of the properties of the studentâ€™s t distribution are listed below.\n\nFor any degrees of freedom, the studentâ€™s t distribution is symmetric about the mean 0 and bell-shaped like \\(N(0, 1)\\).\nFor any degrees of freedom, the studentâ€™s t distribution has more variability than \\(N(0, 1)\\), meaning that the distribution has heavier tails and lower peak.\nThe the studentâ€™s t distribution has less variability for larger degrees of freedom (sample size).\nAs \\(n \\rightarrow \\infty\\) \\((df \\rightarrow \\infty)\\), the studentâ€™s t distribution approaches \\(N(0, 1)\\).\n\n\n\n\n\nFigureÂ 13.6: Student t distributions with various degrees of freedom.\n\n\n\n\n Critical Values of \\(t_{\\alpha/2, n-1}\\) \nIn the CI formula with known \\(\\sigma\\), we use the critical value \\(z_{\\alpha/2}\\), the standard normal value so that \\(P(Z > z_{\\alpha/2}) = \\alpha/2\\). When \\(\\sigma\\) is unknown, we use \\(t_{\\alpha/2, n - 1}\\) as the critical value, instead of \\(z_{\\alpha/2}\\). Notice that the standard normal has nothing to do with \\(\\mu\\) and \\(\\sigma\\) of a general \\(N(\\mu, \\sigma^2)\\) distribution. 1 Therefore no parameter is attached to \\(z_{\\alpha/2}\\). However, the \\(t\\) critical value \\(t_{\\alpha/2, n - 1}\\) changes with the degrees of freedom \\(n - 1\\). With the same logic, the critical value \\(t_{\\alpha/2, n - 1}\\) is a Studentâ€™s t value with degrees of freedom \\(n - 1\\) so that \\(P(T_{n-1} > t_{\\alpha/2, n - 1}) = \\alpha/2\\) as shown in FigureÂ 13.7.\n\n\n\n\nFigureÂ 13.7: Illustration of critical value for Student t distribution.\n\n\n\n\n\n\n\n\n\n\nWith the same \\(\\alpha\\), is \\(t_{\\alpha, n-1}\\) or \\(z_{\\alpha}\\) larger?\n\n\n\n\n\n\nYou should be able to answer this question based on the fact that for any degrees of freedom, the studentâ€™s t distribution has more variability than \\(N(0, 1)\\), or heavier tails. The heavier tail forces \\(t_{\\alpha/2, n-1}\\) to be more extreme than \\(z_{\\alpha/2}\\). FigureÂ 13.8 illustrates this fact. The red \\(t_{df = 2}\\) distribution has heavier tails than the black standard normal distribution.\n\n\n\n\nFigureÂ 13.8: z and t critical values.\n\n\n\n\nThe table below shows \\(z\\) and \\(t\\) critical values at confidence level 90%, 95% and 99%. The \\(t\\) values are getting closer to the \\(z\\) values as the degree of freedom increases. When the degree of freedom goes to infinity, the \\(t\\) values converge to \\(z\\) values.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLevel\nt df = 5\nt df = 15\nt df = 30\nt df = 1000\nt df = inf\nz\n\n\n\n90%\n2.02\n1.75\n1.70\n1.65\n1.64\n1.64\n\n\n95%\n2.57\n2.13\n2.04\n1.96\n1.96\n1.96\n\n\n99%\n4.03\n2.95\n2.75\n2.58\n2.58\n2.58\n\n\n\n\n\n\n \\((1-\\alpha)100\\%\\) Confidence Intervals for \\(\\mu\\) When \\(\\sigma\\) is Unknown \nWe have been equipped with everything we need for constructing \\((1-\\alpha)100\\%\\) confidence interval for \\(\\mu\\) when \\(\\sigma\\) is unknown. The interval is  \\[\\left(\\overline{x} - t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}, \\overline{x} + t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}\\right)\\] \nThe interval form is the same as before. We have the sample mean plus and minus the margin of error. Comparing to the interval with known \\(\\sigma\\), the difference is that \\(z_{\\alpha/2}\\) is replaced with \\(t_{\\alpha/2, n-1}\\), and \\(\\sigma\\) is replaced with \\(s\\).\nGiven the same confidence level \\(1-\\alpha\\), \\(t_{\\alpha/2, n-1} > z_{\\alpha/2}\\), leading to a wider interval if \\(s\\) is not too smaller than the true \\(\\sigma\\). The intuition is that we are more uncertain when doing inference about \\(\\mu\\) because we donâ€™t have information about both \\(\\mu\\) and \\(\\sigma\\), and replacing \\(\\sigma\\) with \\(s\\) adds additional uncertainty.\n\n\n\n\n Computation in R \nBack to the systolic blood pressure (SBP) example. We have \\(n=16\\) and \\(\\overline{x} = 121.5\\). Estimate the mean SBP with a 95% confidence interval with unknown \\(\\sigma\\) and \\(s = 5\\). The code for the \\(t\\) interval is pretty similar to the \\(z\\) interval. The main difference is that we are gonna use qt() to find a quantile or critical value from the Studentâ€™s t distribution. In the function, the first argument is still the given probability, then we must specify the degrees of freedom, otherwise R cannot determine which \\(t\\)-distribution is being considered, and will render an error message.\n\nalpha <- 0.05\nn <- 16\nx_bar <- 121.5\ns <- 5  ## sigma is unknown and s = 5\n\n## t-critical value\n(cri_t <- qt(p = alpha / 2, df = n - 1, lower.tail = FALSE)) \n\n[1] 2.13145\n\n## margin of error\n(m_t <- cri_t * (s / sqrt(n)))  \n\n[1] 2.664312\n\n## 95% CI for mu when sigma is unknown\nx_bar + c(-1, 1) * m_t  \n\n[1] 118.8357 124.1643\n\n\n\\(z_{0.025} = 1.96 < t_{0.025, 15} = 2.13\\). The interval is wider with \\(s = 5\\)."
  },
  {
    "objectID": "infer-ci.html#summary",
    "href": "infer-ci.html#summary",
    "title": "13Â  Point and Interval Estimation",
    "section": "\n13.5 Summary",
    "text": "13.5 Summary\nTo conclude this chapter, a table that summarizes the confidence interval for \\(\\mu\\) is provided.\n\n\n\n\n\n\n\n\nNumerical Data, \\(\\sigma\\) known\nNumerical Data, \\(\\sigma\\) unknown\n\n\n\nParameter of Interest\nPopulation Mean \\(\\mu\\)\n\nPopulation Mean \\(\\mu\\)\n\n\n\nConfidence Interval\n\\(\\bar{x} \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\)\n\\(\\bar{x} \\pm t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}\\)\n\n\n\nRemember to check if the population is normally distributed and/or \\(n>30\\). What if the population is not normal and \\(n \\le 30\\)? We could use a simulation-based approach, for example bootstrapping discussed in ChapterÂ 14."
  },
  {
    "objectID": "infer-ci.html#exercises",
    "href": "infer-ci.html#exercises",
    "title": "13Â  Point and Interval Estimation",
    "section": "\n13.6 Exercises",
    "text": "13.6 Exercises\n\n\nHere are summary statistics for randomly selected weights of newborn boys: \\(n =207\\), \\(\\bar{x} = 30.2\\)hg (1hg = 100 grams), \\(s = 7.3\\)hg.\n\nCompute a 95% confidence interval for \\(\\mu\\), the mean weight of newborn boys.\nIs the result in (a) very different from the 95% confidence interval if \\(\\sigma = 7.3\\)?\n\n\nA 95% confidence interval for a population mean \\(\\mu\\) is given as (18.635, 21.125). This confidence interval is based on a simple random sample of 32 observations. Calculate the sample mean and standard deviation. Assume that all conditions necessary for inference are satisfied. Use the t-distribution in any calculations.\nA market researcher wants to evaluate car insurance savings at a competing company. Based on past studies he is assuming that the standard deviation of savings is $95. He wants to collect data such that he can get a margin of error of no more than $12 at a 95% confidence level. How large of a sample should he collect?\n\nThe 95% confidence interval for the mean rent of one bedroom apartments in Chicago was calculated as ($2400, $3200).\n\nInterpret the meaning of the 95% interval.\nFind the sample mean rent from the interval."
  },
  {
    "objectID": "infer-bt.html#the-r-user-interface",
    "href": "infer-bt.html#the-r-user-interface",
    "title": "14Â  Bootstrapping",
    "section": "14.1 The R User Interface",
    "text": "14.1 The R User Interface"
  },
  {
    "objectID": "infer-ht.html#introduction",
    "href": "infer-ht.html#introduction",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.1 Introduction",
    "text": "15.1 Introduction\n What is Hypothesis Testing? \nIn statistics, a hypothesis is a claim or statement about a property of a population, often the value of a population distribution parameter. For example,\n\n The mean body temperature of humans is less than \\(98.6^{\\circ}\\) F.  Here the mean body temperature is a property or characteristic of target population human beings. We can turn the verbal claim into a brief mathematical expression \\(\\mu < 98.6\\).\n Marquette studentsâ€™ IQ scores has standard deviation equal to 15.  The IQ score standard deviation is a characteristic of the population Marquette students. Mathematically, we can write the claim as \\(\\sigma = 15\\).\n\nYou can see that we usually focus on claims about a population distribution parameter. \nThe null hypothesis, denoted \\(H_0\\), is a statement that the value of a parameter is equal to some claim value, or the negation of the alternative hypothesis that will be discussed in a minute. Often \\(H_0\\) represents a skeptical perspective or a claim to be tested, or the current status of the parameter. For example, the claim â€œthe percentage of Marquette female students loving Japanese food is equal to 80%â€ is a \\(H_0\\) claim because of the key word â€œequalâ€. Usually we are not very convinced that the \\(H_0\\) claim is true, and in our analysis we want to test the claim, and see whether the evidence and information we collect is strong enough to make a conclusion that the percentage is not equal to 80%.\nThe alternative hypothesis, denoted \\(H_1\\) or \\(H_a\\), is a claim that the parameter is less than, greater than or not equal to some value. It is usually our research hypothesis of some new scientific theory or finding. If we think the percentage of Marquette female students loving Japanese food is greater than 80%, this hypothesis is the \\(H_1\\) claim. If after a formal testing procedure, we conclude that the percentage is greater than 80%, we sort of make a new research discovery that overturns the previous claim or status quo that the percentage is equal to 80%.\nLetâ€™s do one more exercise. Is the statement â€œOn average, Marquette students consume less than 3 drinks per week.â€ a \\(H_0\\) or \\(H_1\\) claim? Because of the key word â€œless thanâ€, it is a \\(H_1\\) claim.\n\n\n\n\n\nSo what is hypothesis testing? Hypothesis testing 1 is a procedure to decide whether or not to reject \\(H_0\\) based on how much evidence there is against \\(H_0\\). If the evidence is strong enough, we reject \\(H_0\\) in favor of \\(H_1\\).\n\n Example \nBefore we jump into the formal hypothesis testing procedure, letâ€™s talk about a criminal charge example. How a criminal is convicted is similar to the formal testing procedure.\n\n\nSuppose a person is charged with a crime, and a jury will decide whether the person is guilty or not. We all know the rule: Even though the person is charged with the crime, at the beginning of the trial, the accuse is assumed to be innocent until the jury declares otherwise. Only if overwhelming evidence of the personâ€™s guilt can be shown is the jury expected to declare the person guilty, otherwise the person is considered not guilty.\n\n\n\n\n\n\n\n\n\n\n\nIf we want to make a claim about whether the person is guilty or not, what are our \\(H_0\\) and \\(H_1\\)? Remember that the null hypothesis represents a skeptical perspective or a claim to be tested, or the current status of the parameter, so we have\n\n\n\\(H_0:\\) The person is  not guilty  ðŸ™‚\n\nThis is how we write a hypothesis: start with \\(H_0:\\) followed by the statement. Being not guilty is the default status quo of anyone, although the jury may doubt or be skeptical of the person being not guilty. The prosecutors and police detectives are trying their best the collect enough strong evidence to proof beyond a reasonable doubt to the jury. Therefore the alternative hypothesis is\n\n\n\\(H_1:\\) The person is  guilty  ðŸ˜Ÿ\n\nIn the example, the evidence could be  photos, videos, witnesses, fingerprints, DNA, and so on . How do we decide to keep \\(H_0\\) or to accept \\(H_1\\)? After all evidence including defense attorney and prosecutorâ€™s arguments are presented to the jury, the decision rule is the  juryâ€™s voting . Finally, to close the case, we need a conclusion that is the verdict  â€œguiltyâ€  or  â€œNot enough evidence to convictâ€ .\nPlease go through the entire criminal charge process again:\n\\(H_0\\) and \\(H_a\\) => Evidence => Decision rule => Conclusion\nThe process is quite similar to the formal procedure for a hypothesis testing."
  },
  {
    "objectID": "infer-ht.html#how-to-formally-do-a-statistical-hypothesis-testing",
    "href": "infer-ht.html#how-to-formally-do-a-statistical-hypothesis-testing",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.2 How to Formally Do a Statistical Hypothesis Testing",
    "text": "15.2 How to Formally Do a Statistical Hypothesis Testing\nThe entire hypothesis testing can be wrapped up in the following six steps. No worries if you donâ€™t have any idea of it. We will learn this step by step using a test for the population mean \\(\\mu\\).\n\nStep 0: Check Method Assumptions\nStep 1: Set the \\(H_0\\) and \\(H_a\\) in Symbolic Form from a Claim\nStep 2: Set the Significance Level \\(\\alpha\\)\nStep 3: Calculate the Test Statistic (Evidence)\n\n\n\nDecision Rule I: Critical Value Method\n\n Step 4-c: Find the Critical Value \n Step 5-c: Draw a Conclusion Using Critical Value Method \n\n\nDecision Rule II: P-Value Method\n\n Step 4-p: Find the P-Value \n Step 5-p: Draw a Conclusion Using P-Value Method \n\n\n\n\nStep 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim\n\nLetâ€™s look at this example: Is the New Treatment Effective?\n\n\nA population of patients with hypertension is normal and has mean blood pressure (BP) of 150. After 6 months of treatment, the BP of 25 patients from this population was recorded. The sample mean BP is \\(\\overline{x} = 147.2\\) and the sample standard deviation is \\(s = 5.5\\).\n\n\n\n\n\n\nSource: https://unsplash.com/photos/i1iqQRLULlg\n\n\n\n\n\n\n\nOur goal is to determine whether a new treatment is effective in reducing BP. Letâ€™s learn the testing procedure step by step using this example.\n\n\n Step 0: Check Method Assumptions \nAny statistical method is based on some assumptions. To use the method, and analyze our data appropriately, we have to make sure that the assumptions are satisfied. In this book, most of the distribution-based methods require\n\nRandom sample\nThe population is normally distributed and/or the sample size \\(n > 30\\).\n\n\n\n\n\nSource: https://www.pinterest.ph/pin/633387417082544/\n\n\n\n\n\n Example Step 0: Check Method Assumptions \n\nFrom the question description,  A population of hypertension group is normal .\n\n\n Step 1: Set the \\(H_0\\) and \\(H_1\\) from a Claim \nThe first step of testing is to understand the \\(H_0\\) and \\(H_1\\) claims, and express them using mathematically using population parameters. The followings provdie three examples.\n\nðŸ§‘â€ðŸ« The mean IQ score of statistics professors is higher than 120.\n\n \\(\\begin{align}&H_0: \\mu \\le 120 \\\\ &H_1: \\mu > 120 \\end{align}\\) \n\n\nðŸ’µ The mean starting salary for Marquette graduates who didnâ€™t take MATH 4720 is less than $60,000.\n\n \\(\\begin{align} &H_0: \\mu \\ge 60000 \\\\ &H_1: \\mu < 60000 \\end{align}\\) \n\n\nðŸ“º The mean time between uses of a TV remote control by males during commercials equals 5 sec.Â \n\n \\(\\begin{align} &H_0: \\mu = 5 \\\\ &H_1: \\mu \\ne 5 \\end{align}\\) \n\n\n\nKeep in mind that the equality sign is always put in \\(H_0\\), and \\(H_0\\) and \\(H_1\\) are mutually exclusive. Also, the claims are for population parameters, not sample statistics. We are not sure the value of the parameter being tested, but we want to collect evidence, and see which claim about the parameter is supported by the evidence.\n Example Step 1: Set the \\(H_0\\) and \\(H_1\\) from a Claim \nThe claim that the new treatment is effective in reducing BP means the mean BP is less than 150, which is an \\(H_1\\) claim. So we can write our \\(H_0\\) and \\(H_1\\) as\n \\(\\small \\begin{align} &H_0: \\mu = 150 \\\\ &H_1: \\mu < 150 \\end{align}\\) \nwhere \\(\\mu\\) is the mean blood pressure.\n\n Step 2: Set the Significance Level \\(\\alpha\\) \nNext, we set the significance level \\(\\alpha\\) that determines how rare or unlikely our evidence must be in order to represent sufficient evidence against \\(H_0\\). It tells us how strong the collected evidence must be in order to overturn the current claim. An \\(\\alpha\\) level of 0.05 implies that evidence occurring with probability lower than 5% will be considered sufficient evidence to reject \\(H_0\\). Mathematically, \\[\\alpha = P(\\text{Reject } H_0 \\mid H_0 \\text{ is true})\\] As a result, \\(\\alpha = 0.05\\) means that we incorrectly reject \\(H_0\\) 5 out of every 100 times we collect a sample and run the test.\nHere is the idea. When we want to see if what we care about (the population parameter) is not as described as in the null hypothesis \\(H_0\\), we first assume or believe \\(H_0\\) is right, then based on this, we see if there is sufficient and strong evidence to conclude that it is probably not the case, and find the alternative hypothesis more reasonable.\nLetâ€™s explain \\(\\alpha\\) by an example. Suppose we would like to test the claim that â€œThe mean IQ of statistics professors is greater than 120.â€ Or in short \\(H_0: \\mu = 120\\) vs.Â \\(H_1: \\mu > 120\\). With large sample size, we can assume \\(\\overline{X}\\) follows a normal distribution. Now, to test whether the mean IQ is greater than 120, we need to first treat the mean not being greater than 120 unless later we have sufficient evidence to say it is greater than 120. In particular, we need to do the test and analysis on the basis that the mean is under \\(H_0\\). That is, we first assume the mean is 120, or \\(\\mu = 120\\), then see if the assumption really makes sense.\nBecause \\(\\overline{X}\\) is normal, we do the test under the assumption that \\(\\overline{X} \\sim N(120, \\sigma^2)\\) for some \\(\\sigma^2\\), say \\(9\\). (Letâ€™s focus on \\(\\mu\\) and ignore \\(\\sigma\\) at this moment). If \\(\\overline{X}\\) has mean 120, and from our sample data we got the sample mean \\(\\overline{x} = 121\\), do you think the claim \\(H_0: \\mu = 120\\) make sense? How about you got \\(\\overline{x} = 127\\)? Now \\(\\alpha\\) comes into play. Let me ask you a question. What is the threshold or value of the sample mean \\(\\overline{x}\\) that you think it is too large to believe that \\(H_0: \\mu = 120\\) is a reasonable assumption or data generating mechanism? What is the threshold that makes you start to believe that \\(H_1: \\mu > 120\\) makes more sense than \\(H_0: \\mu = 120\\)? The significance level \\(\\alpha\\) is such threshold value. With \\(\\alpha\\) being specified, we know what is the corresponding sample mean threshold \\(\\overline{x}^*\\), which is the one such that \\(P(\\overline{X} > \\overline{x}^*) = \\alpha\\).\nFigureÂ 15.1 illustrates the significance level \\(\\alpha\\). Once we decide \\(\\alpha\\), we determines how rare or unlikely our sample mean \\(\\overline{x}\\) must be in order to represent sufficient evidence against \\(H_0: \\mu = 120\\). In this example, if our \\(\\overline{x}\\) is greater than 125, we would think the evidence is strong enough to conclude that \\(\\mu = 120\\) is not so reasonable because the chance of such value happening is no larger than \\(\\alpha\\). We instead think \\(H_1: \\mu > 120\\) makes more sense.\n\n\n\n\n\n\nFigureÂ 15.1: Illustration of significance level, alpha.\n\n\n\n\n\n\nThe entire rationale is the rare event rule.\n\n\n\n\n\n\nRare Event Rule\n\n\n\nIf, under a given assumption, the probability of a particular observed event is exceptionally small, we conclude that the assumption is probably not correct.\n\n\n\n\nThe level \\(\\alpha\\) is related to the \\(\\alpha\\) used in confidence intervals for defining a â€œcritical valueâ€.\n Example Step 2: Set the Significance Level \\(\\alpha\\) \nThere is no \\(\\alpha\\) mentioned in the question description. Usually \\(\\alpha\\) is set by researchers themselves. Letâ€™s set \\(\\alpha= 0.05\\). This means we are asking, â€œIs there a sufficient evidence at \\(\\alpha= 0.05\\) that the new treatment is effective?â€\n\n Step 3: Calculate the Test Statistic \nSetting \\(\\alpha\\) is kind of setting the threshold for determining whether our collected evidence is sufficient or strong enough or not. In this step, we are collecting our evidence. The evidence is collected from the information we have, which is the sample data. Sample data is the only source we have for the inference about the unknown parameter. So to do a test about the parameter, or decide whether a statement about the parameter makes sense, we let the data and evidence speak up.\nThe evidence used in the hypothesis testing is called test statistic: a sample statistic value used in making a decision about the \\(H_0\\). Suppose  the test we are interested is \\(H_0: \\mu = \\mu_0\\) and \\(\\quad H_1: \\mu < \\mu_0\\)  where \\(\\mu_0\\) is some population mean value that could be 150 lbs, 175 cm, 50 ounces, etc. When computing a test statistic, we assume \\(H_0\\) is true. Remember, we are trying to see if there is any strong evidence that is against \\(H_0\\). We should do our analysis in the world of \\(H_0\\) or the status quo. If the evidence is not sufficient, we stay in our current situation.\nWhen \\(\\sigma\\) is known, the test statistic for testings about \\(\\mu\\) is\n\\[\\boxed{ z_{test} = \\frac{\\overline{x} - \\color{blue}{\\mu_0}}{\\sigma/\\sqrt{n}} }\\]\nWhen \\(\\sigma\\) is unknown, the test statistic for testings about \\(\\mu\\) is\n\\[\\boxed{ t_{test} = \\frac{\\overline{x} - \\color{blue}{\\mu_0}}{s/\\sqrt{n}} }\\]\nFamiliar with them? Those are \\(z\\) score and \\(t\\) score. Those are the sample statistics used for testing. When we calculate the test statistics, we need the value of \\(\\mu\\). What value we should use? You are right if you use the value assumed in \\(H_0\\)! The test statistics are the evidence we use in testing. The evidence is collected under the assumption that \\(\\mu = \\mu_0\\). We collect any evidence to prove that a suspect committed a crime under the assumption that he is innocent, right? We shouldnâ€™t look at any person through colored spectacles, or frame anyone by treating someone as criminal, then make up a fake story for what heâ€™s never done.\n Example Step 3: Calculate the Test Statistic \nSince we donâ€™t know the true \\(\\sigma\\), and only know \\(s\\), we use \\(t\\) distribution and the test statistic is  \\[\\small t_{test} = \\frac{\\overline{x} - \\mu_0}{s/\\sqrt{n}} =  \\frac{147.2 - 150}{5.5/\\sqrt{25}} = -2.55.\\]  So if the true mean blood pressure is 150, our test statistic or evidence is about 2.55 standard deviations below the mean. Is this number too weird or uncommon to believe that the mean blood pressure is really 150? We need a decision rule, and that is what we are going to learn in the step 4.\n\n Step 4-c: Find the Critical Value \nIn this step, we set the decision rule. There are two methods in testing, the critical-value method and the p-value method. The two methods are equivalent, leading to the same decision and conclusion. Letâ€™s first talk about the critical-value method.\nIn step 2, we set the \\(\\alpha\\), and in step 3, we collect the evidence. Now we need a way to decide whether the collected evidence is sufficient or not to reject the \\(H_0\\) claim. The critical value(s) is a value determined by the significance level \\(\\alpha\\) that separates the rejection region or critical region, where we reject \\(H_0\\), from the values of the test statistic that do not lead to the rejection of \\(H_0\\).\n\nWhich critical value to be used depends on whether our test is a right-tailed, left-tailed or two-tailed. The right-tailed test, or right-sided test is the test with \\(H_1: \\mu > \\mu_0\\). When we are interested of \\(\\mu\\) is greater than some value, say \\(\\mu_0\\), in the sampling distribution, we will focus on the right hand side of the distribution, because the evidence, the test statistic calculated in the step 3, will usually be on the right hand side of the distribution, so is the critical value used in the decision rule. Similarly, The left-tailed test, or left-sided test is the test with \\(H_1: \\mu < \\mu_0\\). For a two-tailed or two-sided test, we have \\(H_1: \\mu \\ne \\mu_0\\). In this case, we wonder \\(\\mu\\) is larger or smaller than the assumed \\(\\mu_0\\). So we need to pay attention to both sides of the sampling distribution.\nFigureÂ 15.2 illustrates rejection regions for the different types of hypothesis tests. Letâ€™s assume \\(\\sigma\\) is known as the unknown \\(\\sigma\\) case is similar and we just replace the \\(z\\) score with the \\(t\\) score. Given the significance level \\(\\alpha\\), for a right-tailed test, the critical value is \\(z_{\\alpha}\\), the standard normal quantile so that \\(P(Z > z_{\\alpha}) = \\alpha\\), where \\(Z \\sim N(0, 1)\\). For a right-tailed test, the critical value is \\(-z_{\\alpha}\\), or in fact \\(z_{1-\\alpha}\\), the standard normal quantile so that \\(P(Z < -z_{\\alpha}) = \\alpha\\) or \\(P(Z > -z_{\\alpha}) = 1-\\alpha\\). When the test is a two-tailed test, there are two critical values, one at the right-hand side, the other at the left-hand side of the distribution. Here, we need to split \\(\\alpha\\) equally into \\(\\alpha/2\\), and the critical value at the right-hand side is \\(z_{\\alpha/2}\\) such that \\(P(Z > z_{\\alpha/2}) = \\alpha\\) and the critical value at the left-hand side is \\(-z_{\\alpha/2}\\) such that \\(P(Z < -z_{\\alpha/2}) = \\alpha/2\\). Note that by definition, \\(z_{\\alpha}\\) and \\(t_{\\alpha, n-1}\\) are always positive and on the right hand side of the distribution.\n\n\n\n\nFigureÂ 15.2: Rejection regions for the different types of hypothesis tests. Source: https://towardsdatascience.com/everything-you-need-to-know-about-hypothesis-testing-part-i-4de9abebbc8a\n\n\n\n\n\n\nThe following table is the summary of the critical values under different cases. When \\(\\sigma\\) is known, we use \\(z\\) scores, and when \\(\\sigma\\) is unknown, we use \\(t\\) scores.\n\n\n\n\n\n\n\n\nCondition Â  Â \n\nRight-tailed \\((H_1: \\mu > \\mu_0)\\)\n\n\nLeft-tailed \\((H_1: \\mu < \\mu_0)\\)\n\n\nTwo-tailed \\((H_1: \\mu \\ne \\mu_0)\\)\n\n\n\n\n\n\\(\\sigma\\) known\n\\(z_{\\alpha}\\)\n\\(-z_{\\alpha}\\)\n\n\\(-z_{\\alpha/2}\\) and \\(z_{\\alpha/2}\\)\n\n\n\n\n\\(\\sigma\\) unknown\n\\(t_{\\alpha, n-1}\\)\n\\(-t_{\\alpha, n-1}\\)\n\n\\(-t_{\\alpha/2, n-1}\\) and \\(t_{\\alpha/2, n-1}\\)\n\n\n\n\n Example Step 4-c: Find the Critical Value \nSince the test is a left-tailed test, and \\(\\sigma\\) is unknown and \\(n = 25\\), the critical value is \\(-t_{\\alpha, n-1}\\) that is  \\(\\small -t_{0.05, 25-1} = -t_{0.05, 24} = -1.711.\\) \n\n Step 5-c: Draw a Conclusion Using Critical Value \nThe critical value separates the the standard normal values into the rejection region and non-rejection region. For a right-tailed test, the rejection region is any \\(z\\) value greater than \\(z_{\\alpha}\\), and the non-rejection region is any \\(z\\) value smaller than or equal to \\(z_{\\alpha}\\). For a left-tailed test, the rejection region is any \\(z\\) value small than \\(-z_{\\alpha}\\), and the non-rejection region is any \\(z\\) value greater than or equal to \\(-z_{\\alpha}\\). For a two-tailed test, the rejection region is the union of any \\(z\\) value smaller than \\(-z_{\\alpha/2}\\) and any \\(z\\) value greater than \\(z_{\\alpha/2}\\).\nIf the test statistic \\(z_{test}\\) is in the rejection region, we reject \\(H_0\\). If \\(z_{test}\\) is not in the rejection region, we do not or fail to reject \\(H_0\\). FigureÂ 15.3 is an example that we reject \\(H_0\\) in a right-tailed test. The test statistic is 2.5 which is greater than the critical value 1.645, so the test statistic falls in the rejection region.\n\n\n\n\nFigureÂ 15.3: Test statistic inside of critical region. Source: https://www.thoughtco.com/example-of-a-hypothesis-test-3126398\n\n\n\n\nThe rejection region for any type of tests is shown in the table below.\n\n\n\n\n\n\n\n\nCondition Â  Â \n\nRight-tailed \\((H_1: \\mu > \\mu_0)\\)\n\n\nLeft-tailed \\((H_1: \\mu < \\mu_0)\\)\n\n\nTwo-tailed \\((H_1: \\mu \\ne \\mu_0)\\)\n\n\n\n\n\n\\(\\sigma\\) known\n\\(z_{test} > z_{\\alpha}\\)\n\\(z_{test} < -z_{\\alpha}\\)\n\\(\\mid z_{test}\\mid \\, > z_{\\alpha/2}\\)\n\n\n\n\\(\\sigma\\) unknown\n\\(t_{test} > t_{\\alpha, n-1}\\)\n\\(t_{test} < -t_{\\alpha, n-1}\\)\n\\(\\mid t_{test}\\mid \\, > t_{\\alpha/2, n-1}\\)\n\n\n\nRemember that a test statistic works as our evidence, and the critical value is a threshold to determine whether the evidence is strong enough. When the test statistic is more extreme than the critical value, it means that from our point of view, the chance of our evidence happening is way too small given the current rules of the game or under \\(H_0\\). Therefore, we donâ€™t think we live in the world of \\(H_0\\), and it probably makes more sense to think we live in the world of \\(H_1\\), and it is commonplace to see these evidence happening.\n Example Step 5-c: Draw a Conclusion Using Critical Value \nWe reject \\(H_0\\) if \\(t_{test} < -t_{\\alpha, n-1}\\). Since  \\(\\small t_{test} = \\frac{\\overline{x} - \\mu_0}{s/\\sqrt{n}} = \\frac{147.2 - 150}{5.5/\\sqrt{25}} = -2.55\\)  and  \\(\\small -t_{0.05, 25-1} = -t_{0.05, 24} = -1.711\\) , we have \\(\\small t_{test} = -2.55 < -1.711 = -t_{\\alpha, n-1}\\), so we reject \\(H_0\\).\n\n Step 4-p: Find the P-Value \nAnother decision rule is the p-value method. The \\(p\\)-value measures the strength of the evidence against \\(H_0\\) provided by the data. The smaller the \\(p\\)-value, the greater the evidence against \\(H_0\\). As the name implies, the \\(p\\)-value is the probability of getting a test statistic value that is at least as extreme as the one obtained from the data, assuming that \\(H_0\\) is true. \\((\\mu = \\mu_0)\\). For example, \\(p\\)-value \\(= P(Z \\ge z_{test} \\mid H_0)\\) for a right-tailed test. We are more likely to get a \\(p\\)-value near 0 when \\(H_0\\) is false than when \\(H_0\\) is true. Because when \\(H_0\\) is true, \\(z_{test}\\) will be closer to zero or located around the center of the distribution (the \\(\\mu_0\\) value assumed in \\(H_0\\)), and its p-value will be around 0.5. On the other hand, when \\(H_0\\) is false, or the true \\(\\mu\\) is not \\(\\mu_0\\), the test statistic \\(z_{test}\\) will be farther away from \\(\\mu_0\\) and located at the either tail of the distribution. Therefore, its p-value will be small.\n P-Value Illustration \nSince p-value is a probability, in the distribution, it represents the area under the density curve for values that are at least as extreme as the test statisticâ€™s value. FigureÂ 15.4 shows the p-value for different tests. Note that the p-value for a two-tailed test depends on whether the test statistic is positive or negative. If the calculated test statistic is on the right (left) hand side, the p-value will be the right (left) tail area times two.\n\n\n\n\nFigureÂ 15.4: Illustration of p-values for different types of hypothesis tests\n\n\n\n\nMathematically, the p-value for any type of tests is shown in the table below.\n\n\n\n\n\n\n\n\nCondition Â  Â \n\nRight-tailed \\((H_1: \\mu > \\mu_0)\\)\n\n\nLeft-tailed \\((H_1: \\mu < \\mu_0)\\)\n\n\nTwo-tailed \\((H_1: \\mu \\ne \\mu_0)\\)\n\n\n\n\n\n\\(\\sigma\\) known\n\\(P(Z > z_{test} \\mid H_0)\\)\n\\(P(Z < z_{test} \\mid H_0)\\)\n\\(2P(Z > \\,\\mid z_{test} \\mid \\, \\mid H_0)\\)\n\n\n\n\\(\\sigma\\) unknown\n\\(P(T > t_{test} \\mid H_0)\\)\n\\(P(T < t_{test} \\mid H_0)\\)\n\\(2P(T > \\, \\mid t_{test} \\mid \\, \\mid H_0)\\)\n\n\n\n Example Step 4-p: Find the P-Value \nThis is a left-tailed test, so the \\(p\\)-value is \\(P(T < t_{test})=P(T < -2.55) =\\) 0.01 \n\n Step 5-p: Draw a Conclusion Using P-Value Method \nHow do we use the p-value to make the decision? Well, here the p-value is like our evidence, and the significance level \\(\\alpha\\) is the cut-off for measuring the strength of the evidence. If the \\(p\\)-value \\(\\le \\alpha\\) , we reject \\(H_0\\). If instead the \\(p\\)-value \\(> \\alpha\\), we do not reject or fail to reject \\(H_0\\).\nYes, it is a pretty simple decision rule, but the \\(p\\)-value has been misinterpreted and misused for a long time. When we do a hypothesis testing, it is dangerous to simply compare the size of \\(p\\)-value and \\(\\alpha\\), then jump into the conclusion. You can find more issues of p-value at XXX.\n Example Step 5-p: Draw a Conclusion Using P-Value Method \n We reject \\(H_0\\) if the \\(p\\)-value < \\(\\alpha\\). Since \\(p\\)-value \\(= 0.01 < 0.05 = \\alpha\\), we reject \\(H_0\\).\n\n Both Methods Lead to the Same Conclusion \nRemember I say both critical-value method and \\(p\\)-value method lead to the same conclusion? FigureÂ 15.5 shows why. Test statistic and critical value are variable values, either \\(z\\) or \\(t\\) scores. The p-value and significance level \\(\\alpha\\) are probabilities, either \\(z\\) or \\(t\\) probabilities. The p-value is computed from the test statistic, and \\(\\alpha\\) defines the critical value. The more extreme test statistic implies the smaller p-value, and smaller \\(\\alpha\\) means more extreme critical value. When we reject \\(H_0\\), the following three statements are equivalent:\n\ntest statistic is in the rejection region.\nthe test statistic is more extreme than the critical value\nthe p-value is smaller than \\(\\alpha\\).\n\n\n\n\n\nFigureÂ 15.5: The conclusion is the same regardless of the method used (Critical Value or P-Value).\n\n\n\n\n\nThe following distribution shows the equivalence of the critical-value method and the p-value method in the blood pressure example.\n\n\n\n\n\n\n\n\n\n Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim \nThe final step in the entire hypothesis testing procedure is to make a verbal conclusion, and address the original claim. FigureÂ 15.6 gives you a guideline of how we make a conclusion.\n\n\n\n\nFigureÂ 15.6: Conclusions based on testing results. Source: https://www.drdawnwright.com/category/statistics/\n\n\n\n\nHere is a reminder. We never say we accept \\(H_0\\). Why canâ€™t we say we â€œaccept the nullâ€? The reason is that we are assuming the null hypothesis is true or the situation we are currently in. We are trying to see if there is evidence against it. Therefore, the conclusion should be in terms of rejecting the null. We donâ€™t accept \\(H_0\\) when we donâ€™t have evidence against it because we are already in the world of \\(H_0\\).\n\n\n\n\nFigureÂ 15.7: Meme about hypothesis testing conclusions. Source: https://www.pinterest.com/pin/287878601159173631/\n\n\n\n\n\n Example Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim \nWe have a \\(H_1\\) claim and we reject \\(H_0\\), so we conclude that  There is sufficient evidence to support the claim that the new treatment is effective. \n\n Example Calculation in R \nBelow is a demonstration of how to work through the blood pressure example using R.\n\n## create objects for any information we have\nalpha <- 0.05; mu_0 <- 150; \nx_bar <- 147.2; s <- 5.5; n <- 25\n\n## Test statistic\n(t_test <- (x_bar - mu_0) / (s / sqrt(n))) \n\n[1] -2.545455\n\n## Critical value\n(t_cri <- qt(alpha, df = n - 1)) \n\n[1] -1.710882\n\n## p-value\n(p_val <- pt(t_test, df = n - 1)) \n\n[1] 0.008878158\n\n\nThe critical value is \\(-t_{\\alpha, n-1}\\), or the quantile such that \\(P(T_{n-1} < -t_{\\alpha, n-1}) = \\alpha\\). Therefore, we use qt() to get the \\(t\\) value. Notice that the p-value is a probability that the Studentâ€™s t variable with degrees of freedom \\(n-1\\) is smaller (more extreme) than the test statistic. In R, we use pt() to get the probability. Without specifying the lower.tail argument in the function, by default, both qt() and pt() function focuses on the lower tail or left tail, which is what we need in this left-tail test."
  },
  {
    "objectID": "infer-ht.html#example-is-the-new-treatment-effective",
    "href": "infer-ht.html#example-is-the-new-treatment-effective",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.3 Example: Is the New Treatment Effective?",
    "text": "15.3 Example: Is the New Treatment Effective?\n\n\n\nA population of patients with hypertension is normal and has mean blood pressure (BP) of 150.\nAfter 6 months of treatment, the BP of 25 patients from this population was recorded.\n\n\n\\(\\overline{x} = 147.2\\) and \\(s = 5.5\\).\n\n\n\nGoal: Determine whether a new treatment is effective in reducing BP.\n\n\n\n\n\n\n\n\n\n\n\n\n\n Step-by-Step \n Step 0: Check Method Assumptions \n\n\n A population of hypertension group is normal .\n\n Step 1: Set the \\(H_0\\) and \\(H_1\\) from a Claim \n\nThe claim that the new treatment is effective in reducing BP means the mean BP is less than 150, which is an \\(H_1\\) claim.\n\n \\(\\small \\begin{align} &H_0: \\mu = 150 \\\\ &H_1: \\mu < 150 \\end{align}\\) \n\n\n\n Step 2: Set the Significance Level \\(\\alpha\\) \n\nLetâ€™s set \\(\\alpha= 0.05\\).\nThis means we are asking, â€œIs there a sufficient evidence at \\(\\alpha= 0.05\\) that the new treatment is effective?â€\n\n Step 3: Calculate the Test Statistic \n\n The test statistic is \\(\\small t_{test} = \\frac{\\overline{x} - \\mu_0}{s/\\sqrt{n}} = \\frac{147.2 - 150}{5.5/\\sqrt{25}} = -2.55\\)\n\n Step 4-c: Find the Critical Value \n\n The critical value is \\(\\small -t_{0.05, 25-1} = -t_{0.05, 24} = -1.711\\) \n\n Step 5-c: Draw a Conclusion Using Critical Value \n\n \\(\\small t_{test} = \\frac{\\overline{x} - \\mu_0}{s/\\sqrt{n}} = \\frac{147.2 - 150}{5.5/\\sqrt{25}} = -2.55\\) \n \\(\\small -t_{0.05, 25-1} = -t_{0.05, 24} = -1.711\\) \n We reject \\(H_0\\) if \\(t_{test} < -t_{\\alpha, n-1}\\). Since \\(\\small t_{test} = -2.55 < -1.711 = -t_{\\alpha, n-1}\\), we reject \\(H_0\\).\n\n Step 4-p: Find the P-Value \n\nThis is a left-tailed test, so the \\(p\\)-value is \\(P(T < t_{test})=P(T < -2.55) =\\) 0.01 \n\n Step 5-p: Draw a Conclusion Using P-Value Method \n\n We reject \\(H_0\\) if the \\(p\\)-value < \\(\\alpha\\). Since \\(p\\)-value \\(= 0.01 < 0.05 = \\alpha\\), we reject \\(H_0\\).\n\n Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim \n\n There is sufficient evidence to support the claim that the new treatment is effective. \n\n\n Example Calculation in R \n\nBelow is a demonstration of how to work through this example using R.\n\n\n## create objects for any information we have\nalpha <- 0.05; mu_0 <- 150; \nx_bar <- 147.2; s <- 5.5; n <- 25\n\n## Test statistic\n(t_test <- (x_bar - mu_0) / (s / sqrt(n))) \n\n[1] -2.545455\n\n## Critical value\n(t_cri <- qt(alpha, df = n - 1, lower.tail = TRUE)) \n\n[1] -1.710882\n\n## p-value\n(p_val <- pt(t_test, df = n - 1, lower.tail = TRUE)) \n\n[1] 0.008878158"
  },
  {
    "objectID": "infer-ht.html#example-two-tailed-z-test",
    "href": "infer-ht.html#example-two-tailed-z-test",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.3 Example: Two-tailed z-test",
    "text": "15.3 Example: Two-tailed z-test\n\n\nThe milk price of a gallon of 2% milk is normally distributed with standard deviation of $0.10. Last week the mean price of a gallon of milk was 2.78. This week, based on a sample of size 25, the sample mean price of a gallon of milk was \\(\\overline{x} = 2.80\\). Under \\(\\alpha = 0.05\\), determine if the mean price is different this week.\n\n\n\n\n\nSource: https://unsplash.com/photos/BYlHH_1j2GA\n\n\n\n\n\n\n\n Step-by-Step \n Step 1: Set the \\(H_0\\) and \\(H_1\\) from a Claim \nForm the sentence â€œdetermine if the mean price is different this weekâ€, we know the claim or what we are interested is an \\(H_1\\) claim. If we let \\(\\mu\\) be the mean milk price this week, we have the test  \\(\\small \\begin{align}&H_0: \\mu = 2.78 \\\\ &H_1: \\mu \\ne 2.78 \\end{align}\\)  where 2.78 is the mean milk price last week.\n Step 2: Set the Significance Level \\(\\alpha\\) \n \\(\\small \\alpha = 0.05\\) \n Step 3: Calculate the Test Statistic \nFrom the question we know that the population is normally distributed, and \\(\\sigma\\) is known. So we use the \\(z\\)-test, and the test statistic is  \\(\\small z_{test} = \\frac{\\overline{x} - \\mu_0}{\\sigma/\\sqrt{n}} = \\frac{2.8 - 2.78}{0.1/\\sqrt{25}} = 1.00\\) \n Step 4-c: Find the Critical Value \nSince it is a two-tailed test, we have two potential critical values. Because \\(z_{test} > 0\\) and on the right hand side of the standard normal distribution, we compare it with the critical value on the right, which is  \\(\\small z_{0.05/2} = 1.96\\). \n Step 5-c: Draw a Conclusion Using Critical Value \nThis is a two-tailed test, and we reject \\(H_0\\) if \\(|z_{test}| > z_{\\alpha/2}\\). Since \\(\\small |z_{test}| = 1 < 1.96 = z_{\\alpha/2}\\), we DO NOT reject \\(H_0\\).\n Step 4-p: Find the P-Value \nThis is a two-tailed test, and the test statistic is on the right \\((> 0)\\), so the \\(p\\)-value is \\(2P(Z > z_{test})=\\) 0.317 .\n Step 5-p: Draw a Conclusion Using P-Value Method \n We reject \\(H_0\\) if \\(p\\)-value < \\(\\alpha\\). Since \\(p\\)-value \\(= 0.317 > 0.05 = \\alpha\\), we DO NOT reject \\(H_0\\).\nThe critical-value and p-value method are illustrated in FigureÂ 15.8.\n\n\n\n\nFigureÂ 15.8: Illustration of Critical Value and P-Value methods\n\n\n\n\n Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim \n There is insufficient evidence to support the claim that this week the mean price of milk is different from the price last week. \n\n Calculation in R \nBelow is an example of how to perform the two-tailed \\(z\\)-test in R.\n\n## create objects to be used\nalpha <- 0.05; mu_0 <- 2.78; \nx_bar <- 2.8; sigma <- 0.1; n <- 25\n\n## Test statistic\n(z_test <- (x_bar - mu_0) / (sigma / sqrt(n))) \n\n[1] 1\n\n## Critical value\n(z_crit <- qnorm(alpha/2, lower.tail = FALSE)) \n\n[1] 1.959964\n\n## p-value\n(p_val <- 2 * pnorm(z_test, lower.tail = FALSE)) \n\n[1] 0.3173105"
  },
  {
    "objectID": "infer-ht.html#testing-summary",
    "href": "infer-ht.html#testing-summary",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.4 Testing Summary",
    "text": "15.4 Testing Summary\nBelow is a table that summarizes what we have learned about hypothesis testing in this chapter.\n\n\n\n\n\n\n\n\nNumerical Data, \\(\\sigma\\) known\nNumerical Data, \\(\\sigma\\)  unknown \n\n\n\n\nParameter of Interest\nPopulation Mean \\(\\mu\\)\n\nPopulation Mean \\(\\mu\\)\n\n\n\nTest Type\nOne sample \\(\\color{blue}{z}\\) test \\(H_0: \\mu = \\mu_0\\)\n\nOne sample \\(\\color{blue}{t}\\) test \\(H_0: \\mu = \\mu_0\\)\n\n\n\nConfidence Interval\n\\(\\bar{x} \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\)\n\\(\\bar{x} \\pm t_{\\alpha/2, n-1} \\frac{\\color{blue}{s}}{\\sqrt{n}}\\)\n\n\nTest Stat under \\(H_0\\) \n\\(z_{test} = \\frac{\\overline{x} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n\\(t_{test} = \\frac{\\overline{x} - \\mu_0}{\\frac{\\color{blue}{s}}{\\sqrt{n}}}\\)\n\n\n\\(p\\)-value under \\(H_0\\)\n\n\\(H_1: \\mu < \\mu_0\\) \\(p\\)-value \\(=P(Z \\le z_{test})\\)\n\n\n\\(H_1: \\mu < \\mu_0\\) \\(p\\)-value \\(=P(T_{n-1} \\le t_{test})\\)\n\n\n\n\n\n\\(H_1: \\mu > \\mu_0\\) \\(p\\)-value \\(=P(Z \\ge z_{test})\\)\n\n\n\\(H_1: \\mu < \\mu_0\\) \\(p\\)-value \\(=P(T_{n-1} \\ge t_{test})\\)\n\n\n\n\n\n\\(H_1: \\mu \\ne \\mu_0\\) \\(p\\)-value \\(=2P(Z \\ge \\, \\mid z_{test}\\mid)\\)\n\n\n\\(H_1: \\mu \\ne \\mu_0\\) \\(p\\)-value \\(=2P(T_{n-1} \\ge \\, \\mid t_{test} \\mid)\\)"
  },
  {
    "objectID": "infer-ht.html#type-i-and-type-ii-errors",
    "href": "infer-ht.html#type-i-and-type-ii-errors",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.5 Type I and Type II Errors",
    "text": "15.5 Type I and Type II Errors\nIt is important to remember that hypothesis testing is not perfect, meaning that we may make a wrong decision or conclusion. After all, the collected evidence may not be able to present the full picture of what the true population distribution is. There are two types of errors we may commit when doing hypothesis testing: Type I error and Type II error.\nIf in fact \\(H_0\\) is true, but we wrongly reject it, we commit the type I error. We shouldnâ€™t reject it but we did. If \\(H_0\\) is false, but we donâ€™t reject it, we make the type II error. We should have figured out that \\(H_0\\) does not make sense. The following table tells us when we make a correct decision and when we donâ€™t. In practice, we will not know for certain if we made the correct decision or if we made one of these two errors because we never know the truth!\n\n\n\nDecision\n\n\\(H_0\\) is true\n\n\\(H_0\\) is false\n\n\n\nReject \\(H_0\\)\n\nType I error\nCorrect decision\n\n\nDo not reject \\(H_0\\)\n\nCorrect decision\nType II error\n\n\n\nBack to the crime example that \\(H_0:\\) The person is  not guilty  v.s. \\(H_1:\\) The person is  guilty . We can have a decision table like\n\n\n\n\n\n\n\nDecision\nTruth is the person innocent\nTruth is the person guilty\n\n\n\nJury decides the person guilty\nType I error\nCorrect decision\n\n\nJury decides the person not guilty\nCorrect decision\nType II error\n\n\n\nIs it worse to wrongly convict an innocent person (Type I error) or to let a perpetrator free (Type II error)? Both hugely negatively impact our society, and if possible, we should make the two errors as rarely as possible.\n\n\n\n\nFigureÂ 15.9: Example of Type I and Type II errors (https://www.statisticssolutions.com/wp-content/uploads/2017/12/rachnovblog.jpg)\n\n\n\n\nIt you still donâ€™t get the idea of type I and type II errors, FigureÂ 15.9 is a classical example of the two errors. Of course the null hypothesis is â€œnot pregnantâ€, and the alternative hypothesis is â€œpregnantâ€. Claiming that a old man is expecting a baby is a type I error, and saying a pregnant woman not having a baby is a type II error.\nIn statistics, the probability of committing the type I error is in fact the significance level \\(\\alpha\\).\n\\[\\alpha = P(\\text{type I error}) = P(\\text{rejecting } H_0 \\text{ when } H_0 \\text{ is true})\\]\nIf the evidence occurring with probability lower than 5%, it will be considered sufficient evidence to reject \\(H_0\\), even though \\(H_0\\) is actually the true mechanism giving rise to such evidence.\nWhat is the probability of committing the type II error, the probability that we fail to reject \\(H_0\\) when \\(H_0\\) is a false statement? We call the probability \\(\\beta\\):\n\\[\\beta = P(\\text{type II error}) = P(\\text{failing to reject } H_0 \\text{ when } H_0 \\text{ is false})\\]\n\\(\\alpha\\), \\(\\beta\\) and sample size \\(n\\) are related. If we choose any two of them, the third is automatically determined. We would of course prefer \\(\\alpha\\) to be small since we would not like to conclude in favor of the research hypothesis falsely. But given the sample size, small \\(\\alpha\\) leads to a large \\(\\beta\\). On the other hand, too small \\(\\alpha\\) would most likely result in no discovery because we are gonna be conservative, set the threshold too high, and do not reject lots of \\(H_0\\) that should be rejected. In practice, we specify \\(\\alpha\\) beforehand, and then select \\(n\\) that is practical, so the \\(\\beta\\) is determined.\nIt would be great if we correctly reject \\(H_0\\) when \\(H_0\\) is actually false. We hope the probability of having this to be large. The probability is actually \\(1-\\beta\\), which is called the power of a test. The power depends on the same factors as \\(\\beta\\) does, including the size of \\(\\alpha\\), the sample size, and the true value of parameter."
  },
  {
    "objectID": "infer-ht.html#exercises",
    "href": "infer-ht.html#exercises",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.6 Exercises",
    "text": "15.6 Exercises\n\n\nHere are summary statistics for randomly selected weights of newborn boys: \\(n =207\\), \\(\\bar{x} = 30.2\\)hg (1hg = 100 grams), \\(s = 7.3\\)hg.\n\nWith significance level 0.01, use the critical value method to test the claim that the population mean of birth weights of females is greater than 30hg.\nDo the test in (c) by using the p-value method.\n\n\nYou are given the following hypotheses: \\[\\begin{align*}\nH_0&: \\mu = 45 \\\\\nH_A&: \\mu \\neq 45\n\\end{align*}\\] We know that the sample standard deviation is 5 and the sample size is 24. For what sample mean would the p-value be equal to 0.05? Assume that all conditions necessary for inference are satisfied.\n\nOur one sample \\(z\\) test is \\(H_0: \\mu = \\mu_0 \\quad H_1: \\mu < \\mu_0\\) with a significance level \\(\\alpha\\).\n\nDescribe how we reject \\(H_0\\) using the critical-value method and the \\(p\\)-value method.\nWhy do the two methods lead to the same conclusion?"
  },
  {
    "objectID": "infer-twomean.html#introduction",
    "href": "infer-twomean.html#introduction",
    "title": "16Â  Comparing Two Population Means",
    "section": "\n16.1 Introduction",
    "text": "16.1 Introduction\n Why Compare Two Populations? \nWeâ€™ve discussed estimation (ChapterÂ 13) and hypothesis testing (ChapterÂ 15) for one single population mean \\(\\mu.\\) The methods we learned can only be used for one sample or population. However, quite often we are faced with a comparison of parameters from different populations. For example,\n\n Comparing the mean annual income for Male and Female groups. \n Testing if a diet used for losing weight is effective from Placebo samples and New Diet samples. \n\nIf these two samples are drawn from two target populations with means, \\(\\mu_1\\) and \\(\\mu_2\\) respectively, the testing problem can be formulated as  \\[\\begin{align}\n  &H_0: \\mu_1 = \\mu_2 \\\\ &H_1: \\mu_1 > \\mu_2\n  \\end{align}\\] \nwhere \\(\\mu_1\\) for example is the male mean annual income and \\(\\mu_2\\) is the female mean annual income Or \\(\\mu_1\\) is the mean weight loss from the New Diet group, and \\(\\mu_2\\) is the mean weight loss from the Placebo group.\nTo compare two means, we need two samples, one for one mean. But the two samples may be dependent or independent, and the methods for comparing two means depend on whether the two samples are dependent or not. So letâ€™s see what dependent and independent samples are.\n\n Dependent and Independent Samples \nThe two samples used to compare two population means can be independent or dependent.\n\n\nTwo samples are dependent or matched pairs if the sample values are matched, where the matching is based on some inherent relationship. For example,\n\n Height data of fathers and daughters, where the height of each dad is matched with the height of his daughter.  Clearly, father and daughter share the same life style, genes, and other factors that affect both father and daughterâ€™s height. So the taller the father is, the taller the daughter tends to be. Their heights are positively correlated. In the two sample data sets, the first father height in the fatherâ€™s sample is paired with the first daughter height in the daughterâ€™s sample. Same for the second pair, third pair, and so on.\n Weights of subjects measure before and after some diet treatment, where the subjects are the same both before and after treatments.  In this example, we again have two samples. The two samples are dependent because the subjects in the two samples are identical. Your weight today is of course related to your weight last week, right? In the two sample data sets, the first weight in the sample before diet treatment is paired with the first weight in the sample after treatment. The two sample values belong to the same person. Same for the second pair, third pair, and so on.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dependent Samples (Matched Pairs) \nFrom the two examples, we learn that subject 1 may refer to\n\nthe first matched pair (dad-daughter)\nthe same person with two measurements (before and after treatment)\n\nIf we have data with only one variable, in R the data is usually saved as a vector. When we have two samples, the two samples can be saved as a vector separately, or saved as a data matrix with the two samples combined by columns like the table below. Each row is for one matched pair, or the same subject. One column is for one sample data. Note that since every subject in dependent samples is paired, the two samples are of the same size \\(n\\).\n\n\nSubject\n(Dad) Before\n(Daughter) After\n\n\n\n1\n\\(x_{b1}\\)\n\\(x_{a1}\\)\n\n\n2\n\\(x_{b2}\\)\n\\(x_{a2}\\)\n\n\n3\n\\(x_{b3}\\)\n\\(x_{a3}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_{bn}\\)\n\\(x_{an}\\)\n\n\n\n Independent Samples \n\n\nTwo samples are independent if the sample values from one population are not related to the sample values from the other. For example,\n\n Salary samples of men and women, where the two samples are drawn independently from the male and female groups. \n\n\n\n\n\n\n\n\n\n\n\n\nWe may want to compare the mean salary level of male and female. What we can do is to collect two samples independently, one for each group, from their own population. Any subject in the male group has nothing to do with any subject in the female group, and any subject in the male group cannot be paired with any subject in the female group in any way.\nThe independent samples can be summarized as the table below. Notice that the two samples can have different sample sizes, \\(n_1\\) and \\(n_2\\) for example. Because the subjects in the two samples are not paired, we can collect salary data from 50 males and 65 females. In the data table, \\(x_{14}\\) means the 4th subject measurement in the first group, and \\(x_{23}\\) means the 3rd subject measurement in the second group. In general, \\(x_{ij}\\) is the \\(j\\)-th measurement in the \\(i\\)-th group.\n\n\n\n\n\n\n\n\n\nSubject of Group 1 (Male)\nMeasurement of Group 1\nSubject of Group 2 (Female)\nMeasurement of Group 2\n\n\n\n1\n\\(x_{11}\\)\n1\n\\(x_{21}\\)\n\n\n2\n\\(x_{12}\\)\n2\n\\(x_{22}\\)\n\n\n3\n\\(x_{13}\\)\n3\n\\(x_{23}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n_1\\)\n\\(x_{1n_1}\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\\(n_2\\)\n\\(x_{2n_2}\\)\n\n\n\n\n Inference from Two Samples \nThe statistical methods are different for these two types of samples. The good news is the concepts of confidence intervals and hypothesis testing for one population can be applied to two-population cases.\nLetâ€™s quickly review the confidence interval and test statistic in the one-sample case.\n\\(\\text{CI = point estimate} \\pm \\text{margin of error (E)}\\)\n\ne.g., \\(\\overline{x} \\pm t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}\\)\n\n\nMargin of error = critical value \\(\\times\\) standard error of the point estimator\nThe 6 testing steps are the same, and both critical value and \\(p\\)-value method can be applied too.\n\ne.g., \\(t_{test} = \\frac{\\overline{x} - \\mu_0}{s/\\sqrt{n}}\\)"
  },
  {
    "objectID": "infer-twomean.html#inferences-about-two-means-dependent-samples-matched-pairs",
    "href": "infer-twomean.html#inferences-about-two-means-dependent-samples-matched-pairs",
    "title": "16Â  Comparing Two Population Means",
    "section": "\n16.2 Inferences About Two Means: Dependent Samples (Matched Pairs)",
    "text": "16.2 Inferences About Two Means: Dependent Samples (Matched Pairs)\nIn this section we talk about the inference methods for comparing two population means when the samples are dependent.\n Hypothesis Testing for Dependent Samples \n\n\n\n\n\n\nTo analyze a paired data set, we can simply analyze the differences!\n\n\n\n\n\n\nSuppose we would like to learn if the population means \\(\\mu_1\\) and \\(\\mu_2\\) are different. We can conduct a test like  \\[\\begin{align}\n  &H_0: \\mu_1 = \\mu_2 \\\\ &H_1: \\mu_1 \\ne \\mu_2\n  \\end{align}\\] \nThe null hypothesis can also be written as \\(H_0: \\mu_1 - \\mu_2 = 0\\). We donâ€™t really want to know the value of \\(\\mu_1\\) and/or \\(\\mu_2\\), and we just care about if they are equal, or their difference is zero. Therefore, if we let \\(\\mu_d\\) be the difference \\(\\mu_1 - \\mu_2\\), we can write our hypothesis as \\[\\begin{align}\n  &H_0: \\mu_d = 0 \\\\ &H_1: \\mu_d \\ne 0\n  \\end{align}\\] \nor more generally for any types of test,\n \\[\\begin{align} & H_0: \\mu_1 - \\mu_2 = 0 \\iff \\mu_d = 0 \\\\ & H_1: \\mu_1 - \\mu_2 > 0 \\iff \\mu_d > 0 \\\\ & H_1: \\mu_1 - \\mu_2 < 0 \\iff \\mu_d < 0  \\\\ & H_1: \\mu_1 - \\mu_2 \\ne 0 \\iff \\mu_d \\ne 0 \\end{align}\\] \nFor dependent samples, we just transform the two samples into one difference sample by taking the difference between paired measurements. We use the difference sample to do the inference about the mean difference. The data table below illustrate the idea. We create a new difference sample data \\((d_1, d_2, \\dots, d_n)\\) where the \\(i\\)-th sample difference is \\(x_{1i} - x_{2i}\\), the difference between the \\(i\\)-th measurement in the first sample and the \\(i\\)-th measurement in the second sample.\n\n\n\n\n\n\n\n\n\n\nSubject\n\\(x_1\\)\n\\(x_2\\)\nDifference \\(d = x_1 - x_2\\)\n\n\n\n1\n\\(x_{11}\\)\n\\(x_{21}\\)\n\\(\\color{red}{d_1}\\)\n\n\n2\n\\(x_{12}\\)\n\\(x_{22}\\)\n\\(\\color{red}{d_2}\\)\n\n\n3\n\\(x_{13}\\)\n\\(x_{23}\\)\n\\(\\color{red}{d_3}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\color{red}{\\vdots}\\)\n\n\n\\(n\\)\n\\(x_{1n}\\)\n\\(x_{2n}\\)\n\\(\\color{red}{d_n}\\)\n\n\n\nThe sample \\((d_1, d_2, \\dots, d_n)\\) is used to estimate the mean difference \\(\\mu_d = \\mu_1 - \\mu_2\\). So what is our point estimate of \\(\\mu_d\\)? The point estimate is the sample average of \\((d_1, d_2, \\dots, d_n)\\) which is \\(\\overline{d}\\). Actually, the point estimate is equal to \\(\\overline{x}_1 - \\overline{x}_2\\), the estimate for \\(\\mu_1 - \\mu_2\\).\n\n\n\n\n Inference for Paired Data \nHere are the requirements for the inference for paired data. The sample differences \\(\\color{blue}{d_i}\\)s form a random sample, and they are from a normal distribution and/or the sample size \\(n > 30\\). Remember that when analyzing paired data, we focus on the difference of measurements, and this \\(d_i\\) sample becomes our new one single sample for inference about one single population parameter, the mean difference \\(\\mu_d\\).\n\nWith this, the inference for paired data follows the same procedure as the one-sample \\(t\\)-test! Therefore, the test statistic is \\[\\color{blue}{t_{test} = \\frac{\\overline{d}-\\mu_d}{s_d/\\sqrt{n}}} = \\frac{\\overline{d}-0}{s_d/\\sqrt{n}} \\sim T_{n-1}\\] under \\(H_0\\) where \\(\\overline{d}\\) and \\(s_d\\) are the mean and standard deviation of the difference samples \\((d_1, d_2, \\dots, d_n)\\).\n\nThe critical value is either \\(t_{\\alpha, n-1}\\) or \\(t_{\\alpha/2, n-1}\\) depending on if it is a one-tailed or two-tailed test. Below is a table summarizing information necessary to make inferences about paired data.\n\n\n\n\n\n\n\nPaired \\(t\\)-test\nTest Statistic\nConfidence Interval for \\(\\mu_d = \\mu_1 - \\mu_2\\)\n\n\n\n\n\\(\\sigma_d\\) is unknown\n\\(\\large t_{test} = \\frac{\\overline{d}}{s_d/\\sqrt{n}}\\)\n\\(\\large \\overline{d} \\pm t_{\\alpha/2, n-1} \\frac{s_d}{\\sqrt{n}}\\)\n\n\nThe test for matched pairs is called a paired \\(t\\)-test.\n\n Example \nConsider a capsule used to reduce blood pressure (BP) for individuals with hypertension. A sample of 10 individuals with hypertension takes the medicine for 4 weeks. The BP measurements before and after taking the medicine are shown in the table below. Does the data provide sufficient evidence that the treatment is effective in reducing BP?\n\n\n\n\n\n\n\n\nSubject\nBefore \\((x_b)\\)\n\nAfter \\((x_a)\\)\n\nDifference \\(d = x_b - x_a\\)\n\n\n\n1\n143\n124\n19\n\n\n2\n153\n129\n24\n\n\n3\n142\n131\n11\n\n\n4\n139\n145\n-6\n\n\n5\n172\n152\n20\n\n\n6\n176\n150\n26\n\n\n7\n155\n125\n30\n\n\n8\n149\n142\n7\n\n\n9\n140\n145\n-5\n\n\n10\n169\n160\n9\n\n\n\nGiven the data \\(x_b\\) and \\(x_a\\), we first take the difference and create the new data \\(d = x_b - x_a\\) for each subject.\n Step 1 \n\nIf we let \\(\\mu_1 =\\) Mean Before, \\(\\mu_2 =\\) Mean After, and \\(\\mu_d = \\mu_1 - \\mu_2\\), then the hypothesis is  \\(\\begin{align} &H_0: \\mu_1 = \\mu_2 \\iff \\mu_d = 0\\\\ &H_1: \\mu_1 > \\mu_2 \\iff \\mu_d > 0 \\end{align}\\)  The key is that â€œthe treatment is effective in reducing BPâ€ means the mean BP after taking the medicine is lower than that before, so \\(\\mu_1 > \\mu_2\\).\n\n Step 2 \n\n \\(\\alpha = 0.05\\) \n\n Step 3 \nFor the \\(d\\) sample, \\(\\overline{d} = 13.5\\), \\(s_d= 12.48\\).  \\(t_{test} = \\frac{\\overline{d}}{s_d/\\sqrt{n}} = \\frac{13.5}{12.48/\\sqrt{10}} = 3.42.\\) \n Step 4-c \n\nThis is a right-tailed test.  \\(t_{\\alpha, n-1} = t_{0.05, 9} = 1.833\\).\n\n\n Step 5-c \n\n We reject \\(H_0\\) if \\(\\small t_{test} > t_{\\alpha, n-1}\\). Since \\(\\small t_{test} = 3.42 > 1.833 = t_{\\alpha, n-1}\\), we reject \\(H_0\\).\n\n Step 6 \n\n There is sufficient evidence to support the claim that the drug is effective in reducing blood pressure. \n\n\n\n\n\nFigureÂ 16.1: Illustration of right-tailed test for blood pressure example\n\n\n\n\nThe 95% CI for \\(\\mu_d = \\mu_1 - \\mu_2\\) is \\[\\begin{align}\\overline{d} \\pm t_{\\alpha/2, df} \\frac{s_d}{\\sqrt{n}} &= 13.5 \\pm t_{0.025, 9}\\frac{12.48}{\\sqrt{10}}\\\\ &= 13.5 \\pm 8.927 \\\\ &= (4.573, 22.427).\\end{align}\\]\nWe are 95% confident that the mean difference in blood pressure is between 4.57 and 22.43. Since the interval does NOT include 0, it leads to the same conclusion as rejection of \\(H_0\\).\n\n Two-Sample Paired \\(t\\)-Test in R \nBelow is the same data as in the previous hypertension example. We load the R data pair_data.RDS into the R session using the load() function. \n\n\n\n# Load the data set\nload(\"../introstatsbook/data/pair_data.RDS\")\npair_data\n\n   before after\n1     143   124\n2     153   129\n3     142   131\n4     139   145\n5     172   152\n6     176   150\n7     155   125\n8     149   142\n9     140   145\n10    169   160\n\n## Create the difference data d\n(d <- pair_data$before - pair_data$after)\n\n [1] 19 24 11 -6 20 26 30  7 -5  9\n\n## sample mean of d\n(d_bar <- mean(d))\n\n[1] 13.5\n\n\n\n\n\n\n\n## sample standard deviation of d\n(s_d <- sd(d))\n\n[1] 12.48332\n\n## t test statistic\n(t_test <- d_bar/(s_d/sqrt(length(d))))\n\n[1] 3.419823\n\n## t critical value\n\nqt(p = 0.95, df = length(d) - 1)\n\n[1] 1.833113\n\n## p value\npt(q = t_test, df = length(d) - 1, \n   lower.tail = FALSE)\n\n[1] 0.003815036\n\n\n\n\nBelow is an example of how to calculate the confidence interval for the change in blood pressure.\n\n## 95% confidence interval for the mean difference of the paired data\nd_bar + c(-1, 1) * qt(p = 0.975, df = length(d) - 1) * (s_d / sqrt(length(d)))\n\n[1]  4.569969 22.430031\n\n\nWe can see that performing these calculations in R leads us to the same conclusions we previously made. In fact, the R function t.test() does Studentâ€™s t-test for us, either one sample or two samples. To do the two sample paired \\(t\\) test, we provides the two samples in the argument x and y. The alternative argument is either â€œtwo.sidedâ€, â€œlessâ€ or â€œgreaterâ€. We have \\(H_1: \\mu_1 > \\mu_2\\) or \\(\\mu_d > 0\\), so we use â€œgreaterâ€. The argument \\mu is the difference in means in \\(H_0\\), which is zero in our case. Finally, the paired argument should be set as TRUE in order to do the paired \\(t\\) test.\n\n## t.test() function\nt.test(x = pair_data$before, y = pair_data$after,\n       alternative = \"greater\", mu = 0, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  pair_data$before and pair_data$after\nt = 3.4198, df = 9, p-value = 0.003815\nalternative hypothesis: true mean difference is greater than 0\n95 percent confidence interval:\n 6.263653      Inf\nsample estimates:\nmean difference \n           13.5 \n\n\n\nNote that we get the same test statistic and p-value, as well as the test conclusion. However, the one-sided 95% confidence interval shown in the output is not what we want! We may have a one-sided or two-sided test, but we should always use the two-sided confidence interval. When you use the t.test() function to do a one-sided test as we do here, please do not use the confidence interval in the output."
  },
  {
    "objectID": "infer-twomean.html#inference-about-two-means-independent-samples",
    "href": "infer-twomean.html#inference-about-two-means-independent-samples",
    "title": "16Â  Comparing Two Population Means",
    "section": "\n16.3 Inference About Two Means: Independent Samples",
    "text": "16.3 Inference About Two Means: Independent Samples\n Compare Population Means: Independent Samples \nFrequently we would like to compare two different groups. For example,\n\nWhether stem cells can improve heart function. Here the two samples are patients with the stem cell treatment and the ones without the stem cell treatment.\nThe relationship between pregnant womenâ€™s smoking habits and newbornsâ€™ weights. Here the two samples are women who smoke and women who donâ€™t.\nWhether one variation of an exam is harder than another variation. In this case, the two samples are students having exam A and students taking exam B.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn those examples, the two samples are independent. In this section, we are going to learn how to compare their population means. For example, whether the mean score of exam A is higher than the mean score of exam B.\n\n Testing for Independent Samples \\((\\sigma_1 \\ne \\sigma_2)\\) \nWhen we deal with two independent samples, we assume they are drawn from two independent populations which are assumed to be normally distributed in this chapter. We are interested in whether the two population means are equal or which is greater. But to do the inference, we need to take care of their standard deviation, \\(\\sigma_1\\) and \\(\\sigma_2\\). First we discuss the case when \\(\\sigma_1 \\ne \\sigma_2\\).\nThe requirements of testing for independent samples with \\(\\sigma_1 \\ne \\sigma_2\\) are\n\nThe two samples are independent.\nBoth samples are random samples.\n\n\\(n_1 > 30\\), \\(n_2 > 30\\) and/or both samples are from a normally distributed population. Large sample sizes are for the application of the central limit theorem. Note that both sample sizes should be large or at least greater than 30. If either one sample size is small, the inference methods discussed here are not valid.\n\nWe are interested in whether the two population means, \\(\\mu_1\\) and \\(\\mu_2\\), are equal or if one is larger than the other. Therefore, we have \\[H_0: \\mu_1 = \\mu_2\\]\nThis is equivalent to testing if their difference is zero, or \\(H_0: \\mu_1 - \\mu_2 = 0\\).\n\n\n\n\n\n\nWe start by finding a point estimator for \\(\\mu_1 - \\mu_2\\). What is the best point estimator for \\(\\mu_1 - \\mu_2\\)?\n\n\n\n\n\n\\(\\overline{X}_1 - \\overline{X}_2\\) is the best point estimator for \\(\\mu_1 - \\mu_2\\)!\n\n\n\n Sampling Distribution of \\(\\overline{X}_1 - \\overline{X}_2\\) \nAgain, to do the inference we start with the associated sampling distribution. If the two samples are from independent normally distributed populations or \\(n_1 > 30\\) and \\(n_2 > 30\\), then at least approximately\n\\[\\small \\overline{X}_1 \\sim N\\left(\\mu_1, \\frac{\\sigma_1^2}{n_1} \\right), \\quad \\overline{X}_2 \\sim N\\left(\\mu_2,\n\\frac{\\sigma_2^2}{n_2} \\right)\\]\nBecause we use \\(\\overline{X}_1 - \\overline{X}_2\\) to estimate \\(\\mu_1 - \\mu_2\\), we need the sampling distribution of \\(\\overline{X}_1 - \\overline{X}_2\\). We wonâ€™t talk about the details, but it can be shown that \\(\\overline{X}_1 - \\overline{X}_2\\) has the sampling distribution \\[\\small \\overline{X}_1 - \\overline{X}_2 \\sim N\\left(\\mu_1 - \\mu_2, \\frac{\\sigma_1^2}{n_1} \\color{red}{+} \\color{black}{\\frac{\\sigma_2^2}{n_2}} \\right). \\] Before careful that the variance is the sum of the variance of \\(\\overline{X}_1\\) and \\(\\overline{X}_2\\), even the random variable is their difference. Please take MATH 4700 Introduction to Probability to learn more about the properties of normal distribution.\nTherefore by standardization, we have a standard normal variable \\[\\small Z = \\frac{(\\overline{X}_1 - \\overline{X}_2) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}} \\sim N(0, 1)\\]\n Test Statistic for Independent Samples \\((\\sigma_1 \\ne \\sigma_2)\\) \nWith \\(D_0\\) being a hypothesized value, our testing problem could be one of the followings\n\n \\(\\small \\begin{align} &H_0: \\mu_1 - \\mu_2 \\le D_0\\\\ &H_1: \\mu_1 - \\mu_2 > D_0 \\end{align}\\)  (right-tailed)\n \\(\\small \\begin{align} &H_0: \\mu_1 - \\mu_2 \\ge D_0\\\\ &H_1: \\mu_1 - \\mu_2 < D_0 \\end{align}\\)  (left-tailed)\n \\(\\small \\begin{align} &H_0: \\mu_1 - \\mu_2 = D_0\\\\ &H_1: \\mu_1 - \\mu_2 \\ne D_0 \\end{align}\\)  (two-tailed)\n\nOften, we care about of the two means are equal, so \\(D_0\\) is zero. But \\(D_0\\) could be any number that fits your research question. For example, you may wonder if mean weight of male is greater than the mean weight of female by 20 pounds. Then your \\(H_1\\) would be \\(H_1: \\mu_1 - \\mu_2 > 20\\) where \\(\\mu_1\\) is the mean weight of male and \\(\\mu_2\\) is the mean weight of female, and \\(D_0\\) is 20.\nIf \\(\\sigma_1\\) and \\(\\sigma_2\\) are known, with the \\(\\overline{x}_1\\), \\(\\overline{x}_2\\) calculated by our sample, and under the null hypothesis, the test statistic is the z-score from the sampling distribution which is \\[z_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}.\\]\nThen we are pretty much done. We find \\(z_{\\alpha}\\) or \\(z_{\\alpha/2}\\) and follow our testing steps!\nWhat if \\(\\sigma_1\\) and \\(\\sigma_2\\) are unknown? You should be able to sense the answer. The test statistic becomes \\(t_{test}\\):\n\\[t_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\color{red}{s_1^2}}{n_1} + \\frac{\\color{red}{s_2^2}}{n_2}}} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{\\sqrt{\\frac{\\color{red}{s_1^2}}{n_1} + \\frac{\\color{red}{s_2^2}}{n_2}}}. \\]\nWe simply replace the unknown \\(\\sigma_1\\) and \\(\\sigma_2\\) with their corresponding sample estimate \\(s_1\\) and \\(s_2\\)! The critical value is either \\(t_{\\alpha, df}\\) (one-tailed) or \\(t_{\\alpha/2, df}\\) (two-tailed) with the degrees of freedom\n\\[df = \\dfrac{(A+B)^2}{\\dfrac{A^2}{n_1-1}+ \\dfrac{B^2}{n_2-1}},\\] where \\(\\small A = \\dfrac{s_1^2}{n_1}\\) and \\(\\small B = \\dfrac{s_2^2}{n_2}\\).\nThe degrees of freedom looks intimidating, but no worries you donâ€™t need to memorize the formula, and we let the statistical software take care of it. To be conservative (tend to reject \\(H_0\\) less) if the \\(df\\) is not an integer, we round it down to the nearest integer, it does not matter much though.\n Inference About Independent Samples \\((\\sigma_1 \\ne \\sigma_2)\\) \nBelow is a table that summarizes ways to make inferences about independent samples when \\((\\sigma_1 \\ne \\sigma_2)\\).\n\n\n\n\n\n\n\n\\(\\large \\color{red}{\\sigma_1 \\ne \\sigma_2}\\)\nTest Statistic\nConfidence Interval for \\(\\mu_1 - \\mu_2\\)\n\n\n\n\nknown\n\\(\\large z_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}\\)\n\\(\\large (\\overline{x}_1 - \\overline{x}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\\)\n\n\nunknown\n\\(\\large t_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{\\sqrt{\\frac{\\color{red}{s_1^2}}{n_1} + \\frac{\\color{red}{s_2^2}}{n_2}}}\\)\n\\(\\large (\\overline{x}_1 - \\overline{x}_2) \\pm t_{\\alpha/2, df} \\sqrt{\\frac{\\color{red}{s_1^2}}{n_1} + \\frac{\\color{red}{s_2^2}}{n_2}}\\)\n\n\n\nFor unknown \\(\\sigma_1\\) and \\(\\sigma_2\\), we use \\(\\small df = \\dfrac{(A+B)^2}{\\dfrac{A^2}{n_1-1}+ \\dfrac{B^2}{n_2-1}},\\) where \\(\\small A = \\dfrac{s_1^2}{n_1}\\) and \\(\\small B = \\dfrac{s_2^2}{n_2}\\) to get the \\(p\\)-value, critical value and confidence interval. The unequal-variance t-test is called Welchâ€™s t-test in the literature.\n Example: Two-Sample t-Test \n\n\nDoes an over-sized tennis racket exert less stress/force on the elbow? The relevant sample statistics are shown below.\n\n\nOver-sized: \\(n_1 = 33\\), \\(\\overline{x}_1 = 25.2\\), \\(s_1 = 8.6\\)\n\n\nConventional: \\(n_2 = 12\\), \\(\\overline{x}_2 = 33.9\\), \\(s_2 = 17.4\\)\n\n\nThe two populations are known to be nearly normal, and because of the large difference in the sample standard deviation suggests \\(\\sigma_1 \\ne \\sigma_2\\). Please form a hypothesis test with \\(\\alpha = 0.05\\), and construct a 95% CI for the mean difference of force on the elbow.\n\n\n\n\n\nSource: unsplash-Jeffery Erhunse\n\n\n\n\n\n\n Step 1 \n\nLet \\(\\mu_1\\) be the mean force on the elbow for the over-size rackets, and \\(\\mu_2\\) be the mean force for the conventional rackets. The we have a test  \\(\\begin{align} &H_0: \\mu_1 = \\mu_2 \\\\ &H_1: \\mu_1 < \\mu_2 \\end{align}\\) \n\n\n Step 2 \n\n \\(\\alpha = 0.05\\) \n\n Step 3 \n\n \\(t_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - (\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\color{red}{s_1^2}}{n_1} + \\frac{\\color{red}{s_2^2}}{n_2}}} = \\frac{(25.2 - 33.9) - 0}{\\sqrt{\\frac{\\color{red}{8.6^2}}{33} + \\frac{\\color{red}{17.4^2}}{12}}} = -1.66\\)\n\n\\(\\small df = \\dfrac{(A+B)^2}{\\dfrac{A^2}{n_1-1}+ \\dfrac{B^2}{n_2-1}},\\) \\(\\small A = \\dfrac{s_1^2}{n_1}\\) and \\(\\small B = \\dfrac{s_2^2}{n_2}\\)\n\n\n\\(\\small A = \\dfrac{8.6^2}{33}\\), \\(\\small B = \\dfrac{17.4^2}{12}\\), \\(\\small df = \\dfrac{(A+B)^2}{\\dfrac{A^2}{33-1}+ \\dfrac{B^2}{12-1}} = 13.01\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the computed value of \\(df\\) is not an integer, always round down to the nearest integer.\n\n\n Step 4-c \n\nBecause it is a left-tailed test, the critical value is  \\(-t_{0.05, 13} = -1.771\\). \n\n\n Step 5-c \n\n We reject \\(H_0\\) if \\(\\small t_{test} < -t_{\\alpha, df}\\). \\(\\small t_{test} = -1.66 > -1.771 = -t_{\\alpha, df}\\), we fail to reject \\(H_0\\). \n\n Step 6 \n\n There is insufficient evidence to support the claim that the the oversized racket delivers less stress to the elbow. \n\nThe 95% CI for \\(\\mu_1 - \\mu_2\\) is\n\\[\\begin{align}(\\overline{x}_1 - \\overline{x}_2) \\pm t_{\\alpha/2, df} \\sqrt{\\frac{\\color{red}{s_1^2}}{n_1} + \\frac{\\color{red}{s_2^2}}{n_2}} &= (25.2 - 33.9) \\pm t_{0.025,13}\\sqrt{\\frac{8.6^2}{33} + \\frac{17.4^2}{12}}\\\\&= -8.7 \\pm 11.32 = (-20.02, 2.62).\\end{align}\\]\nWe are 95% confident that the difference in the mean forces is between -20.02 and 2.62. Since the interval includes 0, it leads to the same conclusion as failing to reject \\(H_0\\).\n Two-Sample t-Test in R \n\n## Prepare needed variables \nn1 = 33; x1_bar = 25.2; s1 = 8.6\nn2 = 12; x2_bar = 33.9; s2 = 17.4\nA <- s1^2 / n1; B <- s2^2 / n2\ndf <- (A + B)^2 / (A^2/(n1-1) + B^2/(n2-1))\n\n## Use floor() function to round down to the nearest integer.\n(df <- floor(df))\n\n[1] 13\n\n## t_test\n(t_test <- (x1_bar - x2_bar) / sqrt(s1^2/n1 + s2^2/n2))\n\n[1] -1.659894\n\n## t_cv\nqt(p = 0.05, df = df)\n\n[1] -1.770933\n\n## p_value\npt(q = t_test, df = df)\n\n[1] 0.06042575\n\n\n\n Testing for Independent Samples (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)) \nWeâ€™ve done the case that \\(\\sigma_1 \\ne \\sigma_2\\). Now we are talking about the case when \\(\\sigma_1 = \\sigma_2\\). Because they are equal, the two \\(\\sigma\\)s can be treated as one common \\(\\sigma\\).\n Sampling Distribution of \\(\\overline{X}_1 - \\overline{X}_2\\) \nAgain, we start with the sampling distribution of \\(\\overline{X}_1 - \\overline{X}_2\\) \\[\\overline{X}_1 - \\overline{X}_2 \\sim N\\left(\\mu_1 - \\mu_2, \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2} \\right).\\] If \\(\\sigma_1 = \\sigma_2 = \\sigma\\), we can write \\[\\overline{X}_1 - \\overline{X}_2 \\sim N\\left(\\mu_1 - \\mu_2, \\sigma^2\\left(\\frac{1}{n_1} + \\frac{1}{n_2} \\right) \\right).\\] Therefore, \\[ Z = \\frac{(\\overline{X}_1 - \\overline{X}_2) - (\\mu_1 - \\mu_2)}{\\sigma\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} \\sim N(0, 1).\\]\n Test Statistic for Independent Samples \\((\\sigma_1 = \\sigma_2 = \\sigma)\\) \nSimilar to the case that \\(\\sigma_1 = \\sigma_2\\), if \\(\\sigma_1\\) and \\(\\sigma_2\\) are known, the test statistic is the z-score of \\(\\overline{X}_1 - \\overline{X}_2\\) under \\(H_0\\): \\[z_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - (\\mu_1 - \\mu_2)}{\\sigma\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{\\sigma\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} \\]\nIf \\(\\sigma_1\\) and \\(\\sigma_2\\) are unknown, we use \\(t_{test}\\) just like we would for the one-sample case. Now here is the key point. We donâ€™t know the common \\(\\sigma\\). How do we use the two independent samples to construct one point estimate of \\(\\sigma\\), so that the estimate can replace \\(\\sigma\\) in the z-score to get the \\(t\\) test statistic?\n\nThe idea is to use the so-called pooled sample variance to estimate the common population variance, \\(\\sigma^2\\):\n\\[ s_p^2 = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2} \\]\nAs \\(\\sigma_1 = \\sigma_2 = \\sigma\\), we just need one sample standard deviation to replace the population standard deviation, \\(\\sigma\\). The two samples are from the populations with the same variance, and \\(s_1^2\\) and \\(s_2^2\\) are estimating the same population variance. But we just need one estimate. The idea is to combine the two sample variances \\(s_1^2\\) and \\(s_2^2\\) together, so that we can use all the information from the two samples to obtain one single point estimate \\(s_p^2\\) for \\(\\sigma^2\\). The pooled estimate \\(s_p^2\\) is in fact the weighted average of \\(s_1^2\\) and \\(s_2^2\\) weighted by their corresponding degrees of freedom \\(n_1-1\\) and \\(n_2-1\\). The idea is that when the sample size is large, we tend to get a more precise estimate. So \\(s_p^2\\) would be closer to \\(s_1^2\\) or \\(s_2^2\\) whichever has large sample size.\n\nIf \\(\\sigma_1\\) and \\(\\sigma_2\\) are unknown, we replace \\(\\sigma\\) with \\(s_p\\) and get the \\(t\\) test statistic\n\\[t_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - (\\mu_1 - \\mu_2)}{{\\color{red}{s_p}}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{{\\color{red}{s_p}}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\\] Here, the critical value is either \\(t_{\\alpha, df}\\) (for one-tailed tests) or \\(t_{\\alpha/2, df}\\) (for two-tailed tests), and the \\(t\\) distribution used to compute the \\(p\\)-value has the degrees of freedom \\[df = n_1 + n_2 - 2\\] Yes, that simple.\n Inference from Independent Samples \\((\\sigma_1 = \\sigma_2 = \\sigma)\\) \nBelow is a table that summarizes ways to make inferences about independent samples when \\(\\sigma_1 = \\sigma_2\\).\n\n\n\n\n\n\n\n\\(\\large \\color{red}{\\sigma_1 = \\sigma_2}\\)\nTest Statistic\nConfidence Interval for \\(\\mu_1 - \\mu_2\\)\n\n\n\n\nknown\n\\(\\large z_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{\\sigma\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\\)\n\\(\\large (\\overline{x}_1 - \\overline{x}_2) \\pm z_{\\alpha/2} \\sigma \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\\)\n\n\nunknown\n\\(\\large t_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{{\\color{red}{s_p}}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\\)\n\\(\\large (\\overline{x}_1 - \\overline{x}_2) \\pm t_{\\alpha/2, df} {\\color{red}{s_p}}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\\)\n\n\n\n\n\\(s_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}\\)\nUse \\(df = n_1+n_2-2\\) to get the \\(p\\)-value, critical value and confidence interval.\nThe test from two independent samples with \\(\\sigma_1 = \\sigma_2 = \\sigma\\) is usually called two-sample pooled \\(z\\)-test or two-sample pooled \\(t\\)-test.\n\n Example: Weight Loss \n\n\nA study was conducted to see the effectiveness of a weight loss program. Two groups (Control and Experimental) of 10 subjects were selected. The two populations are normally distributed and have the same standard deviation.\n\n\n\n\n\n\n\n\n\n\n\nThe data on weight loss was collected at the end of six months, and the revelant sample statistics\n\nControl: \\(n_1 = 10\\), \\(\\overline{x}_1 = 2.1\\, lb\\), \\(s_1 = 0.5\\, lb\\)\nExperimental: \\(n_2 = 10\\), \\(\\overline{x}_2 = 4.2\\, lb\\), \\(s_2 = 0.7\\, lb\\)\n\nIs there a sufficient evidence at \\(\\alpha = 0.05\\) to conclude that the program is effective? If yes, construct a 95% CI for \\(\\mu_1 - \\mu_2\\) to show how much effective it is.\n Step 1 \n\nLet \\(\\mu_1\\) be the mean weight loss in the control group, and \\(\\mu_2\\) be the mean weight loss in the experimental group. Then we have  \\(\\begin{align} &H_0: \\mu_1 = \\mu_2 \\\\ &H_1: \\mu_1 < \\mu_2 \\end{align}\\) \n\n\n\\(\\mu_1 < \\mu_2\\) means the weight loss program, the program the experimental group are in, is effective because on average the participants in the the experimental group loss weights more than those in the control group.\n Step 2 \n\n \\(\\alpha = 0.05\\) \n\n Step 3 \n\nFrom the question we know \\(\\sigma_1 = \\sigma_2\\). So the test statistic is  \\(t_{test} = \\frac{(\\overline{x}_1 - \\overline{x}_2) - \\color{blue}{D_0}}{{\\color{red}{s_p}}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\\). \n\n\\(s_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}} = \\sqrt{\\frac{(10-1)0.5^2 + (10-1)0.7^2}{10+10-2}}=0.6083\\)\n \\(t_{test} = \\frac{(2.1 - 4.2) - 0}{0.6083\\sqrt{\\frac{1}{10} + \\frac{1}{10}}} = -7.72\\)\n\n\n\n Step 4-c \n\n \\(df = n_1 + n_2 - 2 = 10 + 10 - 2 = 18\\). So \\(-t_{0.05, df = 18} = -1.734\\). \n\n Step 5-c \n\n We reject \\(H_0\\) if \\(\\small t_{test} < -t_{\\alpha, df}\\). Since \\(\\small t_{test} = -7.72 < -1.734 = -t_{\\alpha, df}\\), we reject \\(H_0\\).\n\n Step 4-p \n\n The \\(p\\)-value is \\(P(T_{df=18} < t_{test}) \\approx 0\\) \n\n Step 5-p \n\n We reject \\(H_0\\) if \\(p\\)-value < \\(\\alpha\\). Since \\(p\\)-value \\(\\approx 0 < 0.05 = \\alpha\\), we reject \\(H_0\\).\n\n Step 6 \n\n There is sufficient evidence to support the claim that the weight loss program is effective. \n\nThe 95% CI for \\(\\mu_1 - \\mu_2\\) is \\[\\begin{align}(\\overline{x}_1 - \\overline{x}_2) \\pm t_{\\alpha/2, df} {\\color{red}{s_p}}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} &= (2.1 - 4.2) \\pm t_{0.025, 18} (0.6083)\\sqrt{\\frac{1}{10} + \\frac{1}{10}}\\\\ &= -2.1 \\pm 0.572 = (-2.672, -1.528) \\end{align}\\]\nWe are 95% confident that the difference in the mean weight loss is between -2.672 and -1.528. Since the interval does not include 0, it leads to the same conclusion as rejection of \\(H_0\\).\n Two-Sample Pooled t-Test in R \n\n## Prepare values\nn1 = 10; x1_bar = 2.1; s1 = 0.5\nn2 = 10; x2_bar = 4.2; s2 = 0.7\n\n## pooled sample standard deviation\nsp <- sqrt(((n1 - 1) * s1 ^ 2 + (n2 - 1) * s2 ^ 2) / (n1 + n2 - 2))\n\n## degrees of freedom\ndf <- n1 + n2 - 2\n\n## t_test\n(t_test <- (x1_bar - x2_bar) / (sp * sqrt(1 / n1 + 1 / n2)))\n\n[1] -7.719754\n\n## t_cv\nqt(p = 0.05, df = df)\n\n[1] -1.734064\n\n## p_value\npt(q = t_test, df = df)\n\n[1] 2.028505e-07"
  },
  {
    "objectID": "infer-twomean.html#exercises",
    "href": "infer-twomean.html#exercises",
    "title": "16Â  Comparing Two Population Means",
    "section": "\n16.4 Exercises",
    "text": "16.4 Exercises\n\nA study was conducted to assess the effects that occur when children are expected to cocaine before birth. Children were tested at age 4 for object assembly skill, which was described as â€œa task requiring visual-spatial skills related to mathematical competence.â€ The 187 children born to cocaine users had a mean of 7.1 and a standard deviation of 2.5. The 183 children not exposed to cocaine had a mean score of 8.4 and a standard deviation of 2.5.\n\nWith \\(\\alpha = 0.05\\), use the critical-value method and p-value method to perform a 2-sample t-test on the claim that prenatal cocaine exposure is associated with lower scores of 4-year-old children on the test of object assembly.\nTest the claim in part (a) by using a confidence interval.\n\n\nListed below are heights (in.) of mothers and their first daughters.\n\nUse \\(\\alpha = 0.05\\) to test the claim that there is no difference in heights between mothers and their first daughters.\nTest the claim in part (a) by using a confidence interval.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeight of Mother\n66\n62\n62\n63.5\n67\n64\n69\n65\n62.5\n67\n\n\nHeight of Daughter\n67.5\n60\n63.5\n66.5\n68\n65.5\n69\n68\n65.5\n64"
  },
  {
    "objectID": "infer-var.html#inference-for-one-population-variance",
    "href": "infer-var.html#inference-for-one-population-variance",
    "title": "17Â  Inference About Variances",
    "section": "\n17.1 Inference for One Population Variance",
    "text": "17.1 Inference for One Population Variance\n\n Inference for Population Variances \nLetâ€™s start with inference for one population variance. For point estimation, the most intuitive and straightforward point estimator for \\(\\sigma^2\\) is the sample variance \\(S^2\\) defined as\n\\[S^2 = \\frac{\\sum_{i=1}^n(X_i - \\overline{X})^2}{n-1}.\\]\nNote that the the denominator is \\(n-1\\), not the sample size \\(n\\). Note that \\(S^2\\) is a random variable because each data point \\(X_i\\) and \\(\\overline{X}\\) are assumed random variables. Dividing by \\(n-1\\) instead of \\(n\\) actually means something. \\(S^2\\) is an unbiased estimator for \\(\\sigma^2\\), i.e., \\(E(S^2) = \\sigma^2\\), which is a good property of a point estimator. If we were able to repeatedly collect data sets of the same size \\(n\\) lots of times, and for each data set we obtain its sample variance, then the average sample variance will be, if not exactly, very close to the true population variance.\nThe inference methods for \\(\\sigma^2\\) introduced in this chapter require the population to be normally distributed.\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nThe inference methods can work poorly if normality is violated, even if the sample is large.\n\n\n\n\n\n\n\n Chi-Square \\(\\chi^2\\) Distribution \nRemember that when we do the inference for population means, we use either normal distribution or Studentâ€™s \\(t\\) distribution. For the inference about the population variances, we use another distribution called chi-square \\(\\chi^2\\) distribution because the distribution is related to the sampling distribution of some variable involving \\(S^2\\) and \\(\\sigma^2\\). Weâ€™ll talk about that later. Letâ€™s first learn a little about the chi-square \\(\\chi^2\\) distribution.\n\n\n\n\nAs Studentâ€™s \\(t\\) distribution, the chi-square \\(\\chi^2\\) distribution has one parameter, degrees of freedom \\(df\\). To denote a specific chi-square distribution, we write \\(\\chi^2_{df}\\) like \\(\\chi^2_{2}\\) for a chi-square distribution or variable with degrees of freedom two. FigureÂ 17.1 shows \\(\\chi^2\\) distributions with varying degrees of freedom. It is in general a right-skewed distribution, but it gets more and more symmetric as \\(df\\) gets larger. Also, the \\(\\chi^2\\) distribution is defined over positive numbers, one hint why we use it for inferring variances because variance is non-negative, but normal or \\(t\\) distribution is defined on the whole real line.\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 17.1: Illustration of \\(\\chi^2\\) distributions with varying degrees of freedom\n\n\n\n\n\n\n Upper Tail and Lower Tail of Chi-Square \nLike standard normal and \\(t\\) distribution, to do the inference for variances, we get to find or define critical values of a chi-square distribution. With some probability \\(\\alpha\\), we define\n\n\\(\\chi^2_{\\frac{\\alpha}{2},\\, df}\\) is a \\(\\chi^2\\) value of a \\(\\chi^2\\) distribution with degrees of freedom \\(df\\) such that it has area to the right of \\(\\alpha/2\\).\n\\(\\chi^2_{1-\\frac{\\alpha}{2},\\, df}\\) is a \\(\\chi^2\\) value of a \\(\\chi^2\\) distribution with degrees of freedom \\(df\\) such that it has area to the left of \\(\\alpha/2\\). In other words, it has area to the right of \\(1 - \\alpha/2\\), and thatâ€™s why it has a subscript \\(1-\\frac{\\alpha}{2}\\).\n\nFigureÂ 17.2 illustrates the \\(\\chi^2\\) critical values. Notice that in \\(N(0, 1)\\), \\(z_{1-\\frac{\\alpha}{2}} = -z_{\\frac{\\alpha}{2}}\\). Because of the symmetry of the distribution, the \\(z\\)-value having area \\(\\alpha/2\\) on the right is the \\(z\\)-value having area \\(\\alpha/2\\) on the left with a negative sign. However, the chi-square distribution is not symmetric, so \\(\\chi^2_{1-\\frac{\\alpha}{2},\\,df} \\ne -\\chi^2_{\\frac{\\alpha}{2},\\,df}\\).\n\n\n\n\n\nFigureÂ 17.2: Illustration of \\(\\alpha/2\\) significance levels for \\(\\chi^2_{df}\\) distribution\n\n\n\n\n Sampling Distribution \nWhen a random sample of size \\(n\\) is from \\(\\color{red}{N(\\mu, \\sigma^2)}\\), the following sample statistic has the \\(\\chi^2\\) sampling distribution with degrees of freedom \\(n-1\\): \\[ \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1}. \\]\nI would like to stress again that the inference method for \\(\\sigma^2\\) introduced here can work poorly if the normality assumption is violated, even for large samples.\nThe sample statistic involves \\(S^2\\) and \\(\\sigma^2\\), so we have manipulate its sampling distribution to obtain the confidence interval for \\(\\sigma^2\\), and use it as a test statistic in the hypothesis testing for \\(\\sigma^2\\).\n \\((1-\\alpha)100\\%\\) Confidence Interval for \\(\\sigma^2\\) \nThe \\((1-\\alpha)100\\%\\) confidence interval for \\(\\sigma^2\\) is \\[\\color{blue}{\\boxed{\\left( \\frac{(n-1)S^2}{\\chi^2_{\\frac{\\alpha}{2}, \\, n-1}}, \\frac{(n-1)S^2}{\\chi^2_{1-\\frac{\\alpha}{2}, \\, n-1}} \\right)}}\\]\nHow do we get this interval? We start with the sampling distribution of $ $.\n\n\n\\(P\\left(\\chi^2_{1-\\frac{\\alpha}{2}, \\,n-1} < \\frac{(n-1)S^2}{\\sigma^2} < \\chi^2_{\\frac{\\alpha}{2},\\, n-1} \\right) = 1 - \\alpha\\) (Goal: isolate \\(\\sigma^2\\))\n\n\\(P\\left(\\frac{\\chi^2_{1-\\frac{\\alpha}{2}, \\,n-1}}{(n-1)S^2} < \\frac{1}{\\sigma^2} < \\frac{\\chi^2_{\\frac{\\alpha}{2},\\, n-1}}{(n-1)S^2} \\right) = 1 - \\alpha\\) (divided by \\((n-1)S^2\\))\n\n\\(P\\left(\\frac{(n-1)S^2}{\\chi^2_{1-\\frac{\\alpha}{2}, \\, n-1}} > \\sigma^2 > \\frac{(n-1)S^2}{\\chi^2_{\\frac{\\alpha}{2}, \\,n-1}} \\right) = 1 - \\alpha\\) (take reciprocal)\n\n\\(P\\left(\\frac{(n-1)S^2}{\\chi^2_{\\frac{\\alpha}{2}, \\, n-1}} < \\sigma^2 < \\frac{(n-1)S^2}{\\chi^2_{1-\\frac{\\alpha}{2}, \\,n-1}} \\right) = 1 - \\alpha\\) (smaller value on the left)\n\nBe careful that the interval for \\(\\sigma^2\\) cannot be expressed as \\((S^2 - m, S^2 + m)\\) for some margin of error \\(m\\) anymore!\n\n\n\n\n Example: Supermodel Heights \n\n\nListed below are heights (cm) for the simple random sample of 16 female supermodels.\n\nheights <- c(178, 177, 176, 174, 175, 178, 175, 178, \n             178, 177, 180, 176, 180, 178, 180, 176)\n\nThe supermodelsâ€™ heights are normally distributed. Please construct a \\(95\\%\\) confidence interval for population standard deviation \\(\\sigma\\).\n\n\n\n\n\n\n\n\n\n\n\nWe just need to get what we need for constructing the interval from the sample data, sample size \\(n\\), sample variance \\(s^2\\), \\(\\alpha\\), critical values \\(\\chi^2_{\\alpha/2, n-1}\\) and \\(\\chi^2_{1-\\alpha/2, n-1}\\).\n\n\n\\(n = 16\\), \\(s^2 = 3.4\\), \\(\\alpha = 0.05\\).\n\\(\\chi^2_{\\alpha/2, n-1} = \\chi^2_{0.025, 15} = 27.49\\)\n\\(\\chi^2_{1-\\alpha/2, n-1} = \\chi^2_{0.975, 15} = 6.26\\)\n\nNote that we want the interval for \\(\\sigma\\), not \\(\\sigma^2\\), we take a square root of the lower and upper bound of the interval for \\(\\sigma^2\\). The \\(95\\%\\) CI for \\(\\sigma\\) is \\(\\small \\left( \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{\\frac{\\alpha}{2}, \\, n-1}}}, \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{1-\\frac{\\alpha}{2}, \\, n-1}}} \\right) = \\left( \\sqrt{\\frac{(16-1)(3.4)}{27.49}}, \\sqrt{\\frac{(16-1)(3.4)}{6.26}}\\right) = (1.36, 2.85)\\)\nWe are 95% confident that the height of supermodels has standard deviation between 1.36 and 2.85.\n Confidence Interval Computation in R \nWe use qchisq() to get the \\(\\chi^2\\) critical values. The probability \\(p\\) and the degrees of freedom df need to be specified. You should be able to understand the rest part of the code. Enjoy it.\n\n## set values\nn <- 16\ns2 <- var(heights)\nalpha <- 0.05\n\n## two chi-square critical values\nchi2_right <- qchisq(p = alpha/2, df = n - 1, lower.tail = FALSE)\nchi2_left <- qchisq(p = alpha/2, df = n - 1, lower.tail = TRUE)\n\n## two bounds of CI for sigma2\nci_sig2_lower <- (n - 1) * s2 / chi2_right\nci_sig2_upper <- (n - 1) * s2 / chi2_left\n\n## two bounds of CI for sigma\n(ci_sig_lower <- sqrt(ci_sig2_lower))\n\n[1] 1.362104\n\n(ci_sig_upper <- sqrt(ci_sig2_upper))\n\n[1] 2.853802\n\n\n Testing \nBack to the example. Use \\(\\alpha = 0.05\\) to test the claim that â€œsupermodels have heights with a standard deviation that is less than the standard deviation, \\(\\sigma = 7.5\\) cm, for the population of womenâ€.\n Step 1 \n\nWe are comparing the \\(\\sigma\\) of heights of supermodels with the \\(\\sigma\\) of heights of women in general which is 7.5. So the hypothesize value \\(\\sigma_0\\) is 7.5. We wonder if supermodel height standard deviation is smaller than 7.5. Therefore, we have test \\(H_0: \\sigma = \\sigma_0\\) vs.Â \\(H_1: \\sigma < \\sigma_0\\), where \\(\\sigma_0 = 7.5\\) cm.\n\n Step 2 \n\n\\(\\alpha = 0.05\\)\n\n Step 3 \n\nThe test statistic comes from the variable \\(\\chi_{test}^2 = \\frac{(n-1)S^2}{\\sigma^2}\\) that follows \\(\\chi^2_{n-1}\\) distribution. Under \\(H_0\\), we have \\(\\chi_{test}^2 = \\frac{(n-1)s^2}{\\sigma_0^2} = \\frac{(16-1)(3.4)}{7.5^2} = 0.91\\), drawn from \\(\\chi^2_{n-1}\\).\n\n Step 4-c \n\nThis is a left-tailed test.\nThe critical value is \\(\\chi_{1-\\alpha, df}^2 = \\chi_{0.95, 15}^2 = 7.26\\)\n\n\n Step 5-c \n\nReject \\(H_0\\) in favor of \\(H_1\\) if \\(\\chi_{test}^2 < \\chi_{1-\\alpha, df}^2\\).\nSince \\(0.91 < 7.26\\), we reject \\(H_0\\). \n\n\n\n\n\n\n\n\n\n\n\n\n Step 6 \n\nThere is sufficient evidence to support the claim that supermodels have heights with a standard deviation that is less than the standard deviation for the population of all women.\n\nWe conclude that the heights of supermodels vary less than heights of women in the general women population.\n\n Back to Pooled t-Test \nIn a two sample pooled t-test, we assume\n\n \\(n_1 \\ge 30\\) and \\(n_2 \\ge 30\\) or that both samples are drawn from normal populations. \n \\(\\sigma_1 = \\sigma_2\\) \n\nWe can use a QQ-plot (and normality tests, Anderson, Shapiro, etc.) to check the assumption of a normal distribution. We now learn how to check the assumption \\(\\sigma_1 = \\sigma_2\\)."
  },
  {
    "objectID": "infer-var.html#inference-for-comparing-two-population-variances",
    "href": "infer-var.html#inference-for-comparing-two-population-variances",
    "title": "17Â  Inference About Variances",
    "section": "\n17.2 Inference for Comparing Two Population Variances",
    "text": "17.2 Inference for Comparing Two Population Variances\n F Distribution \nFor comparing two population variances, we need another distribution called \\(F\\) distribution. The \\(F\\) distribution has two parameters \\(df_1\\) and \\(df_2\\), a hint why it is used for comparing two variances. We write a specific \\(F\\) distribution \\(F_{df_1, df_2}\\). Second, the \\(F\\) distribution is also right-skewed. Like \\(\\chi^2\\) distribution, the \\(F\\) distribution is defined over positive numbers. FigureÂ 17.3 illustrates \\(F\\) distribution with different parameters. You can see that when \\(df_1\\) and \\(df_2\\) are both large, the \\(F\\) distribution looks bell-shaped.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 17.3: F distributions with different parameters.\n\n\n\n\n\n\n Upper and Lower Tail of F Distribution \nWe denote \\(F_{\\alpha, \\, df_1, \\, df_2}\\) as the \\(F\\) quantile such that \\(P(F_{df_1, df_2} > F_{\\alpha, \\, df_1, \\, df_2}) = \\alpha\\). With it, we can find the critical values \\(F_{\\frac{\\alpha}{2}, \\, df_1, \\, df_2}\\) and \\(F_{1-\\frac{\\alpha}{2}, \\, df_1, \\, df_2}\\) used in constructing the confidence interval for the ratio \\(\\sigma^2_1/\\sigma^2_2\\) discussed next.\n\n\n\n\nFigureÂ 17.4: Illustration of \\(\\alpha/2\\) significance levels for \\(F_{df_1, df_2}\\) distribution\n\n\n\n\nSampling Distribution \nWhen random samples of sizes \\(n_1\\) and \\(n_2\\) have been independently drawn from two normally distributed populations, \\(N(\\mu_1, \\sigma_1^2)\\) and \\(N(\\mu_2, \\sigma_2^2)\\) respectively, the ratio \\(\\frac{S_1^2/S_2^2}{\\sigma_1^2/\\sigma_2^2}\\) has the \\(F\\) sampling distribution \\[\\frac{S_1^2/S_2^2}{\\sigma_1^2/\\sigma_2^2} \\sim F_{n_1-1, \\, n_2-1}.\\]\n\n\n\n\n\n\nImportant\n\n\n\n\nThe order of degrees of freedom matters! \\(F_{n_1-1, \\, n_2-1} \\ne F_{n_2-1, \\, n_1-1}\\). Please donâ€™t mess around.\n\n\n\n \\((1-\\alpha)100\\%\\) Confidence Interval for \\(\\sigma_1^2 / \\sigma_2^2\\) \nFrom the sampling distribution of the ratio, the \\((1-\\alpha)100\\%\\) confidence interval for \\(\\sigma_1^2 / \\sigma_2^2\\) is \\[\\color{blue}{\\boxed{\\left( \\frac{s_1^2/s_2^2}{F_{\\alpha/2, \\, n_1 - 1, \\, n_2 - 1}}, \\frac{s_1^2/s_2^2}{F_{1-\\alpha/2, \\, \\, n_1 - 1, \\, n_2 - 1}} \\right)}}\\]\nHow do we get the interval? Not surprising. We start with the sampling distribution of \\(\\frac{S_1^2/S_2^2}{\\sigma_1^2/\\sigma_2^2}\\).\n\n\\(P\\left(F_{1-\\alpha/2, \\, n_1 - 1, \\, n_2 - 1} < \\frac{S_1^2/S_2^2}{\\sigma_1^2/\\sigma_2^2} < F_{\\alpha/2, \\, n_1 - 1, \\, n_2 - 1} \\right) = 1 - \\alpha\\) (Goal: isolate \\(\\sigma_1^2/\\sigma_2^2\\))\n\\(P\\left(\\frac{1}{F_{\\alpha/2, \\, n_1 - 1, \\, n_2 - 1}} < \\frac{\\sigma_1^2/\\sigma_2^2}{S_1^2/S_2^2} < \\frac{1}{F_{1-\\alpha/2, \\, n_1 - 1, \\, n_2 - 1}} \\right) = 1 - \\alpha\\) (take reciprocal)\n\\(P\\left(\\frac{S_1^2/S_2^2}{F_{\\alpha/2, \\, n_1 - 1, \\, n_2 - 1}} < \\frac{\\sigma_1^2}{\\sigma_2^2} < \\frac{S_1^2/S_2^2}{F_{1-\\alpha/2, \\, n_1 - 1, \\, n_2 - 1}} \\right) = 1 - \\alpha\\) (times \\(S_1^2/S_2^2\\))\n\n\n\n\n\n\n\nNote\n\n\n\nThe confidence interval for \\(\\sigma_1^2 / \\sigma_2^2\\) cannot be expressed as \\(\\left(\\frac{s_1^2}{s_2^2}-m, \\frac{s_1^2}{s_2^2} + m\\right)\\) anymore!\n\n\n\n F test for comparing \\(\\sigma_1^2\\) and \\(\\sigma_2^2\\) \n Step 1 \nFor comparing \\(\\sigma_1^2\\) and \\(\\sigma_2^2\\), the test can be either right-tailed or two-tailed. Left-tailed testing is not necessary because we can always define the population whose variance is hypothetically larger than the variance of another population as the first population.\n\nRight-tailed:  \\(\\small \\begin{align} &H_0: \\sigma_1 \\le \\sigma_2 \\\\ &H_1: \\sigma_1 > \\sigma_2 \\end{align}\\) \n\nTwo-tailed:  \\(\\small \\begin{align} &H_0: \\sigma_1 = \\sigma_2 \\\\ &H_1: \\sigma_1 \\ne \\sigma_2 \\end{align}\\) \n\n\n Step 2 \n\n\\(\\alpha = 0.05\\)\n\n Step 3 \n\nUnder \\(H_0\\), \\(\\sigma_1 = \\sigma_2\\), and the test statistic is \\[\\small F_{test} = \\frac{s_1^2/s_2^2}{\\sigma_1^2/\\sigma_2^2} = \\frac{s_1^2}{s_2^2} \\sim F_{n_1-1, \\, n_2-1}\\] The denominator is gone because the ratio is one.\n\n Step 4-c \n\nRight-tailed:  \\(F_{\\alpha, \\, n_1-1, \\, n_2-1}\\) .\nTwo-tailed:  \\(F_{\\alpha/2, \\, n_1-1, \\, n_2-1}\\) or \\(F_{1-\\alpha/2, \\, n_1-1, \\, n_2-1}\\) \n\n\n Step 5-c \n\nRight-tailed: reject \\(H_0\\) if  \\(F_{test} \\ge F_{\\alpha, \\, n_1-1, \\, n_2-1}\\).\nTwo-tailed: reject \\(H_0\\) if  \\(F_{test} \\ge F_{\\alpha/2, \\, n_1-1, \\, n_2-1}\\) or \\(F_{test} \\le F_{1-\\alpha/2, \\, n_1-1, \\, n_2-1}\\)\n\n\n\n Example: Weight Loss \nThis is our previous example.\n\n\nA study was conducted to see the effectiveness of a weight loss program. Two groups (Control and Experimental) of 10 subjects were selected. The two populations are normally distributed and have the same standard deviation.\n\n\n\n\n\n\n\n\n\n\n\nThe data on weight loss was collected at the end of six months.\n\n\nControl: \\(n_1 = 10\\), \\(\\overline{x}_1 = 2.1\\, lb\\), \\(s_1 = 0.5\\, lb\\)\n\n\nExperimental: \\(n_2 = 10\\), \\(\\overline{x}_2 = 4.2\\, lb\\), \\(s_2 = 0.7\\, lb\\)\n\n\n Check if \\(\\sigma_1 = \\sigma_2\\) \n\n\n\\(n_1 = 10\\), \\(s_1 = 0.5 \\, lb\\)\n\n\n\\(n_2 = 10\\), \\(s_2 = 0.7 \\, lb\\)\n\n\n Step 1 \n\n\\(\\begin{align} &H_0: \\sigma_1 = \\sigma_2 \\\\ &H_1: \\sigma_1 \\ne \\sigma_2 \\end{align}\\)\n\n Step 2 \n\n\\(\\alpha = 0.05\\)\n\n Step 3 \n\nThe test statistic is \\(F_{test} = \\frac{s_1^2}{s_2^2} = \\frac{0.5^2}{0.7^2} = 0.51\\).\n\n Step 4-c \n\nThis is a two-tailed test.\nThe critical value is \\(F_{0.05/2, \\, 10-1, \\, 10-1} = 4.03\\) or \\(F_{1-0.05/2, \\, 10-1, \\, 10-1} = 0.25\\).\n\n\n\n\n\n\n\n\n\n Step 5-c \n\nIs \\(F_{test} > 4.03\\) or \\(F_{test} < 0.25\\)?\n\nNo.Â \n\n\n\n Step 6 \n\nThe evidence is not sufficient to reject the claim that \\(\\sigma_1 = \\sigma_2\\).\n\n 95% CI for \\(\\sigma_1^2 / \\sigma_2^2\\) \n\n\n\n\\(\\small F_{\\alpha/2, \\, df_1, \\, df_2} = F_{0.05/2, \\, 10-1, \\, 10-1} = 4.03\\)\n\\(\\small F_{1-\\alpha/2, \\, df_1, \\, df_2} = F_{1-0.05/2, \\, 10-1, \\, 10-1} = 0.25\\)\n\\(\\small \\frac{s_1^2}{s_2^2} = \\frac{0.5^2}{0.7^2} = 0.51\\)\nThe 95% CI for \\(\\sigma_1^2 / \\sigma_2^2\\) is \\[\\small \\begin{align} &\\left( \\frac{s_1^2/s_2^2}{F_{\\alpha/2, \\, df_1, \\, df_2}}, \\frac{s_1^2/s_2^2}{F_{1-\\alpha/2, \\, df_1, \\, df_2}} \\right) \\\\ &= \\left( \\frac{0.51}{4.03}, \\frac{0.51}{0.25} \\right) = \\left(0.127, 2.05\\right)\\end{align}\\] \n\n\n\n\n\n\n\n\n\n\n\n\nWe are 95% confident that the ratio \\(\\sigma_1^2 / \\sigma_2^2\\) is between 0.127 and 2.04. Because one is included in this interval, meaning that \\(\\sigma^2_1 = \\sigma^2_2\\), it leads to the same conclusion as the F test.\n Implementing F-test in R \nWe use qf() to find the \\(F\\) critical values. \n\n\n\n## set values\nn1 <- 10; n2 <- 10\ns1 <- 0.5; s2 <- 0.7\nalpha <- 0.05\n\n## 95% CI for sigma_1^2 / sigma_2^2\nf_small <- qf(p = alpha / 2, df1 = n1 - 1, df2 = n2 - 1,lower.tail = TRUE)\nf_big <- qf(p = alpha / 2, df1 = n1 - 1, df2 = n2 - 1, lower.tail = FALSE)\n\n## lower bound\n(s1 ^ 2 / s2 ^ 2) / f_big\n\n[1] 0.1267275\n\n## upper bound\n(s1 ^ 2 / s2 ^ 2) / f_small\n\n[1] 2.054079\n\n\n\n\n\n\n\n## Testing sigma_1 = sigma_2\n(test_stats <- s1 ^ 2 / s2 ^ 2)\n\n[1] 0.5102041\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nIf we have the entire two samples data, we can use the R built-in function var.test(x, y, alternative = \"two.sided\") to perform a \\(F\\) test to compare the variances of two samples from normal populations. The arguments x and y are numeric vectors of data values. Argument alternative must be one of \"two.sided\" (default), \"greater\" or \"less\"."
  },
  {
    "objectID": "infer-var.html#exercises",
    "href": "infer-var.html#exercises",
    "title": "17Â  Inference About Variances",
    "section": "\n17.3 Exercises",
    "text": "17.3 Exercises\n\nThe data about male and female pulse rates are summarized below.\n\nConstruct a 95% CI for \\(\\sigma_{male}\\) of pulse rates for males.\nConstruct a 95% CI for \\(\\sigma_{male}/\\sigma_{female}\\).\nDoes it appear that the population standard deviations for males and females are different? Why or why not?\n\n\n\n\n\n\n\nMale\nFemale\n\n\n\n\\(\\overline{x}\\)\n71\n75\n\n\n\\(s\\)\n9\n12\n\n\n\\(n\\)\n14\n12"
  },
  {
    "objectID": "infer-prop.html#introduction",
    "href": "infer-prop.html#introduction",
    "title": "18Â  Inference About Proportions",
    "section": "\n18.1 Introduction",
    "text": "18.1 Introduction\n One Categorical Variable with Two Categories \n\nLet \\(X\\) be the categorical variable Gender with 2 categories, Male and Female.\n\n\n\n\n\nSubject\nMale\nFemale\n\n\n\n1\nx\n\n\n\n2\n\nx\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\nx\n\n\n\n\n\nOne-way frequency/count table\n\n\n\n\\(X\\)\nCount\n\n\n\nMale\n\\(y\\)\n\n\nFemale\n\\(n-y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe number of males can be viewed as a random variable because the count, \\(y\\), varies from sample to sample.\n\n\n\n\n\n\n\nWhat probability distribution might be appropriate for the count, \\(Y\\)?\n\n\n\n\n\n\n\n\n\n Probability Distribution for Count Data: Two Levels \n\n\n\\(binomial(n, \\pi)\\) could be a good option for count data with 2 categories.\n\nFixed number of trials.  (Fixed \\(n\\) subjects) \n\nEach trial results in one of two outcomes.  (Either \\(M\\) or \\(F\\)) \n\nTrials are independent.  (If the subjects are randomly sampled) \n\n\n\nIf the proportion of being in category, \\(M\\), is \\(\\pi\\), the count, \\(Y\\), has \\[P(Y = y \\mid n, \\pi) = \\frac{n!}{y!(n-y)!}\\pi^{y}(1-\\pi)^{n-y}\\]\n\nGoal: Estimate or test the population proportion, \\(\\pi\\), of the category, \\(M\\)."
  },
  {
    "objectID": "infer-prop.html#inference-for-a-single-proportion",
    "href": "infer-prop.html#inference-for-a-single-proportion",
    "title": "18Â  Inference About Proportions",
    "section": "\n18.2 Inference for a Single Proportion",
    "text": "18.2 Inference for a Single Proportion\n Hypothesis Testing for \\(\\pi\\) \nThe point estimator for the population proportion \\(\\pi\\) is the sample proportion \\(Y/n\\). The true probability is approximated by the relative frequency in the sample data. Letâ€™s first learn how to do testing for \\(\\pi\\). This is the one-sample proportion \\(z\\) test.\n\n Step 0: Method Assumptions \n\nThe method requires that  \\(n\\pi_0 \\ge 5\\) and \\(n(1-\\pi_0) \\ge 5\\)  where \\(\\pi_0\\) is the hypothesized value or the value to be tested. The larger \\(n\\pi_0\\) and \\(n(1-\\pi_0)\\) are, the better. In fact, the method relies on the central limit theorem, and uses standard normal distribution to do the test. Large \\(n\\pi_0\\) and \\(n(1-\\pi_0)\\) leads to better normal approximation.\n\n Step 1: Set the Null and Alternative Hypothesis \n\nWe are interested in the proportion of some category being equal to, greater than or less than some value.  \\(\\begin{align} &H_0: \\pi = \\pi_0 \\\\ &H_1: \\pi > \\pi_0 \\text{ or } \\pi < \\pi_0 \\text{ or } \\pi \\ne \\pi_0 \\end{align}\\) \n\n\n Step 2: Set the Significance Level, \\(\\alpha\\) \n Step 3: Calculate the Test Statistic \n\nWith the central limit theorem, it can be shown that the sampling distribution of the statistic \\(Y/n\\) is approximately normal with mean \\(\\pi\\) and standard error, \\(\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\). Therefore, \\[Z = \\frac{Y/n - \\pi}{\\sqrt{\\frac{\\pi(1-\\pi)}{n}}} \\dot\\sim N(0, 1).\\] Then under the null \\(H_0\\), the test statistic is  \\(z_{test} = \\dfrac{\\hat{\\pi} - \\pi_0}{\\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}}\\) where \\(\\hat{\\pi} = \\frac{y}{n}\\) is the realized sample proportion. \n\n\n Step 4-c: Find the Critical Value \\(z_{\\alpha}\\) (one-tailed) or \\(z_{\\alpha/2}\\) (two-tailed) \n\nSame as before.\n\n Step 5-c: Draw a Conclusion Using Critical Value Method \n\n \\(H_1: \\pi > \\pi_0\\): Reject \\(H_0\\) in favor of \\(H_1\\) if \\(z > z_{\\alpha}\\) \n \\(H_1: \\pi < \\pi_0\\): Reject \\(H_0\\) in favor of \\(H_1\\) if \\(z < -z_{\\alpha}\\) \n \\(H_1: \\pi \\ne \\pi_0\\): Reject \\(H_0\\) in favor of \\(H_1\\) if \\(|z| > z_{\\alpha/2}\\) \n\n Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim \n\n Confidence Interval for \\(\\pi\\) \nTo construct the confidence interval for \\(\\pi\\), we rely on some assumption too. Unlike testing that has a hypothesized value \\(\\pi_0\\), there is no hypothesized value in confidence interval, and we only use information from the data to get an interval. To ensure that the normal approximation is fairly good, the interval formula requires \\(n\\hat{\\pi} \\ge 5\\) and \\(n(1-\\hat{\\pi}) \\ge 5\\).  Can you see the difference between this requirement and the testing requirement?\n\n\nThe \\(100(1 - \\alpha)\\%\\) confidence interval for \\(\\pi\\) is \\[\\hat{\\pi} \\pm z_{\\alpha/2}\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\] where \\(\\hat{\\pi} = y/n\\). Since \\(\\pi\\) is unknown, we use its estimate \\(\\hat{\\pi}\\) instead: \\[\\hat{\\pi} \\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{\\pi}(1-\\hat{\\pi})}{n}}\\]\nSuch normal approximation interval is called the Wald interval.   \n\n Example: Exit Poll \nSuppose we collect data on 1,000 voters in an election with only two candidates, R and D, and every voter must vote for either one of them.\n\n\n\n\nVoter\nR\nD\n\n\n\n1\nx\n\n\n\n2\n\nx\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n1000\nx\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the data, we want to predict who won the election. Let \\(Y\\) be the number of voters that voted for R. Assume the count, \\(Y\\), is sampled from \\(binomial(n = 1000, \\pi)\\), and \\(\\pi = P(\\text{a voter voted for R}) =\\) (population) proportion of all voters that for R. Parameter \\(\\pi\\) is the unknown parameter to be estimated or tested. In an exit poll of 1,000 voters, 520 voted for R. At \\(\\alpha = 0.05\\), predict whether or not R won the election.\n\n\n\n\n Hypothesis Testing \n Step 0 \n\n\n\\(\\pi_0 = 1/2\\).  \\(n\\pi_0 = 1000(1/2) = 500 \\ge 5\\) and \\(n(1-\\pi_0) \\ge 5\\) \n\n\n Step 1 \n\n\nR won the election means that the proportion of all voters voting for R is greater than 50%.  \\(\\begin{align} &H_0: \\pi \\le 1/2 \\\\ &H_1: \\pi > 1/2 \\text{ (more than half voted for R)} \\end{align}\\) \n\n\n Step 2 \n\n \\(\\alpha = 0.05\\) \n\n Step 3 \n\n \\(z_{test} = \\frac{\\hat{\\pi} - \\pi_0}{\\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}} = \\frac{\\frac{520}{1000} - 0.5}{\\sqrt{\\frac{0.5(1-0.5)}{1000}}} = 1.26\\) \n\n Step 4-c \n\n \\(z_{\\alpha} = z_{0.05} = 1.645\\) \n\n Step 5-c \n\n Reject \\(H_0\\) in favor of \\(H_1\\) if \\(z_{test} > z_{\\alpha}\\). \n Since \\(z_{test} < z_{\\alpha}\\), we do not reject \\(H_0\\). \n\n Step 6 \n\n We do not have sufficient evidence to conclude that R won. \nWe make the same conclusion using the \\(p\\)-value method.\n\n\\[ p\\text{-value} = P(Z > 1.26) = 0.1 > 0.05\\]\n Confidence Interval \nFirst we check the assumption: + \\(n\\hat{\\pi} = 1000(0.52) = 520 \\ge 5\\) and \\(n(1-\\hat{\\pi}) = 480 \\ge 5\\).\n\nEstimate the proportion of all voters that voted for R using a 95% confidence interval.\n\n\\[\\hat{\\pi} \\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{\\pi}(1-\\hat{\\pi})}{n}} = 0.52 \\pm z_{0.025}\\sqrt{\\frac{0.52(1-0.52)}{1000}} = (0.49, 0.55).\\]\n Computation in R \n\nTo perform the one-sample proportion \\(z\\) test in R, we use the function prop.test(). The argument correct tells us whether or not we want to do continuity correction. Our method here does not do continuity correction. It does not matter much when our method assumption is satisfied.\nTo obtain the confidence interval, we should set alternative = \"two.sided\" because the interval is two sided. Be careful. The interval we learn is the Wald interval. However, the interval from the prop.test() output is not the Wald interval, but the so-called Wilson interval. There are lots of variants of confidence intervals for binomial proportions, and one can use the BinomCI() function in the DescTools package to obtain them.\n\n## one proportion test using normal approximation\nprop.test(x = 520, n = 1000, p = 0.5, alternative = \"greater\", \n          correct = FALSE)\n\n\n    1-sample proportions test without continuity correction\n\ndata:  520 out of 1000, null probability 0.5\nX-squared = 1.6, df = 1, p-value = 0.103\nalternative hypothesis: true p is greater than 0.5\n95 percent confidence interval:\n 0.4939945 1.0000000\nsample estimates:\n   p \n0.52 \n\n# Use alternative = \"two.sided\" to get CI\nprop_ci <- prop.test(x = 520, n = 1000, p = 0.5, \n                     alternative = \"two.sided\", correct = FALSE)\nprop_ci$conf.int\n\n[1] 0.4890177 0.5508292\nattr(,\"conf.level\")\n[1] 0.95\n\n## The Wilson interval and Wald interval\nDescTools::BinomCI(x = 520, n = 1000, method = \"wilson\")\n\n      est    lwr.ci    upr.ci\n[1,] 0.52 0.4890177 0.5508292\n\nDescTools::BinomCI(x = 520, n = 1000, method = \"wald\")\n\n      est    lwr.ci    upr.ci\n[1,] 0.52 0.4890351 0.5509649\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDoing inference with normal approximation to binomial variables is more complicated than what we discuss here. The main reason is that we use a continuous normal distribution to approximate a discrete binomial distribution. Check the Wiki page if you donâ€™t believe it. No worries at this moment unless you want to be a statistician doing research in this field!\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you look at the proportion test output carefully, youâ€™ll find that the test statistic is a chi-squared test statistic, not the \\(z\\) test statistic. In fact, the square of the \\(z\\) statistic is equal to the chi-squared statistic with degrees of freedom one, i.e., \\(z_{test}^2 = \\chi^2_{1, test}\\), and the \\(z\\) test here is equivalent to the chi-squared test discussed in the next chapter (ChapterÂ 19) for two-sided tests.\n\nz_test <- (0.52 - 0.5) / sqrt((0.5)*0.5 / 1000)\nz_test ^ 2\n\n[1] 1.6\n\nprop_ci$statistic\n\nX-squared \n      1.6 \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe method we learn here uses normal approximation to binomial variables. One can also perform the exact binomial test that directly uses binomial probabilities to calculate the \\(p\\)-value and do the testing. As its name suggests, it is what we should use for binomial inference because it is exact. If the requirement of the normal approximation method we learn is not met, the exact binomial test should be used. When the sample size is large, and the expected proportion is not extreme being close to 0 or 1, the normal approximation method and the exact binomial test have pretty similar inference results.\nWe can use binom.test() function to perform the exact binomial test. The page discusses the relationship between the exact binomial test and other methods.\n\n\n\n## exact binom test\nbinom.test(x = 520, n = 1000, p = 0.5, alternative = \"greater\")\n\n\n    Exact binomial test\n\ndata:  520 and 1000\nnumber of successes = 520, number of trials = 1000, p-value = 0.1087\nalternative hypothesis: true probability of success is greater than 0.5\n95 percent confidence interval:\n 0.4934948 1.0000000\nsample estimates:\nprobability of success \n                  0.52 \n\n## confidence interval\nbi <- binom.test(x = 520, n = 1000, p = 0.5, alternative = \"two.sided\")\nbi$conf.int\n\n[1] 0.4885149 0.5513671\nattr(,\"conf.level\")\n[1] 0.95"
  },
  {
    "objectID": "infer-prop.html#inference-for-two-proportions",
    "href": "infer-prop.html#inference-for-two-proportions",
    "title": "18Â  Inference About Proportions",
    "section": "\n18.3 Inference for Two Proportions",
    "text": "18.3 Inference for Two Proportions\nMany times we want to compare two population proportions, say \\(\\pi_1\\) and \\(\\pi_2\\). We could assume there are two independent binomial experiments with the same possible outcomes. For example, we could have male and female voters, and every voter in each group has an opinion about presidentâ€™s performance whose outcome is either Approve or Not approve. Let the number of male voters approving the performance is \\(Y_1\\) and the number of female voters approving the performance is \\(Y_2\\). We can assume \\(Y_1\\) and \\(Y_2\\) both follow binomial distribution but with their own parameters, \\(n_1\\) and \\(\\pi_1\\) for \\(Y_1\\), and \\(n_2\\) and \\(\\pi_2\\) for \\(Y_2\\). Political analysts may want to know whether or not the male presidential approval rate \\(\\pi_1\\) is higher than the female approval rate \\(\\pi_2\\).\n\n\n\n\nGroup 1\nGroup 2\n\n\n\n\n\\(n_1\\) trials\n\n\\(n_2\\) trials\n\n\n\n\\(Y_1\\) number of successes\n\n\\(Y_2\\) number of successes\n\n\n\\(Y_1 \\sim binomial(n_1, \\pi_1)\\)\n\\(Y_2 \\sim binomial(n_2, \\pi_2)\\)\n\n\n\n\n\n\\(\\pi_1\\): Population proportion of success of Group 1\n\n\\(\\pi_2\\): Population proportion of success of Group 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hypothesis Testing for \\(\\pi_1\\) and \\(\\pi_2\\) \nThe method introduced here is based on the central limit theorem and normal approximation to binomial distribution. The idea is similar to the one sample proportion \\(z\\) test, and we perform two sample proportion \\(z\\) test.\n Step 0: Check Method Assumptions \n\nIn order to perform the \\(z\\) test, the following requirements must be met:  \\(n_1\\hat{\\pi}_1 \\ge 5\\), \\(n_1(1-\\hat{\\pi}_1) \\ge 5\\) and \\(n_2\\hat{\\pi}_2 \\ge 5\\), \\(n_2(1-\\hat{\\pi}_2) \\ge 5\\) \n\n\n Step 1: Set the Null and Alternative Hypothesis \n\n \\(\\begin{align} &H_0: \\pi_1 = \\pi_2 \\\\ &H_1: \\pi_1 > \\pi_2 \\text{ or } \\pi_1 < \\pi_2 \\text{ or } \\pi_1 \\ne \\pi_2 \\end{align}\\) \n\n Step 2: Set the Significance Level, \\(\\alpha\\) \n Step 3: Calculate the Test Statistic \n\nIt can be shown that \\[\\frac{\\frac{Y_1}{n_1} - \\frac{Y_2}{n_2} - (\\pi_1 - \\pi_2)}{\\sqrt{\\frac{\\pi_1(1-\\pi_1)}{n_1} + \\frac{\\pi_2(1-\\pi_2)}{n_2}}} \\dot\\sim N(0, 1)\\] Under the null hypothesis, \\(\\pi_1 = \\pi_2 = \\pi\\), with the sample data, the statistic is reduced to \\[\\frac{\\hat{\\pi}_1 - \\hat{\\pi}_2}{\\sqrt{\\pi(1-\\pi)(\\frac{1}{n_1} + \\frac{1}{n_2})}},\\] where \\(\\hat{\\pi}_1 = y_1/n_1\\) and \\(\\hat{\\pi}_2 = y_2/n_2\\). We still cannot use this quantity as a test statistic because it involves the unknown parameter \\(\\pi\\). Like two sample pooled \\(t\\) test, since \\(\\pi_1 = \\pi_2 = \\pi\\) under \\(H_0\\), we combine the two samples using all the trials to get a better pooled sample proportion \\(\\bar{\\pi} = \\frac{y_1+y_2}{n_1+n_2}\\) to estimate the common proportion \\(\\pi\\). Therefore, the test statistic is\n\n \\[z_{test} = \\dfrac{\\hat{\\pi}_1 - \\hat{\\pi}_2}{\\sqrt{\\bar{\\pi}(1-\\bar{\\pi})(\\frac{1}{n_1} + \\frac{1}{n_2})}}.\\] \n Step 4-c: Find the Critical Value \\(z_{\\alpha}\\) (one-tailed) or \\(z_{\\alpha/2}\\) (two-tailed) \nSame before.\n Step 5-c: Draw a Conclusion Using Critical Value Method \n\n\n Reject \\(H_0\\) in favor of \\(H_1\\) if \n\n \\(H_1: \\pi_1 > \\pi_2\\): Reject \\(H_0\\) in favor of \\(H_1\\) if \\(z > z_{\\alpha}\\) \n \\(H_1: \\pi_1 < \\pi_2\\): Reject \\(H_0\\) in favor of \\(H_1\\) if \\(z < -z_{\\alpha}\\) \n \\(H_1: \\pi_1 \\ne \\pi_2\\): Reject \\(H_0\\) in favor of \\(H_1\\) if \\(|z| > z_{\\alpha/2}\\) \n\n\n\n Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim \n\n Confidence Interval for \\(\\pi_1 - \\pi_2\\)\nTo get the Wald confidence interval for \\(\\pi_1 - \\pi_2\\), it requires\n\\(n_1\\hat{\\pi}_1 \\ge 5\\), \\(n_1(1-\\hat{\\pi}_1) \\ge 5\\) and \\(n_2\\hat{\\pi}_2 \\ge 5\\), \\(n_2(1-\\hat{\\pi}_2) \\ge 5\\). Again, no hypothesized values, and sample proportions are used.\nThe \\(100(1 - \\alpha)\\%\\) confidence interval for \\(\\pi_1 - \\pi_2\\) is \\[\\hat{\\pi}_1 - \\hat{\\pi}_2 \\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{\\pi}_1(1-\\hat{\\pi}_1)}{n_1}+\\frac{\\hat{\\pi}_2(1-\\hat{\\pi}_2)}{n_2}}\\]\nThere is no pooled estimate \\(\\bar{\\pi}\\) in the interval because the interval is not constructed under the hypothesis that \\(\\pi_1 = \\pi_2 = \\pi\\). The parameters \\(\\pi_1\\) and \\(\\pi_2\\) are estimated separately by the individual sample proportions \\(\\hat{\\pi}_1\\) and \\(\\hat{\\pi}_2\\).\n\n Example: Effectiveness of Learning \n\n\nSuppose we do a study on 300 students to compare the effectiveness of learning statistics in online vs.Â in-person programs. We randomly assign 125 students to the online program, and the remaining 175 to the in-person program. The exam results are shown in the table below.\n\n\n\n\n\nSource: Unsplash-JESHOOTS.COM\n\n\n\n\n\n\n\n\nExam Results\nOnline Instruction\nIn-Person Instruction\n\n\n\nPass\n94\n113\n\n\nFail\n31\n62\n\n\nTotal\n125\n175\n\n\n\nIs there sufficient evidence to conclude that the online program is more effective than the traditional in-person program at \\(\\alpha=0.05\\)? \n Hypothesis Testing \n Step 0 \n\n \\(\\hat{\\pi}_1 = 94/125 = 0.75\\) and \\(\\hat{\\pi}_2 = 113/175 = 0.65\\). \n \\(n_1\\hat{\\pi}_1 = 94 > 5\\), \\(n_1(1-\\hat{\\pi}_1) = 31 > 5\\), and \\(n_2\\hat{\\pi}_2 = 113 > 5\\), \\(n_2(1-\\hat{\\pi}_2) = 62 > 5\\) \n\nThe assumptions are satisfied.\n Step 1 \n\nLet \\(\\pi_1\\) \\((\\pi_2)\\) be the population proportion of students passing the exam in the online (in-person) program.  \\(H_0: \\pi_1 = \\pi_2\\) vs.Â \\(H_1: \\pi_1 > \\pi_2\\) \n\n\n Step 2 \n\n \\(\\alpha = 0.05\\) \n\n Step 3 \n\n \\(\\bar{\\pi} = \\frac{94+113}{125+175} = 0.69\\) \n \\(z_{test} = \\dfrac{\\hat{\\pi}_1 - \\hat{\\pi}_2}{\\sqrt{\\bar{\\pi}(1-\\bar{\\pi})(\\frac{1}{n_1} + \\frac{1}{n_2})}} = \\frac{0.75 - 0.65}{\\sqrt{0.69(1-0.69)(\\frac{1}{125} + \\frac{1}{175})}} = 1.96\\) \n\n Step 4-c \n\n \\(z_{\\alpha} = z_{0.05} = 1.645\\) \n\n Step 5-c \n\n Reject \\(H_0\\) in favor of \\(H_1\\) if \\(z_{test} > z_{\\alpha}\\). \n Since \\(z_{test} > z_{\\alpha}\\), we reject \\(H_0\\). \n\n Step 6 \n\n We have sufficient evidence to conclude that the online program is more effective. \n\n Confidence Interval \nWe want to know how effective the online program is, so we estimate \\(\\pi_1 - \\pi_2\\) using a \\(95\\%\\) confidence interval\n\\[\\hat{\\pi}_1 - \\hat{\\pi}_2 \\pm z_{0.05/2}\\sqrt{\\frac{\\hat{\\pi}_1(1-\\hat{\\pi}_1)}{n_1}+\\frac{\\hat{\\pi}_2(1-\\hat{\\pi}_2)}{n_2}}\\]  The 95% confidence interval is \\[0.75 - 0.65 \\pm 1.96\\sqrt{\\frac{(0.75)(1-0.75)}{125} + \\frac{(0.65)(1-0.65)}{175}}\\\\\n= (0.002, 0.210)\\]\nBecause 0 is not included in this interval, we reach the same conclusion as the hypothesis testing.\n Implementation in R \nBelow is a demonstration of how to make inferences about two proportions in R. We still use prop.test() function, but here we provide the number of successes and the number of trials in the arguments x and n respectively as a vector whose first element is for the first group and second element for the second group. Please be consistent with the order and donâ€™t mess up.\n\nprop.test(x = c(94, 113), n = c(125, 175), \n          alternative = \"greater\", correct = FALSE)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  c(94, 113) out of c(125, 175)\nX-squared = 3.8509, df = 1, p-value = 0.02486\nalternative hypothesis: greater\n95 percent confidence interval:\n 0.01926052 1.00000000\nsample estimates:\n   prop 1    prop 2 \n0.7520000 0.6457143 \n\nprop_ci2 <- prop.test(x = c(94, 113), n = c(125, 175), \n                     alternative = \"two.sided\", correct = FALSE)\nprop_ci2$conf.int\n\n[1] 0.002588801 0.209982628\nattr(,\"conf.level\")\n[1] 0.95\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe two sample proportion \\(z\\) test is equivalent to the chi-squared test introduced in the next chapter (ChapterÂ 19) that considers more than two possible outcomes.\n\npi_bar <- (94 + 113)/(125 + 175)\npi_1_hat <- 94/125\npi_2_hat <- 113/175\nz_test2 <- (pi_1_hat - pi_2_hat) / (sqrt(pi_bar*(1-pi_bar)*(1/125+1/175)))\nz_test2 ^ 2\n\n[1] 3.850932\n\nprop_ci2$statistic\n\nX-squared \n 3.850932"
  },
  {
    "objectID": "infer-prop.html#exercises",
    "href": "infer-prop.html#exercises",
    "title": "18Â  Inference About Proportions",
    "section": "\n18.4 Exercises",
    "text": "18.4 Exercises\n\nLipitor (atorvastatin) is a drug used to control cholesterol. In clinical trials of Lipitor, 98 subjects were treated with Lipitor and 245 subjects were given a placebo. Among those treated with Lipitor, 6 developed infections. Among those given a placebo, 24 developed infections. Use a 0.05 significance level to test the claim that the rate of inflections was the same for those treated with Lipitor and those given a placebo.\n\nTest the claim using the critical-value and p-value methods.\nTest the claim by constructing a confidence interval."
  },
  {
    "objectID": "infer-goodnessfit.html#sec-infer-goodnessfit",
    "href": "infer-goodnessfit.html#sec-infer-goodnessfit",
    "title": "\n19Â  Inference about Categorical Data\n",
    "section": "\n19.1 Test of Goodness of Fit",
    "text": "19.1 Test of Goodness of Fit\n\n\n\n Categorical Variable with More Than 2 Categories \n\n\n\nA categorical variable has \\(k\\) categories \\(A_1, \\dots, A_k\\).\n\n\n\nSubject\n\\(A_1\\)\n\\(A_2\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(A_k\\)\n\n\n\n1\nx\n\n\n\n\n\n\n2\n\nx\n\n\n\n\n\n3\n\n\n\n\nx\n\n\n\\(\\vdots\\)\n\n\n\n\n\n\n\n\\(n\\)\n\n\n\nx\n\n\n\n\n\n\n\n\nWith the size \\(n\\), for categories \\(A_1, \\dots , A_k\\), their observed count is \\(O_1, \\dots, O_k\\), and \\(\\sum_{i=1}^kO_i = n\\).\nOne-way count table:\n\n\n\n\\(A_1\\)\n\\(A_2\\)\n\\(\\cdots\\)\n\\(A_k\\)\nTotal\n\n\n\\(O_1\\)\n\\(O_2\\)\n\\(\\cdots\\)\n\\(O_k\\)\n\\(n\\)\n\n\n\n\n Example \n\n\n\nAre the selected jurors racially representative of the population?\nIf the jury is representative of the population, the proportions in the sample should reflect the proportions of the population of eligible jurors (i.e.Â registered voters).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\nRepresentation in juries\n205\n26\n25\n19\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\nRepresentation in juries\n0.745\n0.095\n0.091\n0.069\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n\n\n\n\n\n\n\n\n\nAre the proportions of juries close enough to the proportions of registered voters, so that we are confident saying that the jurors really were randomly sampled from the registered voters?\n\n\n\n\n\n\n\n Goodness-of-Fit Test \n\nA goodness-of-fit test tests the hypothesis that the observed frequency distribution fits or conforms to some claim distribution.\n\n\n\n\n\n\n\nIn the jury example, what is our observed frequency distribution, and what is our claim distribution?\n\n\n\n\n\n\n\n\n\n\n\n\nIf the individuals are randomly selected to serve on a jury, about how many of the 275 people would we expect to be white? How about black?\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n\n\n\nAbout \\(72\\%\\) of the population is white, so we would expect about \\(72\\%\\) of the jurors to be white.\n\n\n\\(0.72 \\times 275 = 198\\).\n\n\nWe expect about \\(7\\%\\) of the jurors to be black.\n\nThis corresponds to about \\(0.07 \\times 275 = 19.25\\) black jurors.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\n\nObserved Count\n205\n26\n25\n19\n\n\n\nExpected Count\n198\n19.25\n33\n24.75\n\n\nPopulation Proportion \\((H_0)\\)\n\n0.72\n0.07\n0.12\n0.09\n\n\n\n\nThe observed count and expected count will be similar if there was no bias in selecting the members of the jury.\nWe want to test whether the differences are strong enough to provide convincing evidence that the jurors were not selected from a random sample of all registered voters.\n\n Example \n\n \\(\\begin{align} &H_0: \\text{No racial bias in who serves on a jury, and } \\\\ &H_1: \\text{There is racial bias in juror selection} \\end{align}\\) \n \\(\\begin{align} &H_0: \\pi_1 = \\pi_1^0, \\pi_2 = \\pi_2^0, \\dots, \\pi_k = \\pi_k^0\\\\ &H_1: \\pi_i \\ne \\pi_i^0 \\text{ for some } i \\end{align}\\) \n Under \\(H_0\\), \\(\\chi^2_{test} = \\frac{(O_1 - E_1)^2}{E_1} + \\frac{(O_2 - E_2)^2}{E_2} + \\cdots + \\frac{(O_k - E_k)^2}{E_k}\\), \\(E_i = n\\pi_i^0, i = 1, \\dots, k\\) \nReject \\(H_0\\) if  \\(\\chi^2_{test} > \\chi^2_{\\alpha, df}\\), \\(df = k-1\\) \nRequire each \\(E_i \\ge 5\\), \\(i = 1, \\dots, k\\).\n\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\nObserved Count\n\\(O_1 = 205\\)\n\\(O_2 = 26\\)\n\\(O_3 = 25\\)\n\\(O_4 = 19\\)\n\n\nExpected Count\n\\(E_1 = 198\\)\n\\(E_2 = 19.25\\)\n\\(E_3 = 33\\)\n\\(E_4 = 24.75\\)\n\n\nProportion under \\(H_0\\)\n\n\\(\\pi_1^0 = 0.72\\)\n\\(\\pi_2^0 = 0.07\\)\n\\(\\pi_3^0 = 0.12\\)\n\\(\\pi_4^0 = 0.09\\)\n\n\n\n\nUnder \\(H_0\\), \\(\\chi^2_{test} = \\frac{(205 - 198)^2}{198} + \\frac{(26 - 19.25)^2}{19.25} + \\frac{(25 - 33)^2}{33} + \\frac{(19 - 24.75)^2}{24.75} = 5.89\\)\n\n\n\\(\\chi^2_{0.05, 3} = 7.81\\).\nBecause \\(5.89 < 7.81\\), we fail to reject \\(H_0\\) in favor of \\(H_1\\).\nWe do not have convincing evidence of racial bias in the juror selection process.\n\n Goodness-of-Fit Test in R \n\nBelow is an example of how to perform a Goodness-of-Fit test in R.\n\n\nobs <- c(205, 26, 25, 19)\npi_0 <- c(0.72, 0.07, 0.12, 0.09)\n\n## Use chisq.test() function\nchisq.test(x = obs, p = pi_0)\n\n\n    Chi-squared test for given probabilities\n\ndata:  obs\nX-squared = 5.8896, df = 3, p-value = 0.1171"
  },
  {
    "objectID": "infer-goodnessfit.html#test-of-independence",
    "href": "infer-goodnessfit.html#test-of-independence",
    "title": "\n19Â  Inference about Categorical Data\n",
    "section": "\n19.2 Test of Independence",
    "text": "19.2 Test of Independence\n Contingency Table and Expected Count\n Contingency Table \n\nWe have TWO categorical variables, and we want to test whether or not the two variables are independent.\n Does the opinion of the Presidentâ€™s job performance depend on gender? \n\n\n\n\n\nJob performance: approve, disapprove, no opinion\n\nGender: male, female\n\n\n\n\nApprove\nDisapprove\nNo Opinion\n\n\n\nMale\n18\n22\n10\n\n\nFemale\n23\n20\n12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Expected Count \n\nCompute the expected count of each cell in the two-way table under the condition that the two variables are independent of each other.\n\n\n\n\nApprove\nDisapprove\nNo Opinion\n\n\n\nMale\n18 (19.52)\n22 (20)\n10 (10.48)\n\n\nFemale\n23 (21.48)\n20 (22)\n12 (11.52)\n\n\nTotal\n41\n42\n22\n\n\n\n\nThe expected count for the \\(i\\)-th row and \\(j\\)-th column, which is listed in parentheses in the table above, is: \\[\\text{Expected Count}_{\\text{row i; col j}} = \\frac{\\text{(row i total}) \\times (\\text{col j total})}{\\text{table total}}\\]\n\n\n\n Test of Independence Procedure \n\nRequirements:\n\nEvery \\(E_{ij} \\ge 5\\) in the contingency table.\n\n\n \\(\\begin{align} &H_0: \\text{Two variables are independent }\\\\ &H_1: \\text{The two are dependent (associated) } \\end{align}\\)\n\n\\(\\chi^2_{test} = \\sum_{i=1}^r\\sum_{j=1}^c\\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\), where \\(r\\) is the number of rows and \\(c\\) is the number of columns in the table.\nReject \\(H_0\\) if \\(\\chi^2_{test} > \\chi^2_{\\alpha, \\, df}\\), \\(df = (r-1)(c-1)\\).\n\n Example \n\n\n\nApprove\nDisapprove\nNo Opinion\n\n\n\nMale\n18 (19.52)\n22 (20)\n10 (10.48)\n\n\nFemale\n23 (21.48)\n20 (22)\n12 (11.52)\n\n\nTotal\n41\n42\n22\n\n\n\n\n \\(\\begin{align} &H_0: \\text{ Opinion does not depend on gender } \\\\ &H_1: \\text{ Opinion and gender are dependent } \\end{align}\\)\n\\(\\small \\chi^2_{test} = \\frac{(18 - 19.52)^2}{19.52} + \\frac{(22 - 20)^2}{20} + \\frac{(10 - 10.48)^2}{10.48} + \\frac{(23 - 21.48)^2}{21.48} + \\frac{(20 - 22)^2}{22} + \\frac{(12 - 11.52)^2}{11.52}= 0.65\\)\n\n\\(\\chi^2_{\\alpha, df} =\\chi^2_{0.05, (2-1)(3-1)} = 5.991\\).\nSince \\(\\chi_{test}^2 < \\chi^2_{\\alpha, df}\\), we do not reject \\(H_0\\).\nWe fail to conclude that the opinion of the Presidentâ€™s job performance depends on gender.\n\n Test of Independence in R \n\nBelow is an example of how to perform the test of independence using R.\n\n\n(contingency_table <- matrix(c(18, 23, 22, 20, 10, 12), nrow = 2, ncol = 3))\n\n     [,1] [,2] [,3]\n[1,]   18   22   10\n[2,]   23   20   12\n\n## Using chisq.test() function\n(indept_test <- chisq.test(contingency_table))\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_table\nX-squared = 0.65019, df = 2, p-value = 0.7225\n\nqchisq(0.05, df = (2 - 1) * (3 - 1), lower.tail = FALSE)  ## critical value\n\n[1] 5.991465"
  },
  {
    "objectID": "infer-goodnessfit.html#exercises",
    "href": "infer-goodnessfit.html#exercises",
    "title": "\n19Â  Inference about Categorical Data\n",
    "section": "\n19.3 Exercises",
    "text": "19.3 Exercises\n\nA researcher has developed a model for predicting eye color. After examining a random sample of parents, she predicts the eye color of the first child. The table below lists the eye colors of offspring. On the basis of her theory, she predicted that 87% of the offspring would have brown eyes, 8% would have blue eyes, and 5% would have green eyes. Use 0.05 significance level to test the claim that the actual frequencies correspond to her predicted distribution.\n\n\n\nEye Color\nBrown\nBlue\nGreen\n\n\nFrequency\n127\n21\n5\n\n\n\nIn a study of high school students at least 16 years of age, researchers obtained survey results summarized in the accompanying table. Use a 0.05 significance level to test the claim of independence between texting while driving and driving when drinking alcohol. Are these two risky behaviors independent of one another?\n\n\n\n\nDrove after drinking alcohol?\n\n\n\n\n\nYes\nNo\n\n\nTexted while driving\n720\n3027\n\n\nDid not text while driving\n145\n4472"
  },
  {
    "objectID": "infer-bayes.html#the-r-user-interface",
    "href": "infer-bayes.html#the-r-user-interface",
    "title": "20Â  Bayesian Inference",
    "section": "20.1 The R User Interface",
    "text": "20.1 The R User Interface"
  },
  {
    "objectID": "infer-nonpar.html#the-r-user-interface",
    "href": "infer-nonpar.html#the-r-user-interface",
    "title": "21Â  Nonparametric Inference",
    "section": "21.1 The R User Interface",
    "text": "21.1 The R User Interface"
  },
  {
    "objectID": "model.html#the-r-user-interface",
    "href": "model.html#the-r-user-interface",
    "title": "Statistical Models",
    "section": "The R User Interface",
    "text": "The R User Interface"
  },
  {
    "objectID": "model-anova.html#anova-rationale",
    "href": "model-anova.html#anova-rationale",
    "title": "22Â  Analysis of Variance",
    "section": "\n22.1 ANOVA Rationale",
    "text": "22.1 ANOVA Rationale\n Comparing More Than Two Population Means \n\nIn many research settings, we want to compare 3 or more population means.\n\n\n\n\n Are there differences in the mean readings of 4 types of devices used to determine the pH of soil samples? \n\n\n\n\n\n\n\n\n\n\n\n Do different treatments (None, Fertilizer, Irrigation, Fertilizer and Irrigation) affect the mean weights of poplar trees? \n\n\n\n\n\n\n\n\n\n\n\n\n One-Way Analysis of Variance \n\nA factor is a property or characteristic (categorical variable) that allows us to distinguish the different populations from one another.\n\n\nType of device and treatment of trees are factors from the examples previously provided.\n\n\nOne-way ANOVA examines the effect of a categorical variable on the mean of a numerical variable (response).\n\nWe use analysis of  variance  to test the equality of 3 or more population  means. ðŸ¤”\nThe method is one-way because we use one single property (categorical variable) for categorizing the populations.\n\n\n\n Requirements \n\nThe populations of each category are normally distributed.\nThe populations have the same variance \\(\\sigma^2\\) (two sample pooled \\(t\\)-test).\nThe samples are random samples.\nThe samples are independent of each other (not matched or paired in any way).\n\n Rationale \n\nData 1 and Data 2 have the same group sample means \\(\\bar{y}_1\\), \\(\\bar{y}_2\\) and \\(\\bar{y}_3\\) denoted as red dots.\nHowever, they differ with regards to the variance within each group.\n\n\n\n\n\nFigureÂ 22.1: Boxplots illustrating the variance within samples\n\n\n\n\n\n\n\n\n\n\nFor which data do you feel more confident in saying the population means \\(\\mu_1\\), \\(\\mu_2\\) and \\(\\mu_3\\) are not all the same?\n\n\n\n\n\n\n\n Variation Between Samples & Variation Within Samples \n\nData 1: Variability between samples is large in comparison to the variation within samples.\nData 2: Variation between samples is small relatively to the variation within samples.\n\n\n\n\n\n\n\nWe are more confident concluding there is a difference in population means when variation between samples is larger than variation within samples.\n\n\n\n\n\n\n\n\n\n\nFigureÂ 22.2: Illustration of small and large variance within samples"
  },
  {
    "objectID": "model-anova.html#anova-procedures",
    "href": "model-anova.html#anova-procedures",
    "title": "22Â  Analysis of Variance",
    "section": "\n22.2 ANOVA Procedures",
    "text": "22.2 ANOVA Procedures\n\n \\(\\begin{align} &H_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_k\\\\ &H_1: \\text{Population means are not all equal} \\end{align}\\) \n\n\nStatistician Ronald Fisher found a way to define a variable that follows the \\(F\\) distribution: \\[\\frac{\\text{variance between samples}}{\\text{variance within samples}} \\sim F_{df_B,\\, df_W}\\]\n\nIf the variance between samples is larger than the variance within samples (\\(F_{test}\\) is much greater than 1), as in Data 1, we reject \\(H_0\\).\n\n\n\n\n\n\n\nKey\n\n\n\n\nDefine variance between samples and variance within samples so that the ratio is \\(F\\) distributed.\n\n\n\n\n Variance Within Samples \n\nBack to the two-sample pooled \\(t\\)-test with equal variance, \\(\\sigma^2\\). We have \\[s_p^2 = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}\\]\n\n\n\n\n\n\n\n\nHow about the pooled sample variance for \\(k\\) samples?\n\n\n\n\n\n\n\nANOVA assumes the populations have the same variance such that \\(\\sigma_1^2 = \\sigma_2^2 = \\cdots = \\sigma_k^2 = \\sigma^2\\). \\[\\boxed{s_W^2 = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2 + \\cdots + (n_k-1)s_k^2}{n_1 + n_2 + \\cdots + n_k - k}}\\] where \\(s_i^2\\), \\(i = 1, \\dots ,k\\), is the sample variance of group \\(i\\).\n\n\\(s_W^2\\) represents a combined estimate of the common variance, \\(\\sigma^2\\).\n\nIt measures variability of the observations within the \\(k\\) populations.\n\n\n\n\n Variance Between Samples \n\\[\\boxed{s^2_{B} = \\frac{\\sum_{i=1}^k n_i (\\bar{y}_{i\\cdot} - \\bar{y}_{\\cdot\\cdot})^2}{k-1}}\\]\n\n\n\\(\\bar{y}_{i\\cdot}\\) is the \\(i\\)-th sample mean.\n\n\\(\\bar{y}_{\\cdot\\cdot}\\) is the grand sample mean with all data points in all groups combined.\n\n\\(s^2_{B}\\) is also an estimate of \\(\\sigma^2\\) and measures variability among sample means for the \\(k\\) groups.\nIf \\(H_0\\) is true \\((\\mu_1 = \\cdots = \\mu_k = \\mu)\\), any variation in the sample means is due to chance and randomness, so it shouldnâ€™t be too large.\n\n\n\\(\\bar{y}_{1\\cdot}, \\cdots, \\bar{y}_{k\\cdot}\\) should be close each other and should be close to \\(\\bar{y}_{\\cdot \\cdot}\\).\n\n\n\n\n ANOVA Table: Sum of Squares \n\nTotal Sum of Squares (SST) measures the total variation around \\(\\bar{y}_{\\cdot\\cdot}\\) in all of the sample data combined (ignoring the groups): \\[\\scriptsize{\\color{blue}{SST = \\sum_{j=1}^{n_i}\\sum_{i=1}^{k} \\left(y_{ij} - \\bar{y}_{\\cdot\\cdot}\\right)^2}}\\] where \\(y_{ij}\\) is the \\(j\\)-th data point in the \\(i\\)-th group.\nSum of Squares Between Samples (SSB) measures the variation between sample means: \\[\\scriptsize{ \\color{blue}{SSB = \\sum_{i=1}^{k}n_i \\left(\\bar{y}_{i\\cdot} - \\bar{y}_{\\cdot\\cdot}\\right)^2}}\\]\nSum of Squares Within Samples (SSW) measures the variation of any value, \\(y_{ij}\\), about its sample mean, \\(\\bar{y}_{i\\cdot}\\): \\[\\scriptsize{ \\color{blue}{SSW = \\sum_{i=1}^{k} \\sum_{j=1}^{n_i} \\left(y_{ij} - \\bar{y}_{i\\cdot}\\right)^2 = \\sum_{i=1}^{k} (n_i - 1)s_i^2}}\\]\n\n Sum of Squares Identity \n\n\\(SST = SSB + SSW\\)\n\\(df_{T} = df_{B} + df_{W} \\implies N - 1 = (k-1) + (N - k)\\) \n\\(\\text{Mean Square (MS)} = \\frac{\\text{sum of squares}}{\\text{degrees of freedom}}\\)\n\\(MSB = \\frac{SSB}{k-1} = s^2_{B}\\)\n\\(MSW = \\frac{SSW}{N-k} = s^2_{W}\\)\n\\(F_{test} = \\frac{MSB}{MSW}\\)\nUnder \\(H_0\\), \\(\\frac{S^2_{B}}{S_W^2} \\sim F_{k-1, \\, N-k}\\)\n\nReject \\(H_0\\) if\n\n\\(F_{test} > F_{\\alpha, \\, k - 1,\\, N-k}\\)\n\n\\(p\\)-value \\(P(F_{k - 1,\\, N-k} > F_{test}) < \\alpha\\)\n\n\n\n\n ANOVA Table"
  },
  {
    "objectID": "model-anova.html#anova-example",
    "href": "model-anova.html#anova-example",
    "title": "22Â  Analysis of Variance",
    "section": "\n22.3 ANOVA Example",
    "text": "22.3 ANOVA Example\n\nWe hypothesize that a nutrient called â€œisoflavonesâ€ varies among three types of food: (1) cereals and snacks, (2) energy bars and (3) veggie burgers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA sample of 5 is taken from each type of food and the amount of isoflavones is measured.\nIs there a sufficient evidence to conclude that the mean isoflavone levels vary among these food items at \\(\\alpha = 0.05\\)?\n\n\n Data \n\n\n\n\nWe prefer a data format like the one shown on the right.\n\n\n\n\ndata\n\n   1  2  3\n1  3 19 25\n2 17 10 15\n3 12  9 12\n4 10  7  9\n5  4  5  8\n\n\n\n\n\n\n\n\nSo tell me what is the value of \\(y_{23}\\)!\n\n\n\n\n\n\n\n\n\n\ndata_anova\n\n    y    food\n1   3 cereals\n2  17 cereals\n3  12 cereals\n4  10 cereals\n5   4 cereals\n6  19  energy\n7  10  energy\n8   9  energy\n9   7  energy\n10  5  energy\n11 25  veggie\n12 15  veggie\n13 12  veggie\n14  9  veggie\n15  8  veggie\n\n\n\n\n\n\n\n\n\nFigureÂ 22.3: Boxplot of the Isoflavone Content in 3 Types of Food\n\n\n\n\n\n Test Assumptions \n\nAssumptions:\n\n\n\\(\\sigma_1 = \\sigma_2 = \\sigma_3\\) (I tested it).\nData are generated from a normal distribution for each type of food (QQ plots confirm this).\n\n\n\n\n\n\n\nFigureÂ 22.4: QQ plots for each type of food\n\n\n\n\n ANOVA Testing \n\n \\(\\begin{align}&H_0: \\mu_1 = \\mu_2 = \\mu_3\\\\&H_1: \\mu_is \\text{ not all equal} \\end{align}\\) \n\n\n\n\n\n\n\n\n\n\nWe can do all the calculations and generate an ANOVA table using just one line of code, as shown below.\n\n\nanova(lm(y ~ food, data = data_anova))\n\nAnalysis of Variance Table\n\nResponse: y\n          Df Sum Sq Mean Sq F value Pr(>F)\nfood       2   60.4   30.20   0.828   0.46\nResiduals 12  437.6   36.47"
  },
  {
    "objectID": "model-reg.html#correlation",
    "href": "model-reg.html#correlation",
    "title": "23Â  Linear Regression",
    "section": "\n23.1 Correlation",
    "text": "23.1 Correlation\n Relationship Between 2 Numerical Variables \n\nDepending on the situation, the two variables can be classified as the explanatory variable and the response variable. (Discussed in Regression)\nHowever, there is not always an explanatory-response relationship.\nExamples:\n\n height and weight \n income and age \n SAT/ACT math score and verbal score \n amount of time spent studying for an exam and exam grade \n\n\n\n\n\n\n\n\n\nCan you provide an example that 2 variables are associated?\n\n\n\n\n\n\n\n Scatterplots \n\n\n\n\nFigureÂ 23.1: Examples of scatterplots\n\n\n\n\n\nThe overall pattern can be described in several ways.\n\nForm: linear or clusters\nDirection: positively associated or negatively associated\nStrength: how close the points lie to a line/curve\n\n\n\n\n Linear Correlation Coefficient \n\nThe sample correlation coefficient, denoted by \\(r\\), measures the direction and strength of the linear relationship between two numerical variables: \\[\\small r :=\\frac{1}{n-1}\\sum_{i=1}^n\\left(\\frac{x_i-\\overline{x}}{s_x}\\right)\\left(\\frac{y_i-\\overline{y}}{s_y}\\right) = \\frac{\\sum_{i=1}^n(x_i-\\overline{x})(y_i-\\overline{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\overline{x})^2\\sum_{i=1}^n(y_i-\\overline{y})^2}}\\]\n\n\n\n\n\n\n\\(-1 \\le r\\le 1\\)\n\n\\(r > 0\\): The larger value of \\(X\\) is, the larger value of \\(Y\\) tends to be.\n\n\\(r = 1\\): Perfect positive linear relationship.\n\n\n\n\n\n\nFigureÂ 23.2: Positive correlation between two variables\n\n\n\n\n\n\n\n\n\n\n\n\\(r < 0\\): The larger value of \\(X\\) is, the smaller value of \\(Y\\) tends to be.\n\n\\(r = -1\\): Perfect negative linear relationship\n\n\n\n\n\n\nFigureÂ 23.3: Negative correlation between two variables\n\n\n\n\n\n\n\n\n\n\n\n\\(r = 0\\): No linear relationship.\nIf the explanatory and response variables are switched, \\(r\\) remains the same.\n\n\\(r\\) has no units of measurement, so scale changes do not affect \\(r\\).\n\n\n\n\n\n\nFigureÂ 23.4: No correlation between two variables\n\n\n\n\n\n\n Example \n\nIt is possible that there is a strong relationship between two variables, but they still have \\(r = 0\\).\n\n\n\n\n\nFigureÂ 23.5: Examples of relationships between two variables and their correlation coefficients (https://upload.wikimedia.org/wikipedia/commons/d/d4/Correlation_examples2.svg)\n\n\n\n\n Example in R \n\n\n\nplot(x = mtcars$wt, y = mtcars$mpg, \n     main = \"MPG vs. Weight\", \n     xlab = \"Car Weight\", \n     ylab = \"Miles Per Gallon\", \n     pch = 16, col = 4, las = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncor(x = mtcars$wt,\n    y = mtcars$mpg)\n\n[1] -0.8676594"
  },
  {
    "objectID": "model-reg.html#introduction-to-regression",
    "href": "model-reg.html#introduction-to-regression",
    "title": "23Â  Linear Regression",
    "section": "\n23.2 Introduction to Regression",
    "text": "23.2 Introduction to Regression\n What is Regression? \n\n\nRegression models the relationship between one or more numerical/categorical response variables \\((Y)\\) and one or more numerical/categorical explanatory variables \\((X)\\).\nA regression function, \\(f(X)\\), describes how a response variable, \\(Y\\), on average, changes as an explanatory variable, \\(X\\), changes.\n\n\n\n\nExamples:\n\n College GPA \\((Y)\\) vs.Â ACT/SAT score \\((X)\\)\n Sales \\((Y)\\) vs.Â Advertising Expenditure \\((X)\\)\n Crime Rate \\((Y)\\) vs.Â Median Income Level \\((X)\\) \n\n\n\n\n\n\n\n\nFigureÂ 23.6: Example of a Regression Function\n\n\n\n\n\n\n\n Unknown Regression Function \n\nThe true relationship between \\(X\\) and the mean of \\(Y\\), the regression function \\(f(X)\\), is unknown.\nThe collected data \\((x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\) are all we know and have.\n\n\n\n\n\nFigureÂ 23.7: Data with an unknown regression function\n\n\n\n\n\nGoal: Estimate \\(f(X)\\) from our data, and use it to predict the value of \\(Y\\) given a value of \\(X\\).\n\n\n Simple Linear Regression \n\nStart with simple linear regression.\n\nThere is only one predictor, \\(X\\) (known and constant), and one response variable, \\(Y\\).\nThe regression function used for predicting \\(Y\\) is a linear function.\nUse a regression line in an X-Y plane to predict the value of \\(Y\\) for a given value of \\(X = x\\).\n\n\n\n\n\n\n\nMath review: A linear function \\(y = f(x) = \\beta_0 + \\beta_1 x\\) represents a straight line.\n\n\n\\(\\beta_1\\): slope, the amount by which \\(y\\) changes when \\(x\\) increases by one unit\n\n\\(\\beta_0\\): intercept, the value of \\(y\\) when \\(x = 0\\)\n\nThe linearity assumption: \\(\\beta_1\\) does not change as \\(x\\) changes.\n\n\n\n\n\n\n\n\nFigureÂ 23.8: Example of a regression line\n\n\n\n\n\n\n Sample Data: Relationship Between X and Y \n\nReal data \\((x_i, y_i), i = 1, 2, \\dots, n\\) do not form a perfect straight line!\n\\(y_i = \\beta_0+\\beta_1x_i + \\color{red}{\\epsilon_i}\\)\n\n\n\n\n\nFigureÂ 23.9: Actual relationship between X and Y isnâ€™t perfectly linear\n\n\n\n\n\nWhen we collect our data, at any given level of \\(X = x\\), \\(y\\) is assumed to be drawn from a normal distribution (for inference purpose).\nIts value varies and will not be exactly equal to its mean, \\(\\mu_y\\).\n\n\n\n\n\nFigureÂ 23.10: Illustration that the responses, y, follow a normal distribution\n\n\n\n\n\nThe mean of \\(Y\\) and \\(X\\) form a straight line.\n\n\n\n\n\nFigureÂ 23.11: Illustration that the regression line is formed from the mean of Y and X\n\n\n\n\n\n Simple Linear Regression Model (Population) \n\nFor the \\(i\\)-th measurement in the target population, \\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\]\n\n\n\\(Y_i\\): the \\(i\\)-th value of the response (random) variable.\n\n\\(X_i\\): the \\(i\\)-th fixed known value of the predictor.\n\n\\(\\epsilon_i\\): the \\(i\\)-th random error with the assumption \\(\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)\\).\n\n\\(\\beta_0\\) and \\(\\beta_1\\) are model coefficients.\n\n\\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\) are fixed unknown parameters to be estimated from the sample data once we collect them.\n\n\n\n Important Features of Model \\(Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\)\n\n\n\\(\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)\\) \\[\\begin{align*}\n\\mu_{Y_i \\mid X_i} &= E(\\beta_0 + \\beta_1X_i + \\epsilon_i) \\\\\n&= \\beta_0 + \\beta_1X_i\n\\end{align*}\\]\n\nThe mean response, \\(\\mu_{Y\\mid X}\\), has a straight-line relationship with \\(X\\) given by a population regression line \\[\\mu_{Y\\mid X} = \\beta_0 + \\beta_1X\\]\n\n\n\n\n\n\n\nFigureÂ 23.12: Illustration of the straight line relationship between \\(\\mu_{Y\\mid X}\\) and \\(X\\)\n\n\n\n\n\n\n\n\n\n\\[\\begin{align*}\nVar(Y_i \\mid X_i) &= Var(\\epsilon_i) = \\sigma^2\n\\end{align*}\\]\n\nThe variance of \\(Y\\) does not depend on \\(X\\).\n\n\n\n\n\n\nFigureÂ 23.13: \\(Y\\) has a constant variance regardless of \\(X\\).\n\n\n\n\n\n\n\n\n\n\\[\\begin{align*}\nY_i \\mid X_i \\stackrel{indep}{\\sim} N(\\beta_0 + \\beta_1X_i, \\sigma^2)\n\\end{align*}\\]\n\nFor any fixed value of \\(X_i = x_i\\), the response, \\(Y_i\\), varies with \\(N(\\mu_{Y_i\\mid x_i}, \\sigma^2)\\).\n\n\n\n\n\n\nFigureÂ 23.14: The response \\(Y_i\\) follows a normal distribution.\n\n\n\n\n\n\n\n\nJob: Collect data and estimate the unknown parameters \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\)!"
  },
  {
    "objectID": "model-reg.html#fitting-a-regression-line-haty-b_0-b_1x",
    "href": "model-reg.html#fitting-a-regression-line-haty-b_0-b_1x",
    "title": "23Â  Linear Regression",
    "section": "\n23.3 Fitting a Regression Line \\(\\hat{Y} = b_0 + b_1X\\)\n",
    "text": "23.3 Fitting a Regression Line \\(\\hat{Y} = b_0 + b_1X\\)\n\n Idea of Fitting \n\nGiven the sample data \\(\\{ (x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\},\\)\n\nWhich sample regression line is the best?\nWhat are the best estimators, \\(b_0\\) and \\(b_1\\), for \\(\\beta_0\\) and \\(\\beta_1\\)?\n\n\n\n\n\n\n\nFigureÂ 23.15: One data set can have multiple fitted regression lines\n\n\n\n\n\nWe are interested in \\(\\beta_0\\) and \\(\\beta_1\\) in the following sample regression model: \\[\\begin{align*}\ny_i = \\beta_0 + \\beta_1~x_{i} + \\epsilon_i,\n\\end{align*}\\] or \\[E({y}_{i}) = \\mu_{y|x_i} = \\beta_0 + \\beta_1~x_{i}\\]\nWe use the sample statistics \\(b_0\\) and \\(b_1\\), which are computed from our sample data, to estimate \\(\\beta_0\\) and \\(\\beta_1\\).\n\\(\\hat{y}_{i} = b_0 + b_1~x_{i}\\) is called the fitted value of \\(y_i\\) and is a point estimate of the mean, \\(\\mu_{y|x_i}\\), and \\(y_i\\) itself.\n\n\n Ordinary Least Squares (OLS) \n\nWhat does best mean?\n\nWe want to choose \\(b_0\\) and \\(b_1\\) or the sample regression line \\(b_0 + b_1x\\) that minimizes the sum of squared residuals \\(SS_{res}\\).\n\n\nThe residual, \\(e_i = y_i - \\hat{y}_i = y_i - (b_0 + b_1x_i)\\), is a point estimate of \\(\\epsilon_i\\).\nThe sample regression line minimizes \\(SS_{res} = e_1^2 + e_2^2 + \\dots + e_n^2 = \\sum_{i = 1}^n e_i^2\\). \\[\\small{\\begin{align} SS_{res} &= (y_1 - b_0 - b_1x_1)^2 + (y_2 - b_0 - b_1x_2)^2 + \\dots + (y_n - b_0 - b_1x_n)^2\\\\ &= \\sum_{i=1}^n(y_i - b_0 - b_1x_i)^2 \\end{align}}\\]\n\n\n Visualizing Residuals \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Least Squares Estimates (LSE) \n\nIn the least squares approach, we choose the \\(b_0\\) and \\(b_1\\) that minimize the \\(SS_{res}\\). \\[(b_0, b_1) = \\arg \\min_{\\beta_0, \\beta_1} \\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\]\nMATH 1450 â€¦\n\n\\[\\color{red}{b_0 = \\overline{y} - b_1\\overline{x}}\\]\n\\[\\color{red}{b_1 = \\frac{\\sum_{i=1}^n(x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n(x_i - \\overline{x})^2} = \\frac{S_{xy}}{S_{xx}} = r \\frac{\\sqrt{S_{yy}}}{\\sqrt{S_{xx}}}},\\] where \\(S_{xx} = \\sum_{i=1}^n(x_i - \\overline{x})^2\\), \\(S_{yy} = \\sum_{i=1}^n(y_i - \\overline{y})^2\\), \\(S_{xy} = \\sum_{i=1}^n(x_i - \\overline{x})(y_i - \\overline{y})\\)\n\n\n\n\n\n\nWhat can we learn from the formula of \\(b_0\\) and \\(b_1\\)?\n\n\n\n\n\n\n\n Estimation for \\(\\sigma^2\\) \n\nWe can think of \\(\\sigma^2\\) as variance around the line or the mean square (prediction) error.\nThe estimate of \\(\\sigma^2\\) is the mean square residual, \\(MS_{res}\\): \\[\\hat{\\sigma}^2 = MS_{res} = \\frac{SS_{res}}{n-2} = \\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}\\]\n\n\n\\(MS_{res}\\) is often shown in computer output as \\(\\texttt{MS(Error)}\\) or \\(\\texttt{MS(Residual)}\\).\n\n\\(E(MS_{res}) = \\sigma^2\\)\n\nTherefore, \\(\\hat{\\sigma}^2\\) is an unbiased estimator for \\(\\sigma^2\\) ðŸ‘."
  },
  {
    "objectID": "model-reg.html#confidence-intervals-and-hypothesis-testing-for-beta_0-and-beta_1",
    "href": "model-reg.html#confidence-intervals-and-hypothesis-testing-for-beta_0-and-beta_1",
    "title": "23Â  Linear Regression",
    "section": "\n23.4 Confidence Intervals and Hypothesis Testing for \\(\\beta_0\\) and \\(\\beta_1\\)\n",
    "text": "23.4 Confidence Intervals and Hypothesis Testing for \\(\\beta_0\\) and \\(\\beta_1\\)\n\n Confidence Intervals for \\(\\beta_0\\) and \\(\\beta_1\\) \n\n\n\\(\\frac{b_1 - \\beta_1}{\\sqrt{\\hat{\\sigma}^2/S_{xx}}} \\sim t_{n-2}\\); \\(\\quad \\frac{b_0 - \\beta_0}{\\sqrt{\\hat{\\sigma}^2\\left(\\frac{1}{n} + \\frac{\\overline{x}^2}{S_{xx}}\\right)}} \\sim t_{n-2}\\)\n\nThe \\((1-\\alpha)100\\%\\) CI for \\(\\beta_1\\) is \\(b_1 \\pm t_{\\alpha/2, n-2}\\sqrt{\\hat{\\sigma}^2/S_{xx}}\\)\n\nThe \\((1-\\alpha)100\\%\\) CI for \\(\\beta_0\\) is \\(b_0 \\pm t_{\\alpha/2, n-2}\\sqrt{\\hat{\\sigma}^2\\left(\\frac{1}{n} + \\frac{\\overline{x}^2}{S_{xx}}\\right)}\\)\n\n\n\n Hypothesis Testing \n \\(\\beta_1\\) \n\n\n \\(H_0: \\beta_1 = \\beta_1^0 \\quad H_1: \\beta_1 \\ne \\beta_1^0\\)  \n\nTest statistic: Under \\(H_0\\), \\[t_{test} = \\frac{b_1 - \\color{red}{\\beta_1^0}}{\\sqrt{\\frac{\\hat{\\sigma}^2}{S_{xx}}}} \\sim t_{n-2}\\]\n\nReject \\(H_0\\) in favor of \\(H_1\\) if\n\n\\(|t_{test}| > t_{\\alpha/2, \\, n-2}\\)\n\\(\\text{$p$-value} = 2P(t_{n-2} > |t_{test}|) < \\alpha\\)\n\n\n\n \\(\\beta_0\\) \n\n\n \\(H_0: \\beta_0 = \\beta_0^0 \\quad H_1: \\beta_0 \\ne \\beta_0^0\\)  \n\nTest statistic: Under \\(H_0\\), \\[t_{test} = \\frac{b_0 - \\color{red}{\\beta_0^0}}{\\sqrt{\\hat{\\sigma}^2\\left(\\frac{1}{n} + \\frac{\\overline{x}^2}{S_{xx}}\\right)}} \\sim t_{n-2}\\]\n\nReject \\(H_0\\) in favor of \\(H_1\\) if\n\n\\(|t_{test}| > t_{\\alpha/2, \\, n-2}\\)\n\\(\\text{$p$-value} = 2P(t_{n-2} > |t_{test}|) < \\alpha\\)\n\n\n\n Interpretation of Testing Results \n\n \\(H_0: \\beta_1 = 0 \\quad H_1: \\beta_1 \\ne 0\\) \n\nFailing to reject \\(H_0: \\beta_1 = 0\\) implies there is no linear relationship between \\(Y\\) and \\(X\\).\n\n\n\n\n\nFigureÂ 23.16: Failing to reject \\(H_0\\) means there is no linear relationship between X and Y, but they could have some other type of relationship.\n\n\n\n\n\n\n\n\n\n\nIf we reject \\(H_0: \\beta_1 = 0\\), does it mean \\(X\\) and \\(Y\\) are linearly related?\n\n\n\n\n\n\n Test of Significance of Regression \n\n\nRejecting \\(H_0: \\beta_1 = 0\\) could mean\n\nthe straight-line model is adequate.\nbetter results could be obtained with a more complicated model.\n\n\n\n\n\n\n\nFigureÂ 23.17: Rejecting \\(H_0\\) doesnâ€™t necessarily mean that a linear model is the best model, just that it is adequate."
  },
  {
    "objectID": "model-reg.html#analysis-of-variance-anova-approach",
    "href": "model-reg.html#analysis-of-variance-anova-approach",
    "title": "23Â  Linear Regression",
    "section": "\n23.5 Analysis of Variance (ANOVA) Approach",
    "text": "23.5 Analysis of Variance (ANOVA) Approach\n \\(X\\) - \\(Y\\) Relationship Explains Some Deviation \n\n\n\n\n\n\nSuppose we only have data for \\(Y\\) and have no information about \\(X\\) or the relationship between \\(X\\) and \\(Y\\). How do we predict a value of \\(Y\\)?\n\n\n\n\n\n\n\nIf the data have no pattern, our best guess for \\(Y\\) would be \\(\\overline{y}\\) (i.e., \\(\\hat{y}_i = \\overline{y}\\)).\n\nWe would treat \\(X\\) and \\(Y\\) as uncorrelated.\n\n\nThe (total) deviation from the mean is \\((y_i - \\overline{y})\\)\n\nIf \\(X\\) and \\(Y\\) are linearly related, fitting a linear regression model helps us predict the value of \\(Y\\) when the value of \\(X\\) is provided.\n\n\\(\\hat{y}_i = b_0 + b_1x_i\\) is closer to \\(y_i\\) than \\(\\overline{y}\\).\nThe regression model explains some of the deviation of \\(y\\).\n\n\n Partition of Deviation \n\nTotal deviation = Deviation explained by regression + unexplained deviation\n\\((y_i - \\overline{y}) = (\\hat{y}_i - \\overline{y}) + (y_i - \\hat{y}_i)\\)\n\\((19 - 9) = (13 - 9) + (19 - 13)\\)\n\n\n\n\n\nFigureÂ 23.18: Explained vs.Â unexplained deviation\n\n\n\n\n Sum of Squares (SS) \n\n\\(\\sum_{i=1}^n(y_i - \\overline{y})^2 = \\sum_{i=1}^n(\\hat{y}_i - \\overline{y})^2 + \\sum_{i=1}^n(y_i - \\hat{y}_i)^2\\)\nTotal SS \\((SS_T)\\) = Regression SS \\((SS_R)\\) + Residual SS \\((SS_{res})\\)\n\\(df_T = df_R + df_{res}\\)\n\\(\\color{blue}{(n-1) = 1 +(n-2)}\\)\n\n\n ANOVA for Testing Significance of Regression \n\n\n\n\nFigureÂ 23.19: Example of an ANOVA table\n\n\n\n\n\nA larger value of \\(F_{test}\\) indicates that the regression is significant.\nReject \\(H_0\\) if\n\n\\(F_{test} > F_{\\alpha, 1, n-2}\\)\n\n\\(\\text{$p$-value} = P(F_{1, n-2} > F_{test}) < \\alpha\\).\n\n\nANOVA is designed to test the \\(H_0\\) that all predictors have no value in predicting \\(y\\).\nIn SLR, the \\(F\\)-test of ANOVA gives the same result as a two-sided \\(t\\)-test of \\(H_0: \\beta_1=0\\).\n\n\n Coefficient of Determination \n\nThe coefficient of determination \\((R^2)\\) is the proportion of the variation in \\(y\\) that is explained by the regression model.\nIt is computed as \\[R^2 = \\frac{SS_R}{SS_T} =\\frac{SS_T - SS_{res}}{SS_T} = 1 - \\frac{SS_{res}}{SS_T}\\]\n\n\n\\(R^2\\) is the proportionate reduction of total variation associated with the use of \\(X\\).\n\n(a) \\(\\hat{y}_i = y_i\\) and \\(\\small SS_{res} = \\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = 0\\). (b) \\(\\hat{y}_i = \\overline{y}\\) and \\(\\small SS_R = \\sum_{i=1}^n(\\hat{y}_i - \\overline{y})^2 = 0\\).\n\n\n\n\n\nFigureÂ 23.20: Examples of \\(R^2\\) being equal to 1 and 0"
  },
  {
    "objectID": "model-reg.html#prediction",
    "href": "model-reg.html#prediction",
    "title": "23Â  Linear Regression",
    "section": "\n23.6 Prediction",
    "text": "23.6 Prediction\n Predicting the Mean Response \n\nWith the predictor value \\(x = x_0\\), we want to estimate the mean response \\(E(y\\mid x_0) = \\mu_{y|x_0} = \\beta_0 + \\beta_1 x_0\\).\n\n Example: The mean highway MPG \\(E(y \\mid x_0)\\) when displacement is \\(x = x_0 = 5.5\\). \n\n\nIf \\(x_0\\) is within the range of \\(x\\), an unbiased point estimator for \\(E(y\\mid x_0)\\) is \\[\\widehat{E(y\\mid x_0)} = \\hat{\\mu}_{y | x_0} = b_0 + b_1 x_0\\]\n\nThe \\((1-\\alpha)100\\%\\) CI for \\(E(y\\mid x_0)\\) is \\(\\boxed{\\hat{\\mu}_{y | x_0} \\pm t_{\\alpha/2, n-2} \\hat{\\sigma}\\sqrt{\\frac{1}{n} + \\frac{(x_0 - \\overline{x})^2}{S_{xx}}}}\\).\n\n\n\n\n\n\n\nDoes the length of the CI for \\(E(y\\mid x_0)\\) stay the same at any location of \\(x_0\\)?\n\n\n\n\n\n\n\n Predicting New Observations \n\nPredict the value of a new observation, \\(y_0\\), with \\(x = x_0\\).\n\n Example: The highway MPG of a car \\(y_0(x_0)\\) when its displacement is \\(x = x_0 = 5.5\\). \n\n\nAn unbiased point estimator for \\(y_0(x_0)\\) is \\[\\hat{y}_0(x_0) = b_0 + b_1 x_0\\]\n\nThe \\((1-\\alpha)100\\%\\) prediction interval (PI) for \\(y_0(x_0)\\) is \\(\\small \\boxed{\\hat{y_0} \\pm t_{\\alpha/2, n-2} \\hat{\\sigma}\\sqrt{1+ \\frac{1}{n} + \\frac{(x_0 - \\overline{x})^2}{S_{xx}}}}\\)\n\n\n\n\n\n\n\n\nWhat is the difference between CI for \\(E(y\\mid x_0)\\) and PI for \\(y_0(x_0)\\)?\n\n\n\n\n\n\n\n\nThe PI is wider as it includes the uncertainty about \\(b_0\\), \\(b_1\\) as well as \\(y_0\\) due to error, \\(\\epsilon\\)."
  },
  {
    "objectID": "model-reg.html#r-lab",
    "href": "model-reg.html#r-lab",
    "title": "23Â  Linear Regression",
    "section": "\n23.7 R Lab",
    "text": "23.7 R Lab\n mpg Data \n\nlibrary(ggplot2)  ## use data mpg in ggplot2 package\nmpg\n\n# A tibble: 234 Ã— 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 autoâ€¦ f        18    29 p     compâ€¦\n 2 audi         a4           1.8  1999     4 manuâ€¦ f        21    29 p     compâ€¦\n 3 audi         a4           2    2008     4 manuâ€¦ f        20    31 p     compâ€¦\n 4 audi         a4           2    2008     4 autoâ€¦ f        21    30 p     compâ€¦\n 5 audi         a4           2.8  1999     6 autoâ€¦ f        16    26 p     compâ€¦\n 6 audi         a4           2.8  1999     6 manuâ€¦ f        18    26 p     compâ€¦\n 7 audi         a4           3.1  2008     6 autoâ€¦ f        18    27 p     compâ€¦\n 8 audi         a4 quattro   1.8  1999     4 manuâ€¦ 4        18    26 p     compâ€¦\n 9 audi         a4 quattro   1.8  1999     4 autoâ€¦ 4        16    25 p     compâ€¦\n10 audi         a4 quattro   2    2008     4 manuâ€¦ 4        20    28 p     compâ€¦\n# â„¹ 224 more rows\n\n\n\n Highway MPG hwy vs.Â Displacement displ \n\nplot(x = mpg$displ, y = mpg$hwy,\n     las = 1, pch = 19, col = \"navy\", cex = 0.5,\n     xlab = \"Displacement (litres)\", ylab = \"Highway MPG\",\n     main = \"Highway MPG vs. Engine Displacement (litres)\")\n\n\n\n\n\n\n\n\n Fit Simple Linear Regression \n\n\n\nreg_fit <- lm(formula = hwy ~ displ, \n              data = mpg)\nreg_fit\n\n\nCall:\nlm(formula = hwy ~ displ, data = mpg)\n\nCoefficients:\n(Intercept)        displ  \n     35.698       -3.531  \n\ntypeof(reg_fit)\n\n[1] \"list\"\n\n\n\n\n\n\n## all elements in reg_fit\nnames(reg_fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n## use $ to extract an element of a list\nreg_fit$coefficients\n\n(Intercept)       displ \n  35.697651   -3.530589 \n\n\n\n\n\n\\(\\widehat{hwy}_{i} = b_0 + b_1 \\times displ_{i} = 35.7 - 3.5 \\times displ_{i}\\)\n\n\\(b_1\\): For a one unit (liter) increase of the displacement, we expect the highway MPG to be decreased, on average, by 3.5.\n\n\n Fitted Values of \\(y\\) \n\n## the first 5 observed response value y\nmpg$hwy[1:5]\n\n[1] 29 29 31 30 26\n\n## the first 5 fitted value y_hat\nhead(reg_fit$fitted.values, 5)\n\n       1        2        3        4        5 \n29.34259 29.34259 28.63647 28.63647 25.81200 \n\n## the first 5 predictor value x\nmpg$displ[1:5]\n\n[1] 1.8 1.8 2.0 2.0 2.8\n\nlength(reg_fit$fitted.values)\n\n[1] 234\n\n\n\n Add a Regression Line \n\nplot(x = mpg$displ, y = mpg$hwy, las = 1, pch = 19, col = \"navy\", cex = 0.5,\n     xlab = \"Displacement (litres)\", ylab = \"Highway MPG\",\n     main = \"Highway MPG vs. Engine Displacement (litres)\")\nabline(reg_fit, col = \"#FFCC00\", lwd = 3)\n\n\n\n\n\n\n\n\n Standard Error of Regression \n\n(summ_reg_fit <- summary(reg_fit))\n\n\nCall:\nlm(formula = hwy ~ displ, data = mpg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.1039 -2.1646 -0.2242  2.0589 15.0105 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  35.6977     0.7204   49.55   <2e-16 ***\ndispl        -3.5306     0.1945  -18.15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.836 on 232 degrees of freedom\nMultiple R-squared:  0.5868,    Adjusted R-squared:  0.585 \nF-statistic: 329.5 on 1 and 232 DF,  p-value: < 2.2e-16\n\n\n\n# lots of fitted information saved in summary(reg_fit)!\nnames(summ_reg_fit)\n\n [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\" \n\n# residual standard error (sigma_hat)\nsumm_reg_fit$sigma\n\n[1] 3.835985\n\n# from reg_fit\nsqrt(sum(reg_fit$residuals^2) / reg_fit$df.residual)\n\n[1] 3.835985\n\n\n\n Confidence Intervals and Testing for \\(\\beta_0\\) and \\(\\beta_1\\) \n\nconfint(reg_fit, level = 0.95)\n\n                2.5 %   97.5 %\n(Intercept) 34.278353 37.11695\ndispl       -3.913828 -3.14735\n\n\n\nsumm_reg_fit\n\n\nCall:\nlm(formula = hwy ~ displ, data = mpg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.1039 -2.1646 -0.2242  2.0589 15.0105 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  35.6977     0.7204   49.55   <2e-16 ***\ndispl        -3.5306     0.1945  -18.15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.836 on 232 degrees of freedom\nMultiple R-squared:  0.5868,    Adjusted R-squared:  0.585 \nF-statistic: 329.5 on 1 and 232 DF,  p-value: < 2.2e-16\n\n\n\nsumm_reg_fit$coefficients\n\n             Estimate Std. Error   t value      Pr(>|t|)\n(Intercept) 35.697651  0.7203676  49.55477 2.123519e-125\ndispl       -3.530589  0.1945137 -18.15085  2.038974e-46\n\n\n\n ANOVA Table \n\nFor \\(H_0: \\beta_1 = 0\\) in SLR, \\(t_{test}^2 = F_{test}\\).\n\n\nanova(reg_fit)\n\nAnalysis of Variance Table\n\nResponse: hwy\n           Df Sum Sq Mean Sq F value    Pr(>F)    \ndispl       1 4847.8  4847.8  329.45 < 2.2e-16 ***\nResiduals 232 3413.8    14.7                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsumm_reg_fit$coefficients\n\n             Estimate Std. Error   t value      Pr(>|t|)\n(Intercept) 35.697651  0.7203676  49.55477 2.123519e-125\ndispl       -3.530589  0.1945137 -18.15085  2.038974e-46\n\nsumm_reg_fit$coefficients[2, 3] ^ 2\n\n[1] 329.4533\n\n\n\n \\(R^2\\) \n\nsumm_reg_fit\n\n\nCall:\nlm(formula = hwy ~ displ, data = mpg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.1039 -2.1646 -0.2242  2.0589 15.0105 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  35.6977     0.7204   49.55   <2e-16 ***\ndispl        -3.5306     0.1945  -18.15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.836 on 232 degrees of freedom\nMultiple R-squared:  0.5868,    Adjusted R-squared:  0.585 \nF-statistic: 329.5 on 1 and 232 DF,  p-value: < 2.2e-16\n\n\n\nsumm_reg_fit$r.squared\n\n[1] 0.5867867\n\n\n\n Prediction \n\n## CI for the mean response\npredict(reg_fit, newdata = data.frame(displ = 5.5), interval = \"confidence\", level = 0.95)\n\n       fit      lwr      upr\n1 16.27941 15.35839 17.20043\n\n## PI for the new observation\npredict(reg_fit, newdata = data.frame(displ = 5.5), interval = \"predict\", level = 0.95)\n\n       fit      lwr      upr\n1 16.27941 8.665682 23.89314"
  },
  {
    "objectID": "model-reg.html#exercises",
    "href": "model-reg.html#exercises",
    "title": "23Â  Linear Regression",
    "section": "\n23.8 Exercises",
    "text": "23.8 Exercises\nUse the data in the table below to answer questions 1-7.\n\n\nTar\n24\n28\n21\n23\n20\n22\n20\n25\n\n\n\n\nNicotine\n1.6\n1.7\n1.2\n1.4\n1.1\n1.0\n1.3\n1.2\n\n\n\n\n\nConstruct a scatterplot using tar for the \\(x\\) axis and nicotine for the \\(y\\) axis. Does the scatterplot suggest a linear relationship between the two variables? Are they positively or negatively related?\nLet \\(y\\) be the amount of nicotine and let \\(x\\) be the amount of tar. Fit a simple linear regression to the data and identify the sample regression equation.\nWhat percentage of the variation in nicotine can be explained by the linear correlation between nicotine and tar?\nThe Raleigh brand king size cigarette is not included in the table, and it has 21 mg of tar. What is the best predicted amount of nicotine? How does the predicted amount compare to the actual amount of 1.2 mg of nicotine? What is the value of residual?\nPerform the test \\(H_0: \\beta_1 = 0\\) vs.Â \\(H_1: \\beta_1 \\ne 0\\).\nProvide 95% confidence interval for \\(\\beta_1\\).\nGenerate the ANOVA table for the linear regression.\n\n\n\n\nCorrelation (30 points): Match each correlation to the corresponding scatterplot.\n\n\\(R = -0.65\\)\n\\(R = 0.47\\)\n\\(R = 0.03\\)\n\\(R = 0.93\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression (30 points): The following regression output is for predicting the heart weight (in g) of cats from their body weight (in kg).\n\nWrite out the simple linear regression equation.\nWhich one is the response variable and which one is the predictor (explanatory variable)?\nInterpret the slope and intercept.\n\n\n\n\n\n(Intercept)\n-0.346\n\n\nbody wt\n3.953"
  },
  {
    "objectID": "model-logistic.html#regression-vs.-classification",
    "href": "model-logistic.html#regression-vs.-classification",
    "title": "24Â  Logistic Regression",
    "section": "\n24.1 Regression vs.Â Classification",
    "text": "24.1 Regression vs.Â Classification\n\nLinear regression assumes that the response \\(Y\\) is numerical.\nIn many situations, \\(Y\\) is categorical.\n\n\n\nNormal vs.Â COVID vs.Â Smokerâ€™s Lungs\n\n\n\n\n\n\n\n\n\n\n\nFake vs.Â Fact\n\n\n\n\n\n\n\n\n\n\n\nThe process of predicting a categorical response is known as classification.\n\n\n Regression Function \\(f(x)\\) vs.Â Classifier \\(C(x)\\) \n\n\n\n\n\n\n\n\n\nFigureÂ 24.1: Difference between classification and regression (https://daviddalpiaz.github.io/r4sl/classification-overview.html)\n\n\n\n\n\n Classification Example \n\nPredict whether people will default on their credit card payment, where \\((Y)\\) is yes or no, based on their monthly credit card balance, \\((X)\\).\nWe use the sample data \\(\\{(x_1, y_1), \\dots, (x_n, y_n)\\}\\) to build a classifier.\n\n\n\n\n\n\n\nFigureÂ 24.2: Boxplot of Default vs.Â Balance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Why Not Linear Regression? \n\\[Y =\\begin{cases}\n    0  & \\quad \\text{if not default}\\\\\n    1  & \\quad \\text{if default}\n     \\end{cases}\\]\n\n\n\\(Y = \\beta_0 + \\beta_1X + \\epsilon\\), \\(\\, X =\\) credit card balance\n\n\n\n\n\n\n\nWhat is the problem with this dummy variable approach?\n\n\n\n\n\n\n\n\n\\(\\hat{Y} = b_0 + b_1X\\) estimates \\(P(Y = 1 \\mid X) = P(default = yes \\mid balance)\\)\n\n\n\n\n\n\nFigureÂ 24.3: Graphical illustration of why a simple linear regression model wonâ€™t work for Default ~ Balance\n\n\n\n\n\n\nSome estimates might be outside \\([0, 1]\\), which doesnâ€™t make sense given that \\(Y\\) is a probability.\n\n\n Why Logistic Regression? \n\nWe first predict the probability of each category of \\(Y\\).\nThen, we predict the probability of default using an S-shaped curve.\n\n\n\n\n\nFigureÂ 24.4: Graphical illustration of why a logistic regression model works better for Default ~ Balance"
  },
  {
    "objectID": "model-logistic.html#introduction-to-logistic-regression",
    "href": "model-logistic.html#introduction-to-logistic-regression",
    "title": "24Â  Logistic Regression",
    "section": "\n24.2 Introduction to Logistic Regression",
    "text": "24.2 Introduction to Logistic Regression\n Binary Responses \n\nTreat each outcome, default \\((y = 1)\\) and not default \\((y = 0)\\), as success and failure arising from separate Bernoulli trials.\n\n\n\n\n\n\n\nWhat is a Bernoulli trial?\n\n\n\n\nA Bernoulli trial is a special case of a binomial trial when the number of trials is \\(m = 1\\).\n\nThere are exactly two possible outcomes, â€œsuccessâ€ and â€œfailureâ€.\nThe probability of success, \\(\\pi\\), is constant.\n\n\n\n\n\n\n\n\n\n\n\nIn the default credit card example,\n\n\n\n\nDo we have exactly two outcomes?\nDo we have constant probability? \\(P(y_1 = 1) = P(y_2 = 1) = \\cdots = P(y_n = 1) = \\pi?\\)\n\n\n\n\n Nonconstant Probability\n\n\n\nTwo outcomes: Default \\((y = 1)\\) and Not Default \\((y = 0)\\)\n\nThe probability of success, \\(\\pi\\), changes with the value of predictor, \\(X\\)!\nWith a different value of \\(x_i\\), each Bernoulli trial outcome, \\(y_i\\), has a different probability of success, \\(\\pi_i\\).\n\n\n\n\n\n\n\n\n\n\n\n\\[ y_i \\mid x_i \\stackrel{indep}{\\sim} \\text{Bernoulli}(\\pi(x_i)) = binomial(m=1,\\pi = \\pi(x_i)) \\]\n\n\n\\(X =\\) balance. \\(x_1 = 2000\\) has a larger \\(\\pi_1 = \\pi(2000)\\) than \\(\\pi_2 = \\pi(500)\\) with \\(x_2 = 500\\) because credit cards with a higher balance are more likely to default.\n\n\n Logistic Regression \n\n\nLogistic regression models a binary response \\((Y)\\) using predictors \\(X_1, \\dots, X_k\\).\n\n\n\\(k = 1\\): simple logistic regression\n\n\\(k > 1\\): multiple logistic regression\n\n\nInstead of predicting \\(y_i\\) directly, we use the predictors to model its probability of success, \\(\\pi_i\\).\n\n\nBut how?\n\n\n Logit function \\(\\eta = logit(\\pi) = \\ln\\left(\\frac{\\pi}{1-\\pi}\\right)\\) \n\nTransform \\(\\pi \\in (0, 1)\\) into another variable \\(\\eta \\in (-\\infty, \\infty)\\). Then fit a linear regression on \\(\\eta\\).\n\nLogit function: For \\(0 < \\pi < 1\\)\n\n\n\\[\\eta = logit(\\pi) = \\ln\\left(\\frac{\\pi}{1-\\pi}\\right)\\]\n\n\n\n\nFigureÂ 24.5: Graphical illustration of the logit function\n\n\n\n\n Logistic Function \\(\\pi = logistic(\\eta) = \\frac{\\exp(\\eta)}{1+\\exp(\\eta)}\\) \n\nThe logit function \\(\\eta = logit(\\pi) = \\ln\\left(\\frac{\\pi}{1-\\pi}\\right)\\) takes a value \\(\\pi \\in (0, 1)\\) and maps it to a value \\(\\eta \\in (-\\infty, \\infty)\\).\n\nLogistic function: \\[\\pi = logistic(\\eta) = \\frac{\\exp(\\eta)}{1+\\exp(\\eta)} = \\frac{1}{1+\\exp(-\\eta)} \\in (0, 1)\\]\n\nThe logistic function takes a value \\(\\eta \\in (-\\infty, \\infty)\\) and maps it to a value \\(\\pi \\in (0, 1)\\).\nSo once \\(\\eta\\) is estimated by the linear regression, we use the logistic function to transform \\(\\eta\\) back to the probability.\n\n\n\n\n\nFigureÂ 24.6: Graphical illustration of the logistic function"
  },
  {
    "objectID": "model-logistic.html#simple-logistic-regression-model",
    "href": "model-logistic.html#simple-logistic-regression-model",
    "title": "24Â  Logistic Regression",
    "section": "\n24.3 Simple Logistic Regression Model",
    "text": "24.3 Simple Logistic Regression Model\n\nFor \\(i = 1, \\dots, n\\) and with one predictor \\(X\\): \\[(Y_i \\mid X = x_i) \\stackrel{indep}{\\sim} \\text{Bernoulli}(\\pi(x_i))\\] \\[\\text{logit}(\\pi_i) = \\ln \\left( \\frac{\\pi(x_i)}{1 - \\pi(x_i)} \\right) = \\eta_i = \\beta_0+\\beta_1 x_{i}\\]\n\n\n\\[\\small \\pi_i = \\frac{\\exp(\\beta_0+\\beta_1 x_{i})}{1+\\exp(\\beta_0+\\beta_1 x_{i})} = \\frac{\\exp(\\eta_i)}{1 + \\exp(\\eta_i)}\\]\n\\[\\small \\hat{\\pi}_i = \\frac{\\exp(\\hat{\\beta}_0+\\hat{\\beta}_1 x_{i} )}{1+\\exp(\\hat{\\beta}_0+\\hat{\\beta}_1 x_{i})}\\]\n\n Probability Curve \n\n\n\nThe relationship between \\(\\pi(x)\\) and \\(x\\) is not linear! \\[\\pi(x) = \\frac{\\exp(\\beta_0+\\beta_1 x)}{1+\\exp(\\beta_0+\\beta_1 x)}\\]\n\nThe amount that \\(\\pi(x)\\) changes due to a one-unit change in \\(x\\) depends on the current value of \\(x\\).\nRegardless of the value of \\(x\\), if \\(\\beta_1 > 0\\), increasing \\(x\\) will increase \\(\\pi(x)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Interpretation of Coefficients \n\nThe ratio \\(\\frac{\\pi}{1-\\pi} \\in (0, \\infty)\\) is called the odds of some event.\nExample: If 1 in 5 people will default, the odds is 1/4 since \\(\\pi = 0.2\\) implies an odds of \\(0.2/(1âˆ’0.2) = 1/4\\).\n\n\\[\\ln \\left( \\frac{\\pi(x)}{1 - \\pi(x)} \\right)= \\beta_0 + \\beta_1x\\]\n-Increasing \\(x\\) by one unit changes the log-odds by \\(\\beta_1\\), or it multiplies the odds by \\(e^{\\beta_1}\\).\n\n\n\n\n\n\nNote\n\n\n\n\n\n\\(\\beta_1\\) does not correspond to the change in \\(\\pi(x)\\) associated with a one-unit increase in \\(x\\).\n\n\\(\\beta_1\\) is the change in log odds associated with one-unit increase in \\(x\\)."
  },
  {
    "objectID": "model-logistic.html#logistic-regression-in-r",
    "href": "model-logistic.html#logistic-regression-in-r",
    "title": "24Â  Logistic Regression",
    "section": "\n24.4 Logistic Regression in R",
    "text": "24.4 Logistic Regression in R\n\n\n\n\nGENDER = 1 if male\n\nGENDER = 0 if female\nUse HEIGHT (centimeter, 1 cm = 0.3937 in) to predict/classify GENDER: whether the person is male or female.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbody <- read.table(\"./data/01 - Body Data.txt\", header = TRUE)\nhead(body)\n\n  AGE GENDER PULSE SYSTOLIC DIASTOLIC HDL LDL WHITE  RED PLATE WEIGHT HEIGHT\n1  43      0    80      100        70  73  68   8.7 4.80   319   98.6  172.0\n2  57      1    84      112        70  35 116   4.9 4.73   187   96.9  186.0\n3  38      0    94      134        94  36 223   6.9 4.47   297  108.2  154.4\n4  80      1    74      126        64  37  83   7.5 4.32   170   73.1  160.5\n5  34      1    50      114        68  50 104   6.1 4.95   140   83.1  179.0\n6  77      1    60      134        60  55  75   5.7 3.95   192   86.5  166.7\n  WAIST ARM_CIRC  BMI\n1 120.4     40.7 33.3\n2 107.8     37.0 28.0\n3 120.3     44.3 45.4\n4  97.2     30.3 28.4\n5  95.1     34.0 25.9\n6 112.0     31.4 31.1\n\n\n\n Data Summary \n\n\n\ntable(body$GENDER)\n\n\n  0   1 \n147 153 \n\nsummary(body[body$GENDER == 1, ]$HEIGHT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  155.0   169.1   173.8   174.1   179.4   193.3 \n\nsummary(body[body$GENDER == 0, ]$HEIGHT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  134.5   156.5   162.2   161.7   166.8   181.4 \n\n\n\n\n\n\nboxplot(body$HEIGHT ~ body$GENDER)\n\n\n\n\n\n\n\n Model Fitting \n\nlogit_fit <- glm(GENDER ~ HEIGHT, data = body, family = \"binomial\")\n(summ_logit_fit <- summary(logit_fit))\n\n\nCall:\nglm(formula = GENDER ~ HEIGHT, family = \"binomial\", data = body)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -40.54809    4.63084  -8.756   <2e-16 ***\nHEIGHT        0.24173    0.02758   8.764   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 415.77  on 299  degrees of freedom\nResidual deviance: 251.50  on 298  degrees of freedom\nAIC: 255.5\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nsumm_logit_fit$coefficients\n\n               Estimate Std. Error   z value     Pr(>|z|)\n(Intercept) -40.5480864 4.63083742 -8.756102 2.021182e-18\nHEIGHT        0.2417325 0.02758399  8.763507 1.892674e-18\n\n\n\n\\(\\hat{\\eta} = \\ln \\left( \\frac{\\hat{\\pi}}{1 - \\hat{\\pi}}\\right) = -40.55 + 0.24 \\times \\text{HEIGHT}\\)\n\\(\\hat{\\eta}(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1x\\)\n\\(\\hat{\\eta}(x+1) = \\hat{\\beta}_0 + \\hat{\\beta}_1(x+1)\\)\n\\(\\hat{\\eta}(x+1) - \\hat{\\eta}(x) = \\hat{\\beta}_1 = \\ln(\\text{odds}_{x+1}) - \\ln(\\text{odds}_{x}) = \\ln \\left( \\frac{\\text{odds}_{x+1}}{\\text{odds}_{x}} \\right)\\)\nA one centimeter increase in HEIGHT increases the log odds of being male by 0.24 units.\nThe odds ratio, \\(\\widehat{OR} = \\frac{\\text{odds}_{x+1}}{\\text{odds}_{x}} = e^{\\hat{\\beta}_1} = e^{0.24} = 1.273\\).\nThe odds of being male increases by 27.3% with an additional one centimeter of HEIGHT.\n\n\n Prediction \n Pr(GENDER = 1) When HEIGHT is 170 cm \n\n\\[ \\hat{\\pi}(x = 170) = \\frac{\\exp(\\hat{\\beta}_0+\\hat{\\beta}_1 x)}{1+\\exp(\\hat{\\beta}_0+\\hat{\\beta}_1 x)} = \\frac{\\exp(-40.55+0.24 \\times 170)}{1+\\exp(-40.55+0.24 \\times 170)} = 0.633 = 63.3\\%\\]\n\npi_hat <- predict(logit_fit, type = \"response\")\neta_hat <- predict(logit_fit, type = \"link\")  ## default gives us b0 + b1*x\npredict(logit_fit, newdata = data.frame(HEIGHT = 170), type = \"response\")\n\n        1 \n0.6333105 \n\n\n Probability Curve \n\n\n\n\n\n\nWhat is the probability of being male when the HEIGHT is 160 cm? What about when the HEIGHTis 180 cm?\n\n\n\n\n\n\n\npredict(logit_fit, newdata = data.frame(HEIGHT = c(160, 170, 180)), type = \"response\")\n\n        1         2         3 \n0.1334399 0.6333105 0.9509103 \n\n\n\n\n\n\n\n\n\n\n\n 160 cm, Pr(male) = 0.13\n 170 cm, Pr(male) = 0.63\n 180 cm, Pr(male) = 0.95"
  },
  {
    "objectID": "model-logistic.html#evaluation-metrics",
    "href": "model-logistic.html#evaluation-metrics",
    "title": "24Â  Logistic Regression",
    "section": "\n24.5 Evaluation Metrics",
    "text": "24.5 Evaluation Metrics\n Sensitivity and Specificity \n\n\n\n\n\n\n\n\n1\n0\n\n\n\nLabeled 1\nTrue Positive (TP)\nFalse Positive (FP)\n\n\nLabeled 0\nFalse Negative (FN)\nTrue Negative (TN)\n\n\n\n\n\nSensitivity (True Positive Rate) \\(= P( \\text{Labeled 1} \\mid \\text{1}) = \\frac{TP}{TP+FN}\\)\n\n\nSpecificity (True Negative Rate) \\(= P( \\text{Labeled 0} \\mid \\text{0}) = \\frac{TN}{FP+TN}\\)\n\n\nAccuracy \\(= \\frac{TP + TN}{TP+FN+FP+TN}\\) \n\nMore on Wiki page\n\n\n\n Confusion Matrix \n\nprob <- predict(logit_fit, type = \"response\")\n\n## true observations\ngender_true <- body$GENDER\n\n## predicted labels\ngender_predict <- (prob > 0.5) * 1\n\n## confusion matrix\ntable(gender_predict, gender_true)\n\n              gender_true\ngender_predict   0   1\n             0 118  29\n             1  29 124\n\n\n\n Receiver Operating Characteristic (ROC) Curve \n\n\nReceiver operating characteristic (ROC) curve\n\nPlots True Positive Rate (Sensitivity) vs.Â False Positive Rate (1 - Specificity)\n\n\nR packages for ROC curves: ROCR and pROC, yardstick of Tidymodels\n\n\n\n\n\n\nFigureÂ 24.7: ROC curve for Gender ~ Height"
  },
  {
    "objectID": "model-logistic.html#exercises",
    "href": "model-logistic.html#exercises",
    "title": "24Â  Logistic Regression",
    "section": "\n24.6 Exercises",
    "text": "24.6 Exercises\n\nThe following logistic regression equation is used for predicting whether a bear is male or female. The value of \\(\\pi\\) is the probability that the bear is male. \\[\\log\\left(\\frac{\\pi}{1-\\pi}\\right) = 2.3 - 0.0573 (\\text{Length}) + 0.00842(\\text{Weight})\\]\n\nIdentify the predictor and response variables. Which of these are dummy variables?\nGiven that the variable Lengthis in the model, does a heavier weight increase or decrease the probability that the bear is a male? Please explain.\nThe given regression equation has an overall p-value of 0.218. What does that suggest about the quality of predictions made using the regression equation?\nUse a length of 60 in. and a weight of 300 lb to find the probability that the bear is a male. Also, what is the probability that the bear is a female?"
  },
  {
    "objectID": "model-bayes.html#the-r-user-interface",
    "href": "model-bayes.html#the-r-user-interface",
    "title": "25Â  Bayesian Linear Regression",
    "section": "25.1 The R User Interface",
    "text": "25.1 The R User Interface"
  },
  {
    "objectID": "model-survival.html#life-table",
    "href": "model-survival.html#life-table",
    "title": "26Â  Survival Analysis",
    "section": "\n26.1 Life Table",
    "text": "26.1 Life Table\n\nA period life table describes mortality and longevity data for a hypothetical cohort.\nThe data is computed with the assumption that the conditions affecting mortality in a particular year remain the same throughout the lives of everyone in the hypothetical cohort.\n\nFor example, a 1-year-old toddler and an elderly 70-year-old live their entire life in a world with the same constant death rates that were present in a given year.\n\n\nAn example of a life table is shown in FigureÂ 26.1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 26.1: Life table for total population in the United States in 2018\n\n\n\n\n\nThe entire report can be downloaded at CDC Publications and Information Products.\nMortality experiences are different for various gender and race groups, so it is common to have tables for specific groups.\n\nFor example, FigureÂ 26.2 below is a table for females in the United States.\n\n\n\n\n\n\n\nFigureÂ 26.2: Life table for females in the United States in 2018\n\n\n\n\n\nThe basis year for the mortality rate in this table is 2018, as is highlighted in FigureÂ 26.3.\nThis life table has data for a cohort of 100,000 hypothetical people.\n\n\n\n\n\nFigureÂ 26.3: The life table lists its basis year and number of hypothetical individuals\n\n\n\n\n\nThe age ranges chosen for this life table include the following classes: \\([0, 1)\\), \\([1, 2)\\), \\([2, 3)\\), â€¦ \\([99, 100)\\), \\([100, \\infty)\\).\n\n\n\n\n\nFigureÂ 26.4: The first column lists the age intervals of the individuals\n\n\n\n\n\nThe probabilities of dying during the age interval are listed in the 1st column of the life table.\nFor example, in FigureÂ 26.5, there is a 0.000367 probability of someone dying between their 1st birthday and their 2nd birthday.\n\n\n\n\n\nFigureÂ 26.5: The second column lists the probability of dying between two ages\n\n\n\n\n\nThe number of people alive at the beginning of the age interval is listed in column 2.\nAs FigureÂ 26.6 displays, among the 100,000 hypothetical people who were born, 99,435 of them are alive on their 1st birthday.\n\n\n\n\n\nFigureÂ 26.6: The third column lists the number of individuals alive at the beginning of the age interval\n\n\n\n\n\nThe number of people who died during the age interval is listed in column 3.\n\n\n\n\n\n\n\nHow is this column related to the previous two columns?\n\n\n\n\n\n\n\n\n\n\nFigureÂ 26.7: The fourth column lists the number of individuals who die during a given age interval\n\n\n\n\n\nThe total number of years lived during the age interval by those who were alive at the beginning of the age interval is listed in the fourth column.\nFor example, the 100,000 people who were present at age 0 lived a total of 99,505 years (FigureÂ 26.8).\nIf none of those people had died, this entry would have been 100,000 years.\n\n\n\n\n\nFigureÂ 26.8: The fifth column lists the total number of person-years lived within a given age interval\n\n\n\n\n\nThe sixth column is similar to the fifth, but lists the total number of years lived during the age interval and all of the following age intervals as well.\n\n\n\n\n\nFigureÂ 26.9: The fifth column lists the total number of person-years lived above a given age\n\n\n\n\n\nThe final column lists the expected remaining lifetime in years, measured from the beginning of the age interval (FigureÂ 26.10).\n\n\n\n\n\n\n\nWhy does the age interval of 1-2 have an expected remaining lifetime of 78.2 years?\n\n\n\n\n\n\n\n\n\n\nFigureÂ 26.10: The final column lists the expectation of life at a given age\n\n\n\n\n\n Example: Probability of Dying \n\nUse FigureÂ 26.1 to find the probability of a person dying between age of 15 and 20.\n\n\\[\\begin{align*} Pr(\\text{die in } [15, 20)) &= Pr([15, 16) \\cup [16, 17) \\cup \\cdots \\cup [19, 20)) \\\\ &= Pr([15, 16) + Pr([16, 17)) + \\cdots + Pr([19, 20)) \\\\ &= 0.000214 + 0.000253 + 0.000292 + 0.000329 + 0.000365 = 0.001453 \\end{align*}\\]\n\\[\\begin{align*} Pr(\\text{surviving between 15th and 20th birthdays}) &= \\frac{\\text{Number of people alive on their 20th birthday}}{\\text{Number of people alive on their 15th birthday}} \\\\ &= \\frac{99,151}{99,296} \\\\ &= 0.99854 \\end{align*}\\]\n\\[Pr(\\text{die in } [15, 20)) = 1-Pr(\\text{survive in } [15, 20)) = 1 - 0.99854 = 0.00146\\]"
  },
  {
    "objectID": "model-survival.html#applications-of-life-tables",
    "href": "model-survival.html#applications-of-life-tables",
    "title": "26Â  Survival Analysis",
    "section": "\n26.2 Applications of Life Tables",
    "text": "26.2 Applications of Life Tables\n Social Security \n\n\n\nThere were 3,600,000 births in the U.S. in 2020.\nIf the age for receiving full Social Security payment is 67, how many of those born in 2020 are expected to be alive on their 67th birthday? Check the report!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmong 100,000 people born, we expect 81,637 of them will survive to their 67th birthday.\nTherefore, we expect that \\(3,600,000 \\times 0.81637 = 2,938,932\\) people born in 2020 will receive their full Social Security payment.\n\n\n Hypothesis Testing \n\n\n\nFor one city, there are 5000 people who reach their 16th birthday.\n25 of them die before their 17th birthday.\nDo we have sufficient evidence to conclude that this number of deaths is significantly high?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe probability of dying for the age interval of 16-17 is 0.000405.\nThis is a \\(H_1\\) claim.  \\(\\small \\begin{align} &H_0: \\pi = 0.000405 \\\\ &H_1: \\pi > 0.000405\\end{align}\\) \n\n\n\\(\\hat{\\pi} = 25/5000 = 0.005\\).\n\\(z = \\frac{0.005 - 0.000405}{\\sqrt{\\frac{(0.000405)(0.999595)}{5000}}} = 16.15\\)\n\n\\(P\\)-value \\(\\approx 0\\).\nThere is sufficient evidence to conclude that the proportion of deaths is significantly higher than the proportion that is usually expected for this age interval."
  },
  {
    "objectID": "model-survival.html#kaplan-meier-survival-analysis",
    "href": "model-survival.html#kaplan-meier-survival-analysis",
    "title": "26Â  Survival Analysis",
    "section": "\n26.3 Kaplan-Meier Survival Analysis",
    "text": "26.3 Kaplan-Meier Survival Analysis\n Survival Analysis \n\n\n\nThe life table method is based on fixed time intervals.\nThe Kaplan-Meier method\n\nis based on intervals that vary according to the times of survival to some particular terminating event.\nis used to describe the probability of surviving for a specific period of time.\n\n\n What is the probability of surviving for 5 more years after cancer chemotherapy? \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Survival Time \n\nThe time lapse from the beginning of observation to the time of terminating event is considered the survival time (FigureÂ 26.11).\n\n\n\n\n\nFigureÂ 26.11: Graph of survival time\n\n\n\n\n\n Survivor \n\nA survivor is a subject that successfully lasted throughout a particular time period.\n\n\n\n\n\n\n\nNote\n\n\n\n\nA survivor does not necessarily mean living.\n\nA patient trying to stop smoking is a survivor if smoking has not resumed.\nYour iPhone that worked for some particular length of time can be considered a survivor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCensored Data \n\nSurvival times are censored data if the subjects\n\nsurvive past the end of the study\n\nare dropped from the study for reasons not related to the terminating event being studied.\n\n\n\n\n\n\n\nFigureÂ 26.12: Illustration of censored data (https://unc.live/3K1ph8f)\n\n\n\n\n\n Example: Medication Treatment for Quitting Smoking \n\n\n\n\n\n\n\n\n\n\nDay\nStatus (0 = censored, 1 = Smoke Again)\nNumber of Patients\nPatients Not Smoking\nProportion Not Smoking\nCumulative Proportion Not Smoking\n\n\n\n1\n0\n\n\n\n\n\n\n3\n1\n4\n3\n3/4 = 0.75\n0.75\n\n\n4\n1\n3\n2\n2/3 = 0.67\n0.5\n\n\n7\n1\n2\n1\n1/2 = 0.5\n0.25\n\n\n21\n1\n1\n0\n0\n0\n\n\n\n\n\n\nâ€œSurvivingâ€ means the patient has NOT resumed smoking.\nAs shown in FigureÂ 26.13, the Subject 1 disliked the medication and dropped out of the study on day one.\nThe table above also provides information regarding the study.\n\n2nd row: Subject 2 resumed smoking 3 days after the start of the program.\n3rd row: \\(0.5 = (3/4)(2/3)\\)\n\n4th row: \\(0.25 = (3/4)(2/3)(1/2)\\)\n\n5th row: \\(0 = (3/4)(2/3)(1/2)(0)\\)\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 26.13: Survival time for five subjects receiving the medication treatment\n\n\n\n\n\n\n\n Example: Counseling Treatment for Quitting Smoking \n\n\n\n\n\n\n\n\n\n\nDay\nStatus  (0 = censored, 1 = Smoke Again)\nNumber of Patients\nPatients Not Smoking\nProportion Not Smoking\nCumulative Proportion Not Smoking\n\n\n\n2\n1\n10\n9\n9/10\n0.9\n\n\n4\n1\n9\n8\n8/9\n0.8\n\n\n5\n0\n\n\n\n\n\n\n8\n1\n7\n6\n6/7\n0.686\n\n\n9\n1\n6\n5\n5/6\n0.571\n\n\n12\n0\n\n\n\n\n\n\n14\n1\n4\n3\n3/4\n0.429\n\n\n22\n1\n3\n2\n2/3\n0.286\n\n\n24\n0\n\n\n\n\n\n\n28\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy is the cumulative proportion on Day 8 0.686?\n\n\n\n\\[0.686 = (9/10)(8/9)(6/7)\\]\n\nOn Day 5 a patient dropped out, so we donâ€™t know whether he resumed smoking on Day 8 or not.\n\n\n\n\n\n\n\n\n\n\nFigureÂ 26.14: Survival time for ten subjects receiving the counseling treatment\n\n\n\n\n\n\n\n Kaplan-Meier Analysis \n\n\n\n\n\n\nWhich treatment is better for quitting smoking?\n\n\n\n\n\n\n\n\n\n\nFigureÂ 26.15: Data from the medication treatment group and the counseling treatment group are compared using a Kaplan-Meier plot"
  },
  {
    "objectID": "infer-cat.html#sec-infer-goodnessfit",
    "href": "infer-cat.html#sec-infer-goodnessfit",
    "title": "\n19Â  Inference about Categorical Data\n",
    "section": "\n19.1 Test of Goodness of Fit",
    "text": "19.1 Test of Goodness of Fit\n\n\n\n Categorical Variable with More Than 2 Categories \n\n\n\nA categorical variable has \\(k\\) categories \\(A_1, \\dots, A_k\\).\n\n\n\nSubject\n\\(A_1\\)\n\\(A_2\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(A_k\\)\n\n\n\n1\nx\n\n\n\n\n\n\n2\n\nx\n\n\n\n\n\n3\n\n\n\n\nx\n\n\n\\(\\vdots\\)\n\n\n\n\n\n\n\n\\(n\\)\n\n\n\nx\n\n\n\n\n\n\n\n\nWith the size \\(n\\), for categories \\(A_1, \\dots , A_k\\), their observed count is \\(O_1, \\dots, O_k\\), and \\(\\sum_{i=1}^kO_i = n\\).\nOne-way count table:\n\n\n\n\\(A_1\\)\n\\(A_2\\)\n\\(\\cdots\\)\n\\(A_k\\)\nTotal\n\n\n\\(O_1\\)\n\\(O_2\\)\n\\(\\cdots\\)\n\\(O_k\\)\n\\(n\\)\n\n\n\n\n Example \n\n\n\nAre the selected jurors racially representative of the population?\nIf the jury is representative of the population, the proportions in the sample should reflect the proportions of the population of eligible jurors (i.e.Â registered voters).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\nRepresentation in juries\n205\n26\n25\n19\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\nRepresentation in juries\n0.745\n0.095\n0.091\n0.069\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n\n\n\n\n\n\n\n\n\nAre the proportions of juries close enough to the proportions of registered voters, so that we are confident saying that the jurors really were randomly sampled from the registered voters?\n\n\n\n\n\n\n\n Goodness-of-Fit Test \n\nA goodness-of-fit test tests the hypothesis that the observed frequency distribution fits or conforms to some claim distribution.\n\n\n\n\n\n\n\nIn the jury example, what is our observed frequency distribution, and what is our claim distribution?\n\n\n\n\n\n\n\n\n\n\n\n\nIf the individuals are randomly selected to serve on a jury, about how many of the 275 people would we expect to be white? How about black?\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n\n\n\nAbout \\(72\\%\\) of the population is white, so we would expect about \\(72\\%\\) of the jurors to be white.\n\n\n\\(0.72 \\times 275 = 198\\).\n\n\nWe expect about \\(7\\%\\) of the jurors to be black.\n\nThis corresponds to about \\(0.07 \\times 275 = 19.25\\) black jurors.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\n\nObserved Count\n205\n26\n25\n19\n\n\n\nExpected Count\n198\n19.25\n33\n24.75\n\n\nPopulation Proportion \\((H_0)\\)\n\n0.72\n0.07\n0.12\n0.09\n\n\n\n\nThe observed count and expected count will be similar if there was no bias in selecting the members of the jury.\nWe want to test whether the differences are strong enough to provide convincing evidence that the jurors were not selected from a random sample of all registered voters.\n\n Example \n\n \\(\\begin{align} &H_0: \\text{No racial bias in who serves on a jury, and } \\\\ &H_1: \\text{There is racial bias in juror selection} \\end{align}\\) \n \\(\\begin{align} &H_0: \\pi_1 = \\pi_1^0, \\pi_2 = \\pi_2^0, \\dots, \\pi_k = \\pi_k^0\\\\ &H_1: \\pi_i \\ne \\pi_i^0 \\text{ for some } i \\end{align}\\) \n Under \\(H_0\\), \\(\\chi^2_{test} = \\frac{(O_1 - E_1)^2}{E_1} + \\frac{(O_2 - E_2)^2}{E_2} + \\cdots + \\frac{(O_k - E_k)^2}{E_k}\\), \\(E_i = n\\pi_i^0, i = 1, \\dots, k\\) \nReject \\(H_0\\) if  \\(\\chi^2_{test} > \\chi^2_{\\alpha, df}\\), \\(df = k-1\\) \nRequire each \\(E_i \\ge 5\\), \\(i = 1, \\dots, k\\).\n\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\nObserved Count\n\\(O_1 = 205\\)\n\\(O_2 = 26\\)\n\\(O_3 = 25\\)\n\\(O_4 = 19\\)\n\n\nExpected Count\n\\(E_1 = 198\\)\n\\(E_2 = 19.25\\)\n\\(E_3 = 33\\)\n\\(E_4 = 24.75\\)\n\n\nProportion under \\(H_0\\)\n\n\\(\\pi_1^0 = 0.72\\)\n\\(\\pi_2^0 = 0.07\\)\n\\(\\pi_3^0 = 0.12\\)\n\\(\\pi_4^0 = 0.09\\)\n\n\n\n\nUnder \\(H_0\\), \\(\\chi^2_{test} = \\frac{(205 - 198)^2}{198} + \\frac{(26 - 19.25)^2}{19.25} + \\frac{(25 - 33)^2}{33} + \\frac{(19 - 24.75)^2}{24.75} = 5.89\\)\n\n\n\\(\\chi^2_{0.05, 3} = 7.81\\).\nBecause \\(5.89 < 7.81\\), we fail to reject \\(H_0\\) in favor of \\(H_1\\).\nWe do not have convincing evidence of racial bias in the juror selection process.\n\n Goodness-of-Fit Test in R \n\nBelow is an example of how to perform a Goodness-of-Fit test in R.\n\n\nobs <- c(205, 26, 25, 19)\npi_0 <- c(0.72, 0.07, 0.12, 0.09)\n\n## Use chisq.test() function\nchisq.test(x = obs, p = pi_0)\n\n\n    Chi-squared test for given probabilities\n\ndata:  obs\nX-squared = 5.8896, df = 3, p-value = 0.1171"
  },
  {
    "objectID": "infer-cat.html#test-of-independence",
    "href": "infer-cat.html#test-of-independence",
    "title": "19Â  Inference about Categorical Data",
    "section": "\n19.2 Test of Independence",
    "text": "19.2 Test of Independence\nSo far we consider one categorical variable with general \\(k\\) categories. In some situations, we have two categorical variables being considered, and we wonder if one affects the other distribution. Formally, we want to test whether or not the two variables are independent each other. The test doing this is the independence test.\n Contingency Table and Expected Count\n Contingency Table \nLetâ€™s start with an example. A popular question in politics is â€œDoes the opinion of the Presidentâ€™s job performance depend on gender?â€ This question may involve two categorical variables such as\n\nJob performance: approve, disapprove, no opinion\nGender: male, female\n\nTo answer such question, as every other test, we collect our data and see if there is any sufficient evidence to say the two variables are dependent. When two categorical variables are involved, we usually summarize the data in a contingency table or two-way frequency/count table as shown below.\n\n\n\n\n\nApprove\nDisapprove\nNo Opinion\nTotal\n\n\n\n\nMale\n18\n22\n10\n50\n\n\n\nFemale\n23\n20\n12\n55\n\n\n\nTotal\n41\n42\n22\n105\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen we consider a two-way table, we often would like to know, are these variables related in any way? That is, are they dependent (versus independent)? If Presidentâ€™s approval rate has nothing to do with gender, the Job performance distributions in the male and female groups should be similar or consistent. In other words, whether or not the person is male or female does not affect how Presidentâ€™s job performance is viewed.\n Expected Count \nThe idea is similar to goodness-of-fit test. We first calculate the expected count in each cell (Total row and column are excluded) in the contingency table, the count we expect to see under the condition that the two variables are independent. We always do our analysis in the world of null hypothesis that two variables have no relationship.\n\n\n\n\n\nApprove\nDisapprove\nNo Opinion\nTotal\n\n\n\nMale\n18 (19.52)\n22 (20)\n10 (10.48)\n50\n\n\nFemale\n23 (21.48)\n20 (22)\n12 (11.52)\n55\n\n\nTotal\n41\n42\n22\n105\n\n\n\nThe expected count for the \\(i\\)-th row and \\(j\\)-th column, which is listed in parentheses in the table above, is calculated by: \\[\\text{Expected Count}_{\\text{row i; col j}} = \\frac{\\text{(row i total}) \\times (\\text{col j total})}{\\text{table total}}\\] For example, the expected count of Disapprove in the Female group is \\[\\text{Expected Count}_{\\text{row 2; col 2}} = \\frac{\\text{(row 2 total}) \\times (\\text{col 2 total})}{\\text{table total}} = \\frac{42 \\times 55}{105} = 22.\\]\nWe are ready for doing test of independence once all expected counts are obtained.\n\n Test of Independence Procedure \nThe test of independence requires that every expected count \\(E_{ij} \\ge 5\\) in the contingency table. The higher the better.\nAs we discussed before, we believe the variables are independent unless strong evidence says they are not. So our hypotheses are  \\[\\begin{align} &H_0: \\text{Two variables are independent }\\\\ &H_1: \\text{The two are dependent (associated) } \\end{align}\\]\nThe test statistic formula is pretty similar to the test of goodness-of-fit. The test of independence is also a chi-squared test. The chi-squared test statistic is\n\\[\\chi^2_{test} = \\sum_{i=1}^r\\sum_{j=1}^c\\frac{(O_{ij} - E_{ij})^2}{E_{ij}},\\] where \\(r\\) is the number of rows and \\(c\\) is the number of columns in the contingency table. The idea is the same as the test of goodness-of-fit. Under the assumption of independence, if the observed counts are far away from the counts we should expect to see, we get a larger test statistic, and tend to conclude that the independence assumption is not reasonable.\nThe chi-squared test is right-tailed, so we reject \\(H_0\\) if \\(\\chi^2_{test} > \\chi^2_{\\alpha, \\, df}\\), where \\(df = (r-1)(c-1)\\).\n Example \n\n\n\nApprove\nDisapprove\nNo Opinion\nTotal\n\n\n\nMale\n18 (19.52)\n22 (20)\n10 (10.48)\n50\n\n\nFemale\n23 (21.48)\n20 (22)\n12 (11.52)\n55\n\n\nTotal\n41\n42\n22\n105\n\n\n\n \\[\\begin{align} &H_0: \\text{ Opinion does not depend on gender } \\\\ &H_1: \\text{ Opinion and gender are dependent } \\end{align}\\]\nThe test statistic is \\[\\small \\chi^2_{test} = \\frac{(18 - 19.52)^2}{19.52} + \\frac{(22 - 20)^2}{20} + \\frac{(10 - 10.48)^2}{10.48} + \\frac{(23 - 21.48)^2}{21.48} + \\frac{(20 - 22)^2}{22} + \\frac{(12 - 11.52)^2}{11.52}= 0.65\\]\nThe critical value is \\(\\chi^2_{\\alpha, df} =\\chi^2_{0.05, (2-1)(3-1)} = 5.991\\). Since \\(\\chi_{test}^2 < \\chi^2_{\\alpha, df}\\), we do not reject \\(H_0\\). Therefore we fail to conclude that the opinion of the Presidentâ€™s job performance depends on gender.\n Test of Independence in R \nCalculating all the expected counts is tedious, especially when the variables have many categories. In practice we never calculate them by hand, and use computing software to do so. Below is an example of how to perform the test of independence using R. Since the test of independence is a chi-squared test, we still use the chisq.test() function. This time we need to prepare the contingency table as a matrix, and put the matrix in the x argument in the function. Thatâ€™s it! R does everything for us. If we save the result as an object like ind_test which is a R list, we can get access to information related to the test, such as the expected counts ind_test$expected.\n\n(contingency_table <- matrix(c(18, 23, 22, 20, 10, 12), nrow = 2, ncol = 3))\n\n     [,1] [,2] [,3]\n[1,]   18   22   10\n[2,]   23   20   12\n\n## Using chisq.test() function\n(ind_test <- chisq.test(x = contingency_table))\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_table\nX-squared = 0.65019, df = 2, p-value = 0.7225\n\n## extract expected counts\nind_test$expected\n\n         [,1] [,2]     [,3]\n[1,] 19.52381   20 10.47619\n[2,] 21.47619   22 11.52381\n\n## critical value\nqchisq(0.05, df = (2 - 1) * (3 - 1), lower.tail = FALSE)  \n\n[1] 5.991465"
  },
  {
    "objectID": "infer-cat.html#exercises",
    "href": "infer-cat.html#exercises",
    "title": "19Â  Inference about Categorical Data",
    "section": "\n19.4 Exercises",
    "text": "19.4 Exercises\n\nA researcher has developed a model for predicting eye color. After examining a random sample of parents, she predicts the eye color of the first child. The table below lists the eye colors of offspring. On the basis of her theory, she predicted that 87% of the offspring would have brown eyes, 8% would have blue eyes, and 5% would have green eyes. Use 0.05 significance level to test the claim that the actual frequencies correspond to her predicted distribution.\n\n\n\nEye Color\nBrown\nBlue\nGreen\n\n\nFrequency\n127\n21\n5\n\n\n\nIn a study of high school students at least 16 years of age, researchers obtained survey results summarized in the accompanying table. Use a 0.05 significance level to test the claim of independence between texting while driving and driving when drinking alcohol. Are these two risky behaviors independent of one another?\n\n\n\n\nDrove after drinking alcohol?\n\n\n\n\n\nYes\nNo\n\n\nTexted while driving\n720\n3027\n\n\nDid not text while driving\n145\n4472"
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "Probability",
    "section": "",
    "text": "If we want to describe or quantify the uncertainty about something happening or not, the most formal and rigorous way of doing it is to use probability. Therefore, we can view the probability as the language of uncertainty.\nMost of the time, we cannot do statistical inference or prediction using machine learning without probability because we usually assume our data at hand are random realizations from some targeted population that are described by a probability distribution. In other words, we are doing data analysis in the world of uncertainty. As a result, before jumping into statistical inference or data analysis, we need to have basic understanding of probability definitions, rules, and operations that are frequently used in the data science community.\nIn this part, we are going to learn the following topics:\n\nProbability definitions\nProbability rules\nDiscrete probability distributions\nContinuous probability distributions\nSampling distributions\nLaw of large numbers and central limit theorem"
  },
  {
    "objectID": "prob-rv.html#random-variables",
    "href": "prob-rv.html#random-variables",
    "title": "8Â  Random Variables",
    "section": "\n8.1 Random Variables",
    "text": "8.1 Random Variables\nIn ChapterÂ 2, we learn that a variable in a data set is a characteristic or attribute that varies from one object to another. A variable can be either categorical or numerical. For example, gender is categorical and height is numerical. In addition, numerical variables can be either discrete or continuous. A discrete variable takes on values of a finite or countable number, while a continuous variable takes on values anywhere over a particular range without gaps or jumps. So the number of conferences Dr.Â Yu attended last year is discrete, and college GPA is continuous.\nWe know variables in a data set vary from one to another. If a variable takes numerical values, and its value is determined by some chance or randomness of a procedure or experiment, then we say the variable is a random variable, usually denoted as \\(X\\) or other capital English letters, \\(Y\\), \\(Z\\) for example.\nUsually a capital letter represents a random variable and a small letter represents a realized value of that random variable. For example, \\(X\\) is weight which is a random variable, and \\(x\\) is a realized value of \\(X\\) that can be any possible value of \\(X\\), for example, \\(X = 170\\) means the realized value \\(x\\) is 170.\n\nOther random variable examples are\n\n\\(X\\) = # of heads after flipping a coin twice.\n\\(X\\) = # of accidents in W. Wisconsin Ave. per day\n\nNote that \\(X\\) must follow some randomness pattern, and its realized value cannot be known in advance unless we collect the data or realize it.\nTo accounting for its randomness, a random variable has a probability distribution associated with it. The probability distribution governs the behavior of the random variable, indicating the range of the possible values, and what values are more probable to be realized than others. Probability distribution is key to uncertainty quantification in statistical inference and machine learning prediction. FigureÂ 8.1 below shows the many different types of probability distributions, and weâ€™ll discuss a few basic but important probability distributions in ChapterÂ 9 and ChapterÂ 10.\n\n\n\n\nFigureÂ 8.1: Source: https://github.com/rasmusab/distribution_diagrams\n\n\n\n\n\nWhen a random variable is defined, \\(X = x\\) or \\(a < X < b\\) or any specification about the values of \\(X\\) represents some event of some experiment. Consider the experiment that one tosses a fair coin twice independently, and define the random variable \\(X\\) as the number of heads. Then \\(\\{X = 0\\}\\) is the event \\(\\{\\text{tails}, \\text{tails}\\}\\) meaning that the first toss ends up with tails, so does the second toss. \\(\\{X = 1\\}\\) is the event \\(\\{\\text{tails}, \\text{heads}\\}\\) or \\(\\{\\text{heads}, \\text{tails}\\}\\) because heads can be shown up in the first toss or the second toss. \\(\\{X = 2\\}\\) corresponds to the event \\(\\{\\text{heads}, \\text{heads}\\}\\)."
  },
  {
    "objectID": "prob-disc.html#probability-mass-function",
    "href": "prob-disc.html#probability-mass-function",
    "title": "9Â  Discrete Probability Distributions",
    "section": "\n9.1 Probability Mass Function",
    "text": "9.1 Probability Mass Function\nA discrete random variable uses a probability function or probability mass function (pmf) to describe its randomness, and the pmf is its associated discrete probability distribution. The probability mass function of a discrete random variable \\(X\\) is a function of \\(X\\), denoted \\(P(X = x)\\) or \\(p(x)\\) for short, that assigns a probability to every possible number \\(x\\) of \\(X\\).\nThe probability distribution for a discrete \\(X\\) displays its probability function. The display can be a table, graph or mathematical formula of \\(P(X = x)\\) as long as every possible value of \\(X\\) has its own corresponding probability. We illustrate the probability function using an example of tossing a coin.\n Example:ðŸª™ðŸª™ Toss a fair coin twice independently where \\(X\\) is the number of heads. \nWith the example, first the possible values of \\(X\\) by its definition are 0, 1, and 2. Both results can be tails and \\(X = 0\\). We can have one heads and one tails, or \\(X=1\\), and we can have two heads showing up \\(X = 2\\). We cannot have \\(X=3\\) or any number greater than 2 because the coin is tossed twice only. Also, the possible value of \\(X\\) cannot be any non-integer values, like 1.5 or 0.8 because \\(X\\) is the number times, and it is discrete.\nTo present its probability distribution in a table, for each possible value of \\(X\\), we get to compute its probability, then list all probabilities as the table below.\n\n\n\n\n\n\n\nx\n0\n1\n2\n\n\nP(X = x)\n0.25\n0.5\n0.25\n\n\n\n\n\n\n\n\n\n\n\nLet me show the calculation of the probabilities.\n\n\\(P(X = 0) = P(\\{\\text{tails}, \\text{tails}\\}) = P(\\text{tails})P(\\text{tails}) = (0.5)(0.5) = 0.25.\\)\n\\(\\begin{align*} P(X = 1) &= P(\\{\\text{heads}, \\text{tails}\\} \\cup \\{\\text{tails}, \\text{heads}\\})\\\\ &= P(\\{\\text{heads}, \\text{tails}\\}) + P(\\{\\text{tails}, \\text{heads}\\}) \\\\ &= (0.5)(0.5) + (0.5)(0.5) = 0.5. \\end{align*}\\)\n\\(P(X = 2) = P(\\{\\text{heads}, \\text{heads}\\}) = P(\\text{heads})P(\\text{heads}) = (0.5)(0.5) = 0.25.\\)\n\nWe can also display the probability distribution using graphs. We put possible values of \\(X\\) in the x-axis, and the y-axis stands for the probability \\(P(X=x)\\). Then for each \\(x\\), we draw a vertical bar at \\(X=x\\) from \\(y = 0\\) to \\(y = P(X=x)\\). FigureÂ 9.1 shows the discrete probability distribution of two coin flips as a graph.\n\n\n\n\nFigureÂ 9.1: Discrete probability distribution of two coin flips as a graph\n\n\n\n\nIf you love math, you can specify the probability distribution using mathematical formula: \\[\nP(X = x)=\n\\begin{cases}\n{2 \\choose x}\\left( \\frac{1}{4}\\right), ~~ x = 0, 1, 2,\\\\\n0,  ~~ \\text{otherwise},\n\\end{cases}\n\\] where \\({2 \\choose x} = \\frac{2!}{x!(2-x)!}\\). Keep in mind that where \\(x\\) takes values or the support of \\(x\\) should be clearly specified.\nNow letâ€™s talk a little bit about the properties of pmf.\n\n\\(0 \\le P(X = x) \\le 1\\) for every value \\(x\\) of \\(X\\). Remember that \\(P(X = x)\\) is a probability of some event, for example \\(P(X = 0) = P(\\{\\text{tails}, \\text{tails}\\})\\), and weâ€™ve learned that \\(0 \\le P(A) \\le 1\\) for any event \\(A\\). \nThe probabilities for a discrete \\(X\\) are additive because \\(\\{X = a\\}\\) and \\(\\{X = b\\}\\) are disjoint for any possible values \\(a \\ne b\\). In our coin tossing example, \\(\\{X = 0\\}\\) and \\(\\{X = 1\\}\\) are disjoint because when tossing a fair coin two times independently, we cannot have no heads and one heads results at the same time. Therefore, \\[P(X = 0 \\text{ or } 1) = P(\\{X = 0\\} \\cup \\{X = 1\\}) = P(X = 0) + P(X = 1).\\]\n\\(\\sum_{x}P(X=x) = 1\\), where \\(x\\) assumes all possible values. In our coin tossing example, \\(P(X = 0) + P(X = 1) + P(X = 2) = 0.25 + 0.5 + 0.25 = 1\\). The reason is that \\(\\{X = 0\\}\\), \\(\\{X = 1\\}\\), and \\(\\{X = 2\\}\\) form a partition of the entire sample space, where in the example \\(\\mathcal{S} = \\left\\{ \\{\\text{tails}, \\text{tails}\\}, \\{\\text{heads}, \\text{tails}\\}, \\{\\text{tails}, \\text{heads}\\}, \\{\\text{heads}, \\text{heads}\\} \\right\\}\\). Therefore, \\(\\sum_{x}P(X=x) = P(\\mathcal{S}) = 1\\).\n\n\n Mean \nRemember that a probability distribution describes the randomness pattern of a random variable \\(X\\). Given its distribution, people are usually interested in its average value or central tendency and how uncertain it is or its dispersion.\nFor the central tendency, we consider the mean of a discrete variable \\(X\\). Suppose \\(X\\) takes values \\(x_1, \\dots, x_k\\) with probabilities \\(P(X = x_1), \\dots, P(X = x_k)\\). The mean or expected value of \\(X\\), written as \\(E(X)\\), is the sum of each outcome multiplied by its corresponding probability: \\[E(X) := x_1 \\times P(X = x_1) + \\dots + x_k \\times P(X = x_k) = \\sum_{i=1}^kx_iP(X=x_i)\\]\nThe Greek letter \\(\\mu\\) may also be used in place of the notation \\(E(X)\\).\nThe mean of a discrete random variable \\(X\\) is actually a weighted average of \\(x\\) weighted by their corresponding probability. \n\n\n\n\n\n\n\n\n\n\nWhat is the mean of \\(X\\) (the number of heads) in the coin example?\n\n\n\n\n\n\nIf you calculate it correctly, your answer should be one. It tells us that if we toss a fair coin twice independently, on average weâ€™ll see one heads showing up.\n\n Variance \nAs sample variance calculated from the sample data, we calculate the variance of the random variable \\(X\\) to quantify its variability and dispersion. Suppose \\(X\\) takes values \\(x_1, \\dots , x_k\\) with probabilities \\(P(X = x_1), \\dots, P(X = x_k)\\) and expected value \\(\\mu = E(X)\\). The variance of \\(X\\), denoted by \\(Var(X)\\) or \\(\\sigma^2\\), is\n\\[\\small \\begin{align*} Var(X) &:= (x_1 - \\mu)^2 \\times P(X = x_1) + \\dots + (x_k - \\mu)^2 \\times P(X = x_k) \\\\ &= \\sum_{i=1}^k(x_i - \\mu)^2P(X=x_i) \\\\ &= E[(X-\\mu)^2] \\end{align*}.\\]\nThe standard deviation of \\(X\\), \\(\\sigma\\), is the square root of the variance.\nIntuitively, the variance of a discrete random variable \\(X\\) is the weighted sum of squared deviation from the mean weighted by probability values. It is the mean squared distance from the mean.\n\n\n\n\n\n\n\n\n\n\nWhat is the variance of \\(X\\) (the number of heads) in the previous example?\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n\nThe mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)) of a random variable or probability distribution are not the same as the sample mean (\\(\\overline{x}\\)) and sample variance (\\(s^2\\)) calculated from the sample data. Their main difference will be discussed in the Part Inference.\n\n\n\n\nWe have learned the general discrete probability distributions. Next we are going to learn two popular discrete probability distributions, binomial and Poisson distribution."
  },
  {
    "objectID": "prob-cont.html#it-is-always-bell-shaped-and-symmetric-about-the-mean-mu.",
    "href": "prob-cont.html#it-is-always-bell-shaped-and-symmetric-about-the-mean-mu.",
    "title": "10Â  Continuous Probability Distributions",
    "section": "\n10.3 It is always bell-shaped and symmetric about the mean \\(\\mu\\).",
    "text": "10.3 It is always bell-shaped and symmetric about the mean \\(\\mu\\).\n\nBelow are examples of normal distribution curves and how they change with different means and standard deviations.\n\n\n\n\n\nFigureÂ 10.2: Normal density curve with mean 100 and standard deviation 15\n\n\n\n\n\n\n\n\nFigureÂ 10.3: Normal density curves with varying means and standard deviations"
  },
  {
    "objectID": "prob-llnclt.html#law-of-large-numbers",
    "href": "prob-llnclt.html#law-of-large-numbers",
    "title": "12Â  Law of Large Numbers and Central Limit Theorem",
    "section": "\n12.1 Law of Large Numbers",
    "text": "12.1 Law of Large Numbers\nComing soon."
  },
  {
    "objectID": "infer.html",
    "href": "infer.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "Statistics can be divided into two parts: descriptive statistics and inferential statistics. The descriptive statistics part has been discussed in Part Summarizing Data including ChapterÂ 4 and ChapterÂ 5, and many of you probably already learned lots of it in your middle or high school. The core and why statistics is that useful in every part of our life is its inferential techniques.\nWe have been equipped with sufficient probability tools for learning basic statistical inference. Weâ€™ll start with the very basic concept of statistical inference followed by inferential methods for various kinds of data and research questions.\nInferential statistics uses the information contained in the sample data to learn about some unknown target population characteristic of our interest. For example, we are interested in the mean height of the adults in the United States. The budget and/or time constraint, however, keep us from taking the census and knowing the height of every adult in the United States. Instead, we collected a sample data, and hopefully with a fair statistical method, we are able to use the height data in the sample to estimate the mean height of the adults in the United States as precisely as possible.\n\nTo be honest, statistical inference is a huge and difficult task. To simply our work, we usually assume the target population follows some distribution but with unknown parameters. Then our goal is to learn or uncover the unknown parameters of the assumed population distribution. For example, we can assume the height of the adults in the United States is normally distributed but with its mean \\(\\mu\\) unknown. Then our goal is to estimate the mean height \\(\\mu\\) from our data set.\n\n\n\n\n\n\n\n\n\nSince we only collect a small part of the entire population as our sample, we never see the entire picture and only have partial information, and the conclusion we made based on the sample, with pretty high chance, may be different or even far away from the unknown truth. Also, as we learned in ChapterÂ 11, our sample data vary due to its randomness nature. In statistics, we not only learn what we learn about the unknown parameter, but also learn how uncertain we are about what we learn.\nIn statistical inference, there are two main approaches in parameter learning: estimation and hypothesis testing. We are going to learn how to estimate and test on the unknown parameters for various types of data and questions. Get ready and letâ€™s go!"
  },
  {
    "objectID": "infer-bayes.html",
    "href": "infer-bayes.html",
    "title": "20Â  Bayesian Inference",
    "section": "",
    "text": "Coming soon."
  },
  {
    "objectID": "infer-nonpar.html",
    "href": "infer-nonpar.html",
    "title": "21Â  Nonparametric Inference",
    "section": "",
    "text": "Coming soon."
  },
  {
    "objectID": "infer-bt.html",
    "href": "infer-bt.html",
    "title": "14Â  Bootstrapping",
    "section": "",
    "text": "Coming soon."
  },
  {
    "objectID": "infer-ht.html#rare-event-rule",
    "href": "infer-ht.html#rare-event-rule",
    "title": "15Â  Hypothesis Testing",
    "section": "\n15.3 Rare Event Rule\n",
    "text": "15.3 Rare Event Rule\n\nIf, under a given assumption, the probability of a particular observed event is exceptionally small, we conclude that the assumption is probably not correct.   \nThe level \\(\\alpha\\) is related to the \\(\\alpha\\) used in confidence intervals for defining a â€œcritical valueâ€.\n\n Step 3: Calculate the Test Statistic \n\nA test statistic is a statistical value used in making a decision about the \\(H_0\\).\nSuppose  \\(H_0: \\mu = \\mu_0\\) and \\(\\quad H_1: \\mu < \\mu_0\\) .\nWhen computing a test statistic, we assume \\(H_0\\) is true.\nWhen \\(\\sigma\\) is known, the test statistic for testings about \\(\\mu\\) is\n\n\\[\\boxed{ z_{test} = \\frac{\\overline{x} - \\color{blue}{\\mu_0}}{\\sigma/\\sqrt{n}} }\\] - When \\(\\sigma\\) is unknown, the test statistic for testings about \\(\\mu\\) is\n\\[\\boxed{ t_{test} = \\frac{\\overline{x} - \\color{blue}{\\mu_0}}{s/\\sqrt{n}} }\\]\n\n Step 4-c: Find the Critical Value \n\nThe critical value(s) separates the rejection region or critical region, where we reject \\(H_0\\), from the values of the test statistic that do not lead to the rejection of \\(H_0\\).\n\nThese depend on whether the test is a right-tailed, left-tailed or two-tailed.\n\n\n\n\n\n\n\nFigureÂ 15.2: Rejection regions for the different types of hypothesis tests\n\n\n\n\n\n\n\\(z_{\\alpha}\\) is such that \\(P(Z > z_{\\alpha}) = \\alpha\\) and \\(Z \\sim N(0, 1)\\).\n\n\\(t_{\\alpha, n-1}\\) is such that \\(P(T > t_{\\alpha, n-1}) = \\alpha\\) and \\(T \\sim t_{n-1}\\).\n\n\n\n\n\n\n\n\n\nCondition Â  Â \n\nRight-tailed \\((H_1: \\mu > \\mu_0)\\)\n\n\nLeft-tailed \\((H_1: \\mu < \\mu_0)\\)\n\n\nTwo-tailed \\((H_1: \\mu \\ne \\mu_0)\\)\n\n\n\n\n\n\\(\\sigma\\) known\n\\(z_{\\alpha}\\)\n\\(-z_{\\alpha}\\)\n\n\\(-z_{\\alpha/2}\\) and \\(z_{\\alpha/2}\\)\n\n\n\n\n\\(\\sigma\\) unknown\n\\(t_{\\alpha, n-1}\\)\n\\(-t_{\\alpha, n-1}\\)\n\n\\(-t_{\\alpha/2, n-1}\\) and \\(t_{\\alpha/2, n-1}\\)\n\n\n\n\n\n\n\\(z_{0.025} =\\) 1.96, \\(z_{0.05} =\\) 1.64\n\n\\(z_{\\alpha}\\) and \\(t_{\\alpha, n-1}\\) are always positive.\n\n\n Step 5-c: Draw a Conclusion Using Critical Value \n\nIf the test statistic is\n\nin the rejection region, we reject \\(H_0\\).\n\nnot in the rejection region, we do not or fail to reject \\(H_0\\).\n\n\n\nReject \\(H_0\\) if\n\n\n\n\n\n\n\n\nCondition Â  Â \n\nRight-tailed \\((H_1: \\mu > \\mu_0)\\)\n\n\nLeft-tailed \\((H_1: \\mu < \\mu_0)\\)\n\n\nTwo-tailed \\((H_1: \\mu \\ne \\mu_0)\\)\n\n\n\n\n\n\\(\\sigma\\) known\n\\(z_{test} > z_{\\alpha}\\)\n\\(z_{test} < -z_{\\alpha}\\)\n\\(\\mid z_{test}\\mid \\, > z_{\\alpha/2}\\)\n\n\n\n\\(\\sigma\\) unknown\n\\(t_{test} > t_{\\alpha, n-1}\\)\n\\(t_{test} < -t_{\\alpha, n-1}\\)\n\\(\\mid t_{test}\\mid \\, > t_{\\alpha/2, n-1}\\)\n\n\n\n\n\n\n\nFigureÂ 15.3: Test statistic inside of critical region\n\n\n\n\n\n Step 4-p: Find the P-Value \n\nThe \\(p\\)-value measures the strength of the evidence against \\(H_0\\) provided by the data.\n\n\nThe smaller the \\(p\\)-value, the greater the evidence against \\(H_0\\).\n\n\nThe \\(p\\)-value is the probability of getting a test statistic value that is at least as extreme as the one obtained from the data, assuming that \\(H_0\\) is true. \\((\\mu = \\mu_0)\\)\n\nFor example, \\(p\\)-value \\(= P(Z \\ge z_{test} \\mid H_0)\\) for a right-tailed test.\n\n\nWe are more likely to get a \\(p\\)-value near 0 when \\(H_0\\) is false than when \\(H_0\\) is true.\n\n P-Value Illustration \n\n\n\n\nFigureÂ 15.4: Illustration of p-values for different types of hypothesis tests\n\n\n\n\n\n Step 5-p: Draw a Conclusion Using P-Value Method \n\nIf the \\(p\\)-value \\(\\le \\alpha\\) , we reject \\(H_0\\).\nIf the \\(p\\)-value \\(> \\alpha\\), we do not reject or fail to reject \\(H_0\\).\n\n\n\n\n\n\n\n\n\nCondition Â  Â \n\nRight-tailed \\((H_1: \\mu > \\mu_0)\\)\n\n\nLeft-tailed \\((H_1: \\mu < \\mu_0)\\)\n\n\nTwo-tailed \\((H_1: \\mu \\ne \\mu_0)\\)\n\n\n\n\n\n\\(\\sigma\\) known\n\\(P(Z > z_{test} \\mid H_0)\\)\n\\(P(Z < z_{test} \\mid H_0)\\)\n\\(2P(Z > \\,\\mid z_{test} \\mid \\, \\mid H_0)\\)\n\n\n\n\\(\\sigma\\) unknown\n\\(P(T > t_{test} \\mid H_0)\\)\n\\(P(T < t_{test} \\mid H_0)\\)\n\\(2P(T > \\, \\mid t_{test} \\mid \\, \\mid H_0)\\)\n\n\n\n\n Both Methods Lead to the Same Conclusion \n\n\n\n\nFigureÂ 15.5: The conclusion is the same regardless of the method used (Critical Value or P-Value).\n\n\n\n\n\n Step 6: Restate the Conclusion in Nontechnical Terms, and Address the Original Claim \n\n\n\n\nFigureÂ 15.6: Conclusions based on testing results (https://www.drdawnwright.com/category/statistics/)\n\n\n\n\n\n\nReminderâ€¦\n\n\n\n\n\nFigureÂ 15.7: Meme about hypothesis testing conclusions (https://www.pinterest.com/pin/287878601159173631/)"
  },
  {
    "objectID": "infer-twomean.html#to-compare-two-means-we-need-two-samples",
    "href": "infer-twomean.html#to-compare-two-means-we-need-two-samples",
    "title": "16Â  Comparing Two Population Means",
    "section": "\n16.2 To compare two means, we need two samples",
    "text": "16.2 To compare two means, we need two samples\n Dependent and Independent Samples \n\nThe two samples collected can be independent or dependent.\n\n\n\n\nTwo samples are dependent or matched pairs if the sample values are matched, where the matching is based on some inherent relationship.\n\n Height data of fathers and daughters, where the height of each dad is matched with the height of his daughter. \n Weights of subjects measure before and after some diet treatment, where the subjects are the same both before and after measurements. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dependent Samples (Matched Pairs) \n\nSubject 1 may refer to\n\nthe same person with two measurements (before and after)\nthe first matched pair (dad-daughter)\n\n\n\n\n\n\n\nSubject\n(Dad) Before\n(Daughter) After\n\n\n\n1\n\\(x_{b1}\\)\n\\(x_{a1}\\)\n\n\n2\n\\(x_{b2}\\)\n\\(x_{a2}\\)\n\n\n3\n\\(x_{b3}\\)\n\\(x_{a3}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_{bn}\\)\n\\(x_{an}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Independent Samples \n\n\n\nTwo samples are independent if the sample values from one population are not related to the sample values from the other.\n\n Salary samples of men and women, where the two samples are drawn independently from the male and female groups. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubject 1 of the Group 1 has nothing to do with the Subject 1 of the Group 2.\n\n\n\n\n\n\n\n\n\nSubject of Group 1 (Male)\nMeasurement of Group 1\nSubject of Group 2 (Female)\nMeasurement of Group 2\n\n\n\n1\n\\(x_{11}\\)\n1\n\\(x_{21}\\)\n\n\n2\n\\(x_{12}\\)\n2\n\\(x_{22}\\)\n\n\n3\n\\(x_{13}\\)\n3\n\\(x_{23}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n_1\\)\n\\(x_{1n_1}\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\\(n_2\\)\n\\(x_{2n_2}\\)\n\n\n\n\n Inference from Two Samples \n\nThe statistical methods are different for these two types of samples.\nThe good news is the concepts of confidence intervals and hypothesis testing for one population can be applied to two-population cases.\n\n\\(\\text{CI = point estimate} \\pm \\text{margin of error (E)}\\)\n\ne.g., \\(\\overline{x} \\pm t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}\\)\n\n\n\nMargin of error = critical value \\(\\times\\) standard error of the point estimator\nThe 6 testing steps are the same, and both critical value and \\(p\\)-value method can be applied too\n\ne.g., \\(t_{test} = \\frac{\\overline{x} - \\mu_0}{s/\\sqrt{n}}\\)"
  },
  {
    "objectID": "infer-prop.html#categorical-data",
    "href": "infer-prop.html#categorical-data",
    "title": "18Â  Inference About Proportions",
    "section": "\n18.1 Categorical Data",
    "text": "18.1 Categorical Data\n One Categorical Variable with Two Categories \nWe start with one categorical variable with two categories. Let \\(X\\) be the categorical variable Gender with 2 categories, Male and Female. Our data table may look like the following. The first subject is Male, so we mark it in the Male column. The second subject is Female, so we check it in the Female column, and so on.\n\n\n\n\nSubject\nMale\nFemale\n\n\n\n1\nx\n\n\n\n2\n\nx\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\nx\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen we collect the categorical data, usually we are interested in their count. We wonder which category has more counts than the other. So we can make a one-way frequency/count table as follows. It is one-way because the count table is for one categorical variable only. Here in the data there are \\(y\\) males and \\(n-y\\) females, where \\(n\\) is the sample size.\n\nOne-way frequency/count table\n\n\n\n\\(X\\)\nCount\n\n\n\nMale\n\\(y\\)\n\n\nFemale\n\\(n-y\\)\n\n\n\nNow the number of males or the proportion of males can be viewed as a random variable because the count, \\(Y\\), or the proportion \\(Y/n\\) varies from sample to sample. Suppose you want to learn the proportion of male students at Marquette, what would you do. You would probably randomly sample some Marquette students, and count how many of them are males, right? If you do the sampling again, the count will be different from the count you got previously. Therefore, to learn the male proportion, we could use the sample proportion \\(Y/n\\) as an estimator that follows some (sampling) distribution.\nOne question for you. What probability distribution might be appropriate for the count, \\(Y\\)? \n\n Probability Distribution for Count Data: Two Levels \nIn our example, each subject is either Male or Female, and with the fixed sample size, we wonder how many subjects are Males. Any probability distribution comes into your mind? Well, \\(binomial(n, \\pi)\\) could be a good option for count data with 2 categories.\n\nFixed number of trials:  We can view each sampled subject as one trial in the experiment, and we have fixed \\(n\\) subjects. \n\nEach trial results in one of two outcomes.  Clearly, in our survey, there are only two possible answers. Each subject is either Male or Females. \n\nTrials are independent.  If the subjects are randomly sampled, the students in the sample are independent. \n\nThe probability of success \\(\\pi\\) is constant:  The proportion of being in category Male is \\(\\pi\\), which is constant at the given point of time. \n\n\nThe count \\(Y\\) of male students, or the number of success, has the binomial probability \\[P(Y = y \\mid n, \\pi) = \\frac{n!}{y!(n-y)!}\\pi^{y}(1-\\pi)^{n-y}\\]\nDo we know \\(\\pi\\)? Absolutely not! The parameter \\(\\pi\\) is the proportion (or relative frequency) of male students, which is what we want to estimate and learn from data. Therefore, our goal is to estimate or test the population proportion, \\(\\pi\\), of the category Male given the assumption that the count of Male \\(Y\\) is binomially distributed \\(Y \\sim binomial(n, \\pi)\\)."
  },
  {
    "objectID": "infer-prop.html#what-probability-distribution-might-be-appropriate-for-the-count-y",
    "href": "infer-prop.html#what-probability-distribution-might-be-appropriate-for-the-count-y",
    "title": "18Â  Inference About Proportions",
    "section": "\n18.2 What probability distribution might be appropriate for the count, \\(Y\\)?",
    "text": "18.2 What probability distribution might be appropriate for the count, \\(Y\\)?\n\n\n Probability Distribution for Count Data: Two Levels \n\n\n\\(binomial(n, \\pi)\\) could be a good option for count data with 2 categories.\n\nFixed number of trials.  (Fixed \\(n\\) subjects) \n\nEach trial results in one of two outcomes.  (Either \\(M\\) or \\(F\\)) \n\nTrials are independent.  (If the subjects are randomly sampled) \n\n\n\nIf the proportion of being in category, \\(M\\), is \\(\\pi\\), the count, \\(Y\\), has \\[P(Y = y \\mid n, \\pi) = \\frac{n!}{y!(n-y)!}\\pi^{y}(1-\\pi)^{n-y}\\]\n\nGoal: Estimate or test the population proportion, \\(\\pi\\), of the category, \\(M\\)."
  },
  {
    "objectID": "infer-cat.html#test-of-goodness-of-fit",
    "href": "infer-cat.html#test-of-goodness-of-fit",
    "title": "19Â  Inference about Categorical Data",
    "section": "\n19.1 Test of Goodness of Fit",
    "text": "19.1 Test of Goodness of Fit\n\n\nA citizen in Wauwatosa, WI is curious about the question:\n\nAre the selected jurors racially representative of the population?\n\n\n\n\nWell the idea is that if the jury is representative of the population, once we collect our sample of juries, the sample proportions should reflect the proportions of the population of eligible jurors (i.e.Â registered voters).\n\n\n\n\n\nSource: https://stock.adobe.com/images/diverse-group-of-business-people/116680830\n\n\n\n\n\n\nSuppose from the government we learn the distribution of registered voters based on races. We then collect 275 jurors racial information, and see if the racial distribution of the sample is kind of consistent with the registered voter racial distribution. The count information is summarized in the table below.\n\n\n\nWhite\nBlack\nHispanic\nAsian\nTotal\n\n\n\nRepresentation in juries\n205\n26\n25\n19\n275\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n1.00\n\n\n\nThe first thing we can do is convert the count into proportion or relative frequency, so that the sample proportion and the target proportion can be easily paired and compared.\n\n\n\nWhite\nBlack\nHispanic\nAsian\nTotal\n\n\n\nRepresentation in juries\n0.745\n0.095\n0.091\n0.069\n1.00\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n1.00\n\n\n\nWhile the proportions in the juries do not precisely represent the population proportions, it is unclear whether these data provide convincing evidence that the sample is not representative. If the jurors really were randomly sampled from the registered voters, we might expect small differences due to chance. However, unusually large differences may provide convincing evidence that the juries were not representative. Specifically, we want a test to answer the question\n\nAre the proportions of juries close enough to the proportions of registered voters, so that we are confident saying that the jurors really were randomly sampled from the registered voters?\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs the binomial case, the multi-class counts \\(O_1, O_2 \\dots O_k\\) and proportions \\(O_1/n, O_2/n \\dots O_k/n\\) are random variables before actual data are collected. Their value varies from sample to sample.\n\n\nThe test we need is the goodness-of-fit test.\n\n Goodness-of-Fit Test \nA goodness-of-fit test tests the hypothesis that the observed frequency distribution fits or conforms to some claim distribution. In the jury example, our observed (relative) frequency distribution is \\((0.745, 0.095, 0.091, 0.069)\\) and the claim distribution is the racial distribution of registered voters \\((0.72, 0.07, 0.12, 0.09)\\). The jury representatives work as our sample, and the registered voters is the population. We wonder if the sample is representative of the general population. If yes, the sample should looks like the population, and sample distribution should conform to the population distribution.\nHere is the question: â€œIf the individuals are randomly selected to serve on a jury, about how many of the 275 people would we expect to be white? How about black?â€ We ask this question because we want to know how the jury distribution looks like if the distribution does follow the distribution of the registered voters. If what we expect to see is far from what we observe, then the jury is probably not randomly sampled from the registered voters. This matches our testing rationale. We do the testing under the null hypothesis, the scenario that the observed frequency distribution fits or conforms to some claim distribution.\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\nRegistered voters\n0.72\n0.07\n0.12\n0.09\n\n\nAccording to the claimed distribution, \\(72\\%\\) of the population is white, so we would expect about \\(72\\%\\) of the jurors to be white. In other words, we expect to see \\(0.72 \\times 275 = 198\\) white jurors in the sample of 275 jury members. We expect about \\(7\\%\\) of the jurors to be black. This corresponds to about \\(0.07 \\times 275 = 19.25\\) black jurors in the sample. The table below shows the observed count and the expected count if members are randomly selected for each ethnic group. In general, the expected count of a category is the total count times the proportion or probability of the category.\n\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\nTotal\n\n\n\n\nObserved Count \\(O_i\\)\n\n205\n26\n25\n19\n275\n\n\n\nExpected Count \\(E_i\\)\n\n198\n19.25\n33\n24.75\n275\n\n\nPopulation Proportion \\((H_0)\\)\n\n0.72\n0.07\n0.12\n0.09\n1.00\n\n\n\nWhile some sampling variation is expected, the observed count and expected count should be similar if there was no bias in selecting the members of the jury. But how similar is similar enough? We want to test whether the differences are strong enough to provide convincing evidence that the jurors were not selected from a random sample of all registered voters.\n Goodness-of-Fit Test Example \nBefore we introduce the test procedure, to have better performance the goodness-of-fit test requires each expected count is as least five. The higher the better.\nIn words, our hypotheses are  \\[\\begin{align} &H_0: \\text{No racial bias in who serves on a jury, and } \\\\ &H_1: \\text{There is racial bias in juror selection} \\end{align}\\] \nIf the true racial distribution of juries is \\((\\pi_1, \\pi_2, \\pi_3, \\pi_4)\\), where\n\n\n\\(\\pi_1\\) is the proportion of White in jury\n\n\\(\\pi_2\\) is the proportion of Black in jury\n\n\\(\\pi_3\\) is the proportion of Hispanic in jury\n\n\\(\\pi_4\\) is the proportion of Asian in jury\n\nwe want to know if the distribution conforms to the claim racial distribution of register voters \\((\\pi_1^0, \\pi_2^0, \\pi_3^0, \\pi_4^0) = (0.72, 0.07, 0.12, 0.09)\\) where\n\n\n\\(\\pi_1^0\\) is the proportion of White in register voters\n\n\\(\\pi_2^0\\) is the proportion of Black in register voters\n\n\\(\\pi_3^0\\) is the proportion of Hispanic in register voters\n\n\\(\\pi_4^0\\) is the proportion of Asian in register voters\n\nIn general, we can rewrite our hypotheses in mathematical notations:  \\[\\begin{align} &H_0: \\pi_1 = \\pi_1^0,  \\pi_2 = \\pi_2^0, \\dots, \\pi_k = \\pi_k^0\\\\ &H_1: \\pi_i \\ne \\pi_i^0 \\text{ for some } i \\end{align}\\] \nNote that \\(H_1\\) is not \\(\\pi_i \\ne \\pi_i^0 \\text{ for all } i\\). As long as one \\(\\pi_i \\ne \\pi_i^0\\) holds, the \\(H_0\\) statement is not true.\nThe test statistic is a chi-squared statistic from the chi-squared distribution with degrees of freedom \\(k-1\\). Under \\(H_0\\), the test statistic is\n \\[\\chi^2_{test} = \\frac{(O_1 - E_1)^2}{E_1} + \\frac{(O_2 - E_2)^2}{E_2} + \\cdots + \\frac{(O_k - E_k)^2}{E_k},\\] where \\(O_i\\) is the observed count of the \\(i\\)-th category, and \\(E_i = n\\pi_i^0\\) is the expected count of the \\(i\\)-th category, \\(i = 1, \\dots, k.\\) \nThe goodness-of-fit test is a chi-squared test that is always right-tailed. So we reject \\(H_0\\) if  \\(\\chi^2_{test} > \\chi^2_{\\alpha, k-1}\\).  Look at the test statistic formula carefully. When will the test statistic be large or the evidence be strong? The numerator term \\((O_i-E_i)^2\\) is the squared distance between the observed and expected counts. When the two are farther away from each other, the test statistic or evidence will be stronger. As a result, when the observed count distribution is more inconsistent with the distribution we expect to see, it is more likely to conclude that the sample is not randomly drawn from the claim or assumed population distribution.\nBack to our example.\n\n\n\n\n\n\n\n\n\n\nWhite\nBlack\nHispanic\nAsian\n\n\n\nObserved Count\n\\(O_1 = 205\\)\n\\(O_2 = 26\\)\n\\(O_3 = 25\\)\n\\(O_4 = 19\\)\n\n\nExpected Count\n\\(E_1 = 198\\)\n\\(E_2 = 19.25\\)\n\\(E_3 = 33\\)\n\\(E_4 = 24.75\\)\n\n\nProportion under \\(H_0\\)\n\n\\(\\pi_1^0 = 0.72\\)\n\\(\\pi_2^0 = 0.07\\)\n\\(\\pi_3^0 = 0.12\\)\n\\(\\pi_4^0 = 0.09\\)\n\n\n\nUnder \\(H_0\\), \\(\\chi^2_{test} = \\frac{(205 - 198)^2}{198} + \\frac{(26 - 19.25)^2}{19.25} + \\frac{(25 - 33)^2}{33} + \\frac{(19 - 24.75)^2}{24.75} = 5.89\\).\nWith \\(\\alpha = 0.05\\), \\(\\chi^2_{0.05, 3} = 7.81\\). Because \\(5.89 < 7.81\\), we fail to reject \\(H_0\\) in favor of \\(H_1\\). Therefore, we do not have convincing evidence of racial bias in the juror selection process.\n Goodness-of-Fit Test in R \nBelow is an example of how to perform a goodness-of-fit test in R. Because the goodness-of-fit test is a chi-squared test, we use the function chisq.test(). The argument x is the observed count vector of length \\(k\\), and the argument p is the hypothesized proportion distribution which is a vector of probabilities of the same length as x. The function does not provide the critical value, but it gives us the \\(p\\)-value. Since the \\(p\\)-value is greater than \\(0.05\\), we do not reject \\(H_0\\).\n\nobs <- c(205, 26, 25, 19)\npi_0 <- c(0.72, 0.07, 0.12, 0.09)\n\n## Use chisq.test() function\nchisq.test(x = obs, p = pi_0)\n\n\n    Chi-squared test for given probabilities\n\ndata:  obs\nX-squared = 5.8896, df = 3, p-value = 0.1171\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe chi-squared test can be used in two-sided one-sample proportion test. Suppose we are doing the following test\n\\[\\begin{align} &H_0: \\pi_1 = 0.5,  \\pi_2 = 0.5 \\\\ &H_1: \\pi_i \\ne 0.5 \\text{ for some } i \\end{align}\\]\nBecause there are only two categories, we automatically know the value of \\(\\pi_2\\) when we know the value of \\(\\pi_1\\) as \\(\\pi_2 = 1 - \\pi_1\\). So the hypothesis can be reduced to\n\\[\\begin{align} &H_0: \\pi_1 = 0.5 \\\\ &H_1: \\pi_1 \\ne 0.5 \\end{align}\\] or even\n\\[\\begin{align} &H_0: \\pi = 0.5 \\\\ &H_1: \\pi \\ne 0.5 \\end{align}\\] when we use \\(\\pi\\) for the proportion of the first category and \\(1-\\pi\\) for the second. We just transform a chi-squared test setting into a two-sided one-sample proportion test setting!\nSuppose \\(n = 1000\\), \\(O_1 = 520\\), \\(O_2 = 480\\), \\(\\pi_1^0 = \\pi_2^0 = 0.5\\). Our chi-squared test is\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(520, 480)\nX-squared = 1.6, df = 1, p-value = 0.2059\n\n\nIn the language of the one-sample proportion test, we have \\(n = 1000\\), \\(y = 520\\), \\(\\pi^0 = 0.5\\). \\((y = O_1 = 520, n-y = O_2 = 480)\\)\n\n\n\n    1-sample proportions test without continuity correction\n\ndata:  520 out of 1000, null probability 0.5\nX-squared = 1.6, df = 1, p-value = 0.2059\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4890177 0.5508292\nsample estimates:\n   p \n0.52 \n\n\nDo you see the two tests are equivalent? They have the same test statistic, degrees of freedom as well as \\(p\\)-value. Both lead to the same conclusion."
  },
  {
    "objectID": "infer-cat.html#test-of-homogeneity",
    "href": "infer-cat.html#test-of-homogeneity",
    "title": "19Â  Inference about Categorical Data",
    "section": "\n19.3 Test of Homogeneity",
    "text": "19.3 Test of Homogeneity\nTest of homogeneity is a generalization of the two-sample proportion test. This test determines if two or more populations (or subgroups of a population) have the same distribution of a single categorical variable having two or more categories.\nMore to be added."
  }
]